\documentclass[12pt]{book}
\usepackage[portuguese]{babel}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{color}
\usepackage[fleqn]{amsmath}
\usepackage[a4paper, margin=1.0in]{geometry}
\usepackage{verbatim}

% INICIO CONFIGURACAO DO HYPER LINK %
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\newcommand\myshade{85}
\colorlet{mylinkcolor}{violet}

\hypersetup{
	linkcolor  = mylinkcolor!\myshade!black,
	citecolor  = mylinkcolor!\myshade!black,
	urlcolor   = mylinkcolor!\myshade!black,
	colorlinks = true,
}
% FIM CONFIGURACAO DO HYPER LINK %

\usepackage{amsthm, amssymb, amsfonts, amsmath}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{calc,shapes}
% \usepackage{enumitem}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usepackage[all,cmtip]{xy}

\newtheorem{teorema}{Teorema}[section]
\newtheorem{corolario}[teorema]{Corolário}
\newtheorem{lema}[teorema]{Lema}
\newtheorem{definicao}[teorema]{Definição}
\newtheorem{exemplo}[teorema]{Exemplo}
\newtheorem{observacao}[teorema]{Observação}
\newtheorem{proposicao}[teorema]{Proposição}

\newenvironment{prova}[1]{$\square$ #1}{\hfill$\blacksquare$}

\newcommand{\aplicacaoexponencial}[2]{exp_{#1}(#2)}
\newcommand{\aplicacaoexponencialgeral}[1]{exp_{#1}}
\newcommand{\aplicaoessuaves}[2]{C^{\infty}(#1, #2)}
\newcommand{\aplicaoessuavesreatacirculo}{C^{\infty}(\retacartesianocirculo, M)}
\newcommand{\autoespaco}[1]{E_{#1}}
\newcommand{\bigmodulo}[1]{\Bigm\lvert #1 \Bigm\lvert }
\newcommand{\bigparenteses}[1]{\Big( #1 \Big) }
\newcommand{\bordo}[1]{\partial_{#1}}
\newcommand{\bordorel}[1]{\overline{\partial}_{#1}}
\newcommand{\cadeia}[2]{C_{#1}(#2; A)}
\newcommand{\caminhosfechadoscirculo}[2]{L([#1,#2], S^{1})}
\newcommand{\caminhosfechadosSp}[2]{L([#1,#2], \gruposimpletico{2n})}
\newcommand{\caminhosdecaimentoexponencial}[2]{C^{\infty}_{\searrow}(#1, #2)}
\newcommand{\caminhosdecaimentoexponencialpadrao}{\caminhosdecaimentoexponencial{x^{-}}{x^{+}}}
\newcommand{\caminhosexponenciaisconectantesabrev}{\mathcal{P}}
\newcommand{\caminhosexponenciaisconectantes}[2]{\mathcal{P}^{1,p}(#1, #2)}
\newcommand{\caminhosexponenciaisconectantespadrao}{\caminhosexponenciaisconectantes{x^{-}}{x^{+}}}
\newcommand{\caminhos}{\mathcal{L}}
\newcommand{\caminhosfechados}[1]{\caminhos^{o}(#1)}
\newcommand{\caminhoslagrangianos}[3]{\caminhos_{#3}(#1,#2)}
\newcommand{\caminhoslagrangianosV}[2]{\caminhoslagrangianos{#1}{#2}{V}}
\newcommand{\caminhospontobase}[1]{\caminhos_{#1}}
\newcommand{\caminhossempontobase}[1]{\caminhos(#1)}
\newcommand{\caminhosNaoDegeneradosSp}{\caminhos^{*}(\gruposimpletico{2n})}
\newcommand{\caminhospontobasegeral}[2]{\caminhos_{#1}(#2)}
\newcommand{\caminhossuavesconectantes}[2]{\caminhos(#1, #2)}
\newcommand{\caminhossubespacoslagrangianos}[2]{L[#1,#2]}
\newcommand{\campogradiente}{\mathcal{X}}
\newcommand{\campogradientefuncional}{\mathcal{X}_{\mathcal{A}}}
\newcommand{\campohamiltoniano}[1]{X_{H}(#1)}
\newcommand{\campohamiltonianoabrev}{X_{H}}
\newcommand{\campossuaves}[1]{\mathfrak{X}(#1)}
\newcommand{\celula}[2]{D^{#1}_{#2}}
\newcommand{\celulabordo}[2]{\partial D^{#1}_{#2}}
\newcommand{\circulo}{S^{1}}
\newcommand{\circulovariedade}{\circulo\times M}
\newcommand{\cktopologia}[1]{\mathcal{C}^{#1}\text{-topologia}}
\newcommand{\classe}[1]{[#1]}
\newcommand{\cohomologia}[2]{H^{#1}(#2)}
\newcommand{\cohomologiadual}[2]{H^{#1}(#2)^{*}}
\newcommand{\cohomologiacompac}[2]{H^{#1}_{c}(#2)}
\newcommand{\cohomologiacompacdual}[2]{H^{#1}_{c}(#2)^{*}}
\newcommand{\colecao}[1]{\{#1_{k} \}_{k\in \inteiros}}
\newcommand{\colecaoabrev}[1]{\{#1 \}_{k\in \inteiros}}
\newcommand{\colecaofinita}[2]{\{#1_{j} \}_{j=1}^{#2}}
\newcommand{\colecaofinitaabrev}[2]{\{#1 \}_{j=1}^{#2}}
\newcommand{\complementar}[2]{#1 \backslash #2}
\newcommand{\complexificacao}[1]{#1_{\complexo{}}}
\newcommand{\complexificacaotensorial}[1]{\complexo{}\otimes_{\reta} #1}
\newcommand{\complexificado}[1]{\mathcal{V}}
\newcommand{\complexificacaoelemento}[2]{#1\otimes_{\reta} #2}
\newcommand{\complexo}[1]{\mathbb{C}^{#1}}
\newcommand{\diferencialfloer}{D\operadorflor}
\newcommand{\diferencialfloerabrev}{\mathcal{D}}
\newcommand{\derivada}[2]{\frac{d #1}{d #2}}
\newcommand{\derivadaparcial}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\derivadaparcialabrev}[1]{\partial_{#1}}
\newcommand{\diferencialhamiltoniano}[1]{(dX_{H})_{#1}}
\newcommand{\distribuicoes}{\distribuicoesgeral{\Omega}}
\newcommand{\distribuicoesgeral}[1]{\mathcal{D'}(#1)}
\newcommand{\energiafinitaM}{\mathcal{E}M}
\newcommand{\energiafinitaMconectante}{\energiafinitaM(x^{-}, x^{+})}
\newcommand{\espacoLdois}[1]{L^{2}(#1)}
\newcommand{\espacoLp}[1]{L^{p}(#1)}
\newcommand{\espacoLpcomp}[1]{L^{p}_{loc}(#1)}
\newcommand{\espacoLpcontradominio}[2]{L^{p}(#1;#2)}
\newcommand{\espacoLpGeral}[2]{L^{#1}(#2)}
\newcommand{\espacoLpretacirculo}{\espacoLpcontradominio{\retacartesianocirculo}{\real{2n}}}
\newcommand{\espacomoduli}[2]{\mathcal{M}_{#1#2}}
\newcommand{\espacoSimpleticoOrtogonal}[1]{#1^{\omega}}
\newcommand{\espacosobolev}[1]{W^{1,p}(#1)}
\newcommand{\espacosobolevcontradominio}[2]{W^{1,p}(#1;#2)}
\newcommand{\espacosobolevretacirculo}{\espacosobolevcontradominio{\retacartesianocirculo}{\real{2n}}}
\newcommand{\espacosobolevgeral}[2]{W^{1,#1}(#2)}
\newcommand{\espacotangente}[1]{\espacotangenteponto{p}{#1}}
\newcommand{\espacotangentevariedadeestavel}{T^{s}_{p}M}
\newcommand{\espacotangentevariedadeinstavel}{T^{u}_{p}M}
\newcommand{\espacotangenteponto}[2]{T_{#1}#2}
\newcommand{\espacotangentevariedade}{\espacotangenteponto{p}{M}}
\newcommand{\espectrooperador}[1]{\sigma(#1)}
\newcommand{\estruturacomplexa}{J_{0}}
\newcommand{\estruturascomplexas}[2]{\mathcal{J}(#1, #2)}
\newcommand{\estruturascomplexaspadrao}{\mathcal{J}(V, \omega)}
\newcommand{\fibradocaminhosexponenciais}{\mathcal{E}(x^{-}, x^{+})}
\newcommand{\fibradocaminhosexponenciaisabrev}{\mathcal{E}}
\newcommand{\formaSimpletica}[2]{\omega(#1, #2)}
\newcommand{\formaSimpleticaabrev}{\omega_{0}}
\newcommand{\formaSimpleticaExtendida}[2]{\Omega(#1, #2)}
\newcommand{\formaSimpleticaPadrao}[2]{\omega_{0}(#1, #2)}
\newcommand{\funcaocond}[5]{
	#1 = 
	\left\{
	\begin{array}{cc}
		#2, & #3\\
		#4, & #5\\
	\end{array}
	\right.
}
\newcommand{\funcionalH}{\mathcal{A}_{H}}
\newcommand{\funcionalHponto}[1]{\mathcal{A}_{H}(#1)}
\newcommand{\funcoesdiferenciaveis}[2]{C^{#1}(#2)}
\newcommand{\funcoesdiferenciaveissupp}[2]{C^{#1}_{c}(#2)}
\newcommand{\funcoesmorse}[1]{\mathcal{M}_{o}(#1)}
\newcommand{\funcoesmorsesmale}[1]{\mathcal{M}^{S}_{o}(#1)}
\newcommand{\funcoessuaves}[1]{C^{\infty}(#1, \real{})}
\newcommand{\funcoesteste}{\mathcal{D}(\Omega)}
\newcommand{\generalgroup}[2]{GL(#1, #2)}
\newcommand{\generalgroupreal}[1]{\generalgroup{#1}{\real{}}}
\newcommand{\generalgroupcomplexo}[1]{\generalgroup{#1}{\complexo{}}}
\newcommand{\gradiente}{\nabla f}
\newcommand{\gradientefuncional}{\nabla \funcionalH}
\newcommand{\grupofundamental}[1]{\pi_{1}(#1)}
\newcommand{\grupofundamentalpontobase}[2]{\pi_{1}(#1; #2)}
\newcommand{\gruposimpletico}[1]{Sp(#1)}
\newcommand{\gruposimpleticocomplexo}[1]{Sp(#1; \complexo{})}
\newcommand{\gruposimpleticoreal}[1]{Sp(#1;\reta)}
\newcommand{\gruposimpleticoespecial}[1]{Sp^{1}(#1)}
\newcommand{\gruposimpleticonaodegenerado}[1]{Sp^{#1}(2n)}
\newcommand{\gruposimpleticopositivo}[1]{Sp_{+}(#1)}
\newcommand{\hessiana}{H_{p}(f)}
\newcommand{\homologia}[2]{H_{#1}(#2;A)}
\newcommand{\homologiaabrev}[2]{H_{#1}(#2)}
\newcommand{\homologiarel}[3]{H_{#1}(#2,#3)}
\newcommand{\homologiarelcel}[3]{H_{#1}(D^{#2}_{#3}, \partial D^{#2}_{#3})}
\newcommand{\homologiarelskele}[3]{H_{#1}(X^{(#2)}, X^{(#3)})}
\newcommand{\homologiarelskelesimpl}[2]{H_{#1}(X^{(#2)}, X^{(#2-1)})}
\newcommand{\imagembordo}[2]{B_{#1}(#2;A)}
\newcommand{\imagembordoabrev}[2]{B_{#1}(#2)}
\newcommand{\induzida}[1]{#1_{\#}}
\newcommand{\inteiros}{\mathbb{Z}}
\newcommand{\inteirospos}{\inteiros_{+}}
\newcommand{\iprod}[2]{\langle #1, #2 \rangle}
\newcommand{\intervalo}{[0,1]}
\newcommand{\kernelbordo}[2]{Z_{#1}(#2;A)}
\newcommand{\kernelbordoabrev}[2]{Z_{#1}(#2)}
\newcommand{\liederivada}[1]{\mathcal{L}_{#1}}
\newcommand{\operadorflor}{\mathcal{F}}
\newcommand{\operadorflordefinicao}[1]{\derivadaparcial{#1}{s} + J(#1)\derivadaparcial{#1}{t} - J(#1)X_{H}(#1)}
\newcommand{\operadorflorparametro}[1]{\mathcal{F}(#1)}
\newcommand{\operadorflorpadrao}{\operadorflorparametro{u}}
\newcommand{\matrizantisimetrica}[1]{Asym(#1)}
\newcommand{\matrizortogonal}[1]{O(#1)}
\newcommand{\matrizquadcomplexa}[1]{M_{#1 \times #1}(\complexo{})}
\newcommand{\matrizquadreal}[1]{M_{#1 \times #1}(\real{})}
\newcommand{\matrizsimetrica}[1]{Sym(#1)}
\newcommand{\matrizSimpleticaOrtogonal}{\mathcal{U}}
\newcommand{\matrizsimetricapositiva}[1]{Sym_{+}(#1)}
\newcommand{\matrizsimpleticapositiva}[1]{Sp_{+}(#1)}
\newcommand{\matrizunitaria}[1]{U(#1)}
\newcommand{\norma}[1]{||#1||}
\newcommand{\normagrande}[1]{\Big|\Big|#1\Big|\Big|}
\newcommand{\normaLp}[1]{||#1||_{L^{p}}}
\newcommand{\normaLpdefinicao}[2]{ \Big(\int_{#2}#1^{p}\Big)^{1/p}}
\newcommand{\normaLpDominio}[2]{||#1||_{L^{p}(#2)}}
\newcommand{\normaLgGeral}[3]{\norma{#1}_{\espacoLpGeral{#2}{#3}}}
\newcommand{\normapequenaLpdefinicao}[2]{ \normaLpdefinicao{\norma{#1}}{#2}}
\newcommand{\normagrandeLpdefinicao}[2]{ \normaLpdefinicao{\normagrande{#1}}{#2}}
\newcommand{\normasubscrito}[2]{\norma{#1}_{#2}}
\newcommand{\normaWp}[1]{||#1||_{W^{1,p}}}
\newcommand{\normaWpgeral}[2]{||#1||_{W^{1,#2}}}
\newcommand{\normaWpGeralDominio}[3]{\norma{#1}_{W^{1,#2}(#3)}}
\newcommand{\normaWpDominio}[2]{||#1||_{W^{1,p}(#2)}}
\newcommand{\operadorcauchyabrev}[1]{\overline{\partial}_{#1}}
\newcommand{\operadorfloer}{\mathfrak{F}}
\newcommand{\operadoresfredholm}[2]{\mathcal{F}r(#1, #2)}
\newcommand{\operadoreslimitados}[2]{\mathcal{B}(#1, #2)}
\newcommand{\orbitaponto}[1]{\mathcal{O}(#1)}
\newcommand{\orbitasconectantes}[2]{\mathcal{M}(#1, #2)}
\newcommand{\orbitasconectantespadrao}{\mathcal{M}(x^{-}, x^{+})}
\newcommand{\parteImaginaria}[1]{\mathcal{I}m(#1)}
\newcommand{\parteReal}[1]{\mathcal{R}e(#1)}
\newcommand{\pontoscriticos}[1]{\textit{Cr}(#1)}
\newcommand{\produtointerno}[2]{\langle #1, #2 \rangle}
\newcommand{\produtointernoabrev}{\langle ., .\rangle}
\newcommand{\produtosinternos}[1]{Riem(#1)}
\newcommand{\produtotensorial}[2]{ #1_{1} \otimes_{\mathbb{K}} \dots \otimes_{\mathbb{K}} #1_{#2}}
\newcommand{\produtotensorialabrev}[2]{#1\otimes #2}
\newcommand{\produtotensorialdual}{\produtotensorialabrev{\complexificado{V}^{*}}{\complexificado{V}^{*}}}
\newcommand{\produtotensorialreal}[2]{\bigotimes_{j=1}^{#1} #2_{j}}
\newcommand{\pullbackfibradotangente}[2]{#1^{*}T#2}
\newcommand{\pullbackfibradotangenteM}[1]{\pullbackfibradotangente{#1}{M}}
\newcommand{\pullbackfibradotangenteMpadrao}{\pullbackfibradotangente{u}{M}}
\newcommand{\retacartesianocirculo}{\real{} \times \circulo}
\newcommand{\retacartesianovariedade}{\real{} \times M}
\newcommand{\real}[1]{\mathbb{R}^{#1}}
\newcommand{\realprojetivo}[1]{\mathbb{R}P^{#1}}
\newcommand{\reta}{\real{}}
\newcommand{\subespacoslagrangianos}{L(V)}
\newcommand{\lacocontrateis}{\mathcal{L}M}
\newcommand{\somadir}[1]{\bigoplus \limits_{#1}}
\newcommand{\cilindrosLM}{\mathcal{C}M}
\newcommand{\morsefunc}[1]{\mathcal{M}o(#1)}
\newcommand{\skeleton}[1]{X^{(#1)}}
\newcommand{\variedadeconectante}{\variedadeconectantepontos{p}{q}}
\newcommand{\variedadeconectantepontos}[2]{W_{#1#2}}
\newcommand{\variedadeestavel}[1]{W^{s}(#1)}
\newcommand{\variedadeinstavel}[1]{W^{u}(#1)}
\newcommand{\vermelho}[1]{{\color{red}#1}}
\begin{document}
	
	\title{Homologia de Floer, Índice de Maslov e a Conjectura de Arnold}
	
	\author{Vinicius Fernades}
	
	\maketitle
	
	\tableofcontents
	
	\chapter*{Introdução}\label{capitulo_introducao}
	Como muitas das construções desenvolvidas na matemática a Homologia de Floer teve como motivação um problema de origem na Física, mais especificamente, no estudo de sistemas Hamiltonianos. A descrição Newtoniana da mecânica clássica tem como um de seus equivalentes a descrição Hamiltoniana. Nesse contexto, grande parte dos sistemas dinâmicos Hamiltonianos podem ser desenvolvidos em uma 2n-variedade diferenciável $M$ munida de uma 2-forma fechada e não degenerada $\omega$. O sistema dinâmico é modelado por uma função Hamiltoniana dependente do tempo $H: \retacartesianovariedade \to \reta$ satisfazendo a equação geométrica $\omega(\campohamiltonianoabrev(t), v) = dH_{t}(v)$, onde o campo vetorial $\campohamiltonianoabrev(t) \in \campossuaves{M}$ é chamado de campo Hamiltoniano associado a $H$. As equações de movimento são as soluções do fluxo
	$$
	\derivada{\psi(t)}{t} = \campohamiltoniano{\psi(t)}.
	$$ 
	Foi estudando sistemas dinâmicos Hamiltonianos que V. I. Arnold formulou a primeira versão da conjectura que atualmente leva seu nome. Sejam $(M, \omega )$ uma 2n-variedade simplética e $\phi:M \to M$ um difeomorfismo tal que $\phi^{*}\omega = \omega$. Então $\phi$ é chamado de simplectomorfismo. Pode-se mostrar que $\psi(t):M\to M$ é um simplétomorfismo e o conjunto $G=\{\psi(t): t \in \reta\}$ forma um grupo de difeomorfismos com a operação de composição, chamado grupo de aplicações Hamiltonianas (ou grupo a 1-parâmetro de difeomorfismos). De acordo com a Teoria de Lefschetz toda aplicação Hamiltoniana possui ao menos um ponto fixo, quando a característica de Euler de $M$ é não-nula. A ideia de Arnold era generalizar esse resultado, o que levou a seguinte versão da conjectura:
	
	\textbf{Conjectura de Arnold (V1):} \textit{Seja $\phi$ uma aplicação Hamiltoniana em uma 2n-variedade compacta simplética $(M, \omega)$. Então, o número de pontos fixos de $\phi$ é, no mínimo, o número de pontos críticos de uma função Hamiltoniana em $M$.}
	
	Posteriormente, trabalhando em particularizações do problema, tais como $T^{2}$ e $S^{2}$, Arnold observou que, se a função Hamiltoniana $H$ depende periodicamente no tempo, isto é, $H:\circulovariedade\to \reta$ tem período 1, então as soluções 1-periódicas do campo Hamiltoniano estão em bijeção com os pontos fixos da função Hamiltoniana. Com isso, ao invés de determinar diretamente os pontos fixos da aplicação Hamiltoniana $\phi$, basta determinar as soluções 1-periódicas do sistema Hamiltoniano. O que resultou na seguinte reformulação da conjectura
	
	\textbf{Conjectura de Arnold (V2):} \textit	{Seja $(M,\omega)$ uma 2n-variedade compacta e simplética. Defina $H:M\times \real{}$ uma função hamiltonia 1-periódica e suponha que as soluções 1-periódicas do sistema hamiltoniano sejam não-degeneradas. Então o número de soluções $\mathcal{N}$ desse sistema será limitado interiormente pela soma dos números de Betti de M, isto é:
		$$
		\mathcal{N}\geq \sum_{i=0}^{2n}\beta_{i}(M),
		$$
		onde $\beta_{i}(M)$ é a dimensão do i-ésimo grupo de homologia singular de $M$.}
	
	Motivado pela demonstração dessa conjectura, nasce um dos principais formalismos no estudo da topologia simplética: a Homologia de Floer.
	
	O fato de estar presente a soma dos números de Betti na conjectura nos conduz a ideia de construirmos uma homologia que tenha como ingredientes as soluções do sistema Hamiltoniano. Mas uma abordagem similiar já era conhecida: a Homologia de Morse-Witten. Também tem origem em problemas de sistemas dinâmicos da Física, mais espeficicamente, em estudos dos aspectos topológicos de sistemas quânticos por Edward Witten $\cite{witten_supersymmetry_morse}$.
	
	A construção de Witten traz um entendimento geométrico do operador bordo do complexo de cadeias. Munindo a variedade $M$ com uma métrica Riemanniana, determina-se os pontos críticos de função de Morse $f: M \to \reta$ e mostra-se que, para cada par de ponstos críticos, existem um número finito de linhas do fluxo gradiente conectando-os. O conjunto de tais linhas são subvariedades de $M$ chamadas variedades de conexão. Escolhemos  uma orientação para a variedade de conexão. Witten definiu o grupo das $k$-cadeias como sendo o grupo abeliano gerado pelos pontos críticos com índice de Morse igual a $k$. Já o operador bordo quando avaliado em uma k-cadeia é a soma sob todos os pontos críticos com índice igual a $k-1$, sendo que os coeficientes dessa soma são dados pela diferença entre o número total das linhas que convergem para o ponto e o número total das linhas que divergem do ponto. Essa é uma metodologia simples e elegante de cálculo da homologia da variedade que permite o estudo dos aspectos topológicos das variedades via sistemas dinâmicos, sendo que a dinâmica é materializada no gradiente da função de Morse $f$.
	
	É tentador nos enveredarmos na demonstração da conjectura de Arnold via construção de Witten. Contudo, dificuldades técnicas fizeram com que uma abordagem ligeiramente diferente fosse realizada por Floer. Em vez de estudar o gradiente de uma função Hamiltoniana definida na variedade $M$ a estratégia foi analisar o comportamento de um funcional, chamado funcional Hamiltoniano, definido no espaço de curvas 1-periódicas e contráteis em $M$. Aplicando o princípio variacional clássico, determina-se que as soluções 1-periódicas e contráteis do sistema Hamiltoniano são os pontos críticos do funcional Hamiltoniano. Essa técnica é conhecido como abdordagem variacional. Uma das grandes dificuldades nesse cenário é que o conjunto de curvas 1-periódicas e contráteis forma uma variedade de dimensão infinita, com isso, estabelecer uma análogo ao índice de Morse para os pontos críticos do funcional é uma tarefa árdua. Foi necessária a construção de um operador de Fredholm e de um índice de Maslov, que generaliza o ideia do índice de Morse para dimensão infinita.
	
	O princípio variacional aplicado no funcional Hamiltoniano resulta na determinação das solução de um sistema de equações diferenciais parciais de primeira ordem. A esse sistema de equações diferenciais é associado um operador diferencial, chamado operador de Floer, cujas soluções são as curvas integrais que conectam os pontos críticos do funcional Hamiltoniano, situação análoga a determinação das linhas de fluxo do gradiente negativo.
	
	O operador de Floer é um operador linear e limitado definido no espaço de todas as curvas que conectam um par de pontos críticos do funcional Hamiltoniano. Mostra-se que esse espaço é uma variedade de dimensão infinita (uma variedade de Banach) e que o diferencial de tal operador é um operador de Fredholm. A todo operador de Fredholm associa-se um número inteiro, chamado índice de Fredholm, que no caso em que estamos interessados, coincide com a diferença dos índices de Maslov de cada um dos pontos críticos. Feito isso, pode-se mostrar que, no caso de uma função Hamiltoniana independente do tempo e cuja Hessiana é limitada, tal índice coincide com o índice de Morse, a menos de uma constante. Tem-se aqui a generalização da Homologia de Morse-Witten.
	
	\chapter{Grupo Fundamental}
	A topologia algébrica é o ramo da matemática no qual se utiliza estruturas algébricas para se analisar a topologia de um conjunto (um espaço topológico) e seus invariantes. Nesse capítulo abordaremos um caso específico de estrutura algébrica, o grupo fundamental $\grupofundamental{X}$, de um espaço topológico $X$. 
	\begin{comment}
	
	De maneira intuitiva, construiremos esse grupo através de um procedimento que involve caminhos contínuos fechados $\gamma:[0,1]\to X$ e seus caminhos equivalentes (que ficará mais claro adiante), assim, se $\gamma, \gamma':[0,1]\to X$ são caminhos fechados tais que $\gamma \sim \gamma'$, então $[\gamma] = [\gamma'] \in \grupofundamental{X}$. Mostraremos que se $X,Y$ forem espaços topológicos homeomorfos, então $\grupofundamental{X}$ e $\grupofundamental{Y}$ serão isomorfos.
	
	Um caminho fechado em um espaço topológico $X$ pode ser definido com uma aplicação contínua $\gamma:\circulo\to X$. Assim, podemos efetuar a construção de grupos mais gerais, ou de ordens superiores, do seguinte modo: seja $S^{n}= \{x \in \real{n+1}: \norma{x}=1\}$ a $n$-esféra. Então o $n$-grupo de homotopia, ou grupo de homotopia de ordem n, é o grupo $\pi_{n}(X) = \{\classe{\gamma}: \gamma,\gamma':S^{n}\to X,\; \gamma \sim \gamma'\}$, onde $\gamma \sim \gamma'$ se, e somente se, existe uma homotopia entre ambas. Com isso, o grupo fundamental é dado pelo $1$-grupo de homotopia.
	
	Os grupos fundamentais de nos dão mais informações sobre a topologia de nossos objetos de estudo do que os grupos de homologia, por exemplo: supondo que $M$ seja uma $n$-variedade compacta e $H_{k}(M)$ seja seu k-ésimo grupo de homologia, pode-se mostrar que $\homologia{k}{M} = 0$, contudo, podemos ter $\pi_{k}(M)\neq 0$ para $k\geq n$.
	\end{comment}
	
	\section{Definições}
	
	Sejam $X$ um espaço topológico e $\caminhossempontobase{X}$ o conjunto dos caminhos contínuos $\gamma:[0,1]\to X$. Tome $\gamma, \beta \in \caminhossempontobase{X}$ tais que $\gamma(1) = \beta(0)$. Definimos a justaposição $*:\caminhossempontobase{X}\times \caminhossempontobase{X} \to \caminhossempontobase{X}$ entre $\gamma$ e $\beta$ por
	$$
	\funcaocond{(\gamma*\beta)(t)}{\gamma(2t)}{0\leq t \leq 1/2}{\beta(2t-1)}{1/2 \leq t \leq 1}.
	$$
	
	Quando não houver ambiguidades denotaremos por simplicidade $\caminhos=\caminhossempontobase{X}$.
	
	\begin{definicao}\label{definicao_caminhos_homotopicos}
		(Homotopia entre caminhos) Sejam $\gamma, \gamma' \in \caminhos$ tais que $\gamma(0)=\gamma'(0)$ e $\gamma(1)=\gamma'(1)$. Uma aplicação contínua $F:X \times [0,1] \to X$ é chamada homotopia entre $\gamma$ e $\gamma'$ se $F(t, 0) = \gamma(t)$ e $F(t, 1) = \gamma'(t)$ para qualquer $t\in \circulo$. Dizemos que  $\gamma$ e $\gamma'$ são homotópicos se, e somente se, existe uma homotopia entre eles. Nesse caso denotaremos $\gamma \sim \gamma'$. 
	\end{definicao}
	
	\begin{definicao}\label{definicao_homotopia_extremos_fixos}
		(Homotopia de extremos fixos entre caminhos) Suponha as condições da definição anterior. Dizemos que a homotopia entre os caminhos $\gamma$ e $\gamma'$ é uma homotopia de extremos fixos se $F(0,s) = \gamma(0) = \gamma'(0)$ e $F(1,s) = \gamma(1) = \gamma'(1)$ para todo $s\in \intervalo$.
	\end{definicao}
	
	\begin{observacao}
		Por definição, toda homotopia de extremos fixos entre caminhos é uma homotopia entre caminhos. Portanto, também diremos que dois caminhos são homotópicos quando existir uma homotopia de extremos fixos entre ambos.
	\end{observacao}
	
	\begin{observacao}
		A definição de caminhos homotópicos não depende da homotopia escolhida, pois, dadas $F,G$ homotopias entre $\gamma$ e $\gamma'$, podemos definir uma aplicação contínua $H: [0,1] \times [0,1] \times [0,1] \to X$ tal que $H(t,s ,0) = F(t,s)$ e $H(t,s, 1) = G(t,s)$ que é uma homotopia entre as homotopias, logo será uma homotopia entre ambas as curvas.
	\end{observacao}
	
	O próximo lema demonstra a compatibilidade entre a justaposição de caminhos e a relação de homotopia.
	
	\begin{lema}\label{lema_compatibilidade_produto_caminhos}
		Sejam $\gamma, \gamma', \alpha, \alpha' \in \caminhos$ tais que $\gamma \sim \gamma'$ e $\alpha \sim \alpha'$, então $\gamma * \alpha \sim \gamma' * \alpha'$.
	\end{lema}
	\begin{prova}
		Sejam  $F, G:[0,1] \times [0,1] \to X$ homotopias entre caminhos tais que $F(t,0)=\gamma(t)$, $F(t,1)=\gamma'(t)$, $G(t,0)=\alpha(t)$, $G(t,1)=\alpha'(t)$. Então, $F_{s}, G_{s}:\intervalo \to X$, definidas por $F_{s}(t) = F(s,t)$ e $G_{s}(t) = G(s,t)$, são curvas contínuas para todo $s \in \intervalo$ tais que $F_{s}(1) = G_{s}(0)$. Com isso, $H :\intervalo\times \intervalo\to X$ tal que $H(t, s)=(F_{s}*G_{s})(t)$ é uma homotopia entre $\gamma*\alpha$ e $\gamma'*\alpha'$. De fato, $H(s) :\intervalo\to X$ é uma curva contínua pois é a justaposição de caminhos contínuos para todo $s \in \intervalo$. Além disso, $H(t, 0) = (\gamma*\alpha)(t)$ e $H(t, 1) = (\gamma'*\alpha')(t)$. Logo, $\gamma*\alpha \sim \gamma'*\alpha'$.
	\end{prova}
	
	A justaposição de caminhos em $\caminhos$ nem sempre é associativo. Contudo, o seguinte lema afirma que tal associatividade vale a menos de uma homotopia. Sua demonstração pode ser encontrada em $\cite{massey}$.
	
	\begin{lema}\label{lema_associatividade_produto_caminhos}
		Dados $\alpha, \beta, \gamma\in \caminhos$, então $(\alpha*\beta)*\gamma \sim \alpha*(\beta*\gamma)$.
	\end{lema}
	
	\begin{lema}\label{lema_caminho_inverso}
		Sejam $\gamma, \gamma^{-1}, c \in \caminhos$ tais que $c(t) = p$ para todo $t\in \circulo$ (c é o caminho constante) e $\gamma^{-1}(t) = \gamma(1-t)$. Então $\gamma*\gamma^{-1} \sim \gamma^{-1}*\gamma \sim c$.
	\end{lema} 	
	\begin{prova}
		Seja a aplicação contínua $F:[0,1]\times [0,1]\to X$ tal que
		$$
		F(t,s) = 
		\left\{
		\begin{array}{cc}
		\gamma(2t), & 0\leq t \leq s/2\\
		\gamma(s), & s/2 \leq t \leq 1-s/2\\
		\gamma(2-2t), & 1-s/2 \leq t \leq 1\\
		\end{array}
		\right.
		$$
		Temos que $F(t,1) = (\gamma*\gamma^{-1})(t)$ e $F(t,0) = c(t) = p$, logo $\gamma*\gamma^{-1}\sim c$ pois $F$ deforma continuamente a justaposição de $\gamma$ e $\gamma'$ no caminho constante. Podemos definir uma homotopia $\hat{F}$ análoga a $F$ substituindo $\gamma$ por $\gamma^{-1}$, consequentemente teremos $\gamma^{-1}*\gamma \sim c$, logo $\gamma*\gamma^{-1} \sim \gamma^{-1}*\gamma \sim c$.
	\end{prova}
	
	Sejam $\caminhospontobasegeral{p}{X} = \{\gamma\in \caminhossempontobase{X}: \gamma(0)=\gamma(1)=p \}$ o conjunto dos caminhos contínuos e fechados com o ponto base $p$, e o quociente $\caminhospontobasegeral{p}{X}/\sim = \{ \classe{\gamma} : \gamma' \in \caminhospontobasegeral{p}{X},\;\;\gamma \sim \gamma'\}$. Então, o produto definido por $\classe{\gamma}.\classe{\alpha} = \classe{\gamma*\alpha}$ esta bem-definido. De fato, tomando $\alpha, \gamma, \gamma' \in \caminhospontobasegeral{p}{X}$ tal que $\gamma \sim \gamma'$, então $\classe{\gamma}.\classe{\alpha} = \classe{\gamma*\alpha} = \classe{\gamma'*\alpha'} = \classe{\gamma'}.\classe{\alpha'}$.
	
	\begin{definicao}
		(Grupo Fundamental) Dado um espaço topológico $X$, o grupo fundamental é
		$$
		\grupofundamentalpontobase{X}{p} = (\caminhospontobase{p}/\sim, .).
		$$
	\end{definicao}
	
	\begin{teorema}
		O grupo fundamental $\grupofundamentalpontobase{X}{p}$ é um grupo.
	\end{teorema}
	\begin{prova}
		Sejam $\classe{\alpha}, \classe{\beta}, \classe{\gamma} \in  \grupofundamentalpontobase{X}{p}$ e $c\in \caminhospontobase{p}$ o caminho constante.
		\begin{enumerate}
			\item \textit{(Operação fechada)} Pelas construções anteriores de produto entre caminhos e pela construções da equivalência homotópica, temos que $\classe{\alpha}.\classe{\beta} \in \grupofundamentalpontobase{X}{p}$, logo é fechada.
			\item \textit{(Associatividade)} Segue do Lema $\ref{lema_associatividade_produto_caminhos}$ $(\classe{\alpha}. \classe{\beta}). \classe{\gamma} = \classe{\alpha*\beta}. \classe{\gamma} = \classe{(\alpha*\beta)*\gamma} = \classe{\alpha*(\beta*\gamma)} = \classe{\alpha}. (\classe{\beta}. \classe{\gamma} )$.
			\item \textit{(Elemento neutro)} Pela definição de produto temos $(\gamma*c)(t) = \gamma(2t)$ para $0\leq t \leq 1/2$ e  $(\gamma*c)(t) = c(2t-1) = p$ para $1/2 \leq t \leq 1$, logo $(\gamma*c)(t) = \gamma(t)$ para todo $t \in \circulo$. Com isso, podemos afirmar que $\classe{\gamma}.\classe{c} = \classe{\gamma*c} = \classe{\gamma}$, portanto $\classe{c}$ é o elemento neutro $Id_{p}$.
			\item \textit{(Elemento inverso)} Pelo Lema $\ref{lema_caminho_inverso}$ vimos que $\gamma *\gamma^{-1} \sim \gamma^{-1} *\gamma \sim c$, logo $Id_{p} =\classe{c} =  \classe{\gamma*\gamma^{-1}} = \classe{\gamma}.\classe{\gamma^{-1}}$, portanto $\classe{\gamma^{-1}}$ é o elemento inverso de $\classe{\gamma}$.
		\end{enumerate}
		Portanto $\grupofundamentalpontobase{X}{p}$ é um grupo.
	\end{prova}
	
	
	\begin{observacao}
		Como consequência direta do Lema $\ref{lema_compatibilidade_produto_caminhos}$, qualquer caminho homotópico ao caminho constante pertence ao elemento neutro do grupo fundamental.
	\end{observacao}
	
	Na definição de grupo fundamental se mantém a escolha do ponto base, contudo, pode-se mostrar que, para espaços topológicos conexos por caminhos, a definição de grupo fundamental independe da escolha do ponto base. A demonstração do teorema a seguir pode ser encontrado em $\cite{massey}$.
	
	\begin{teorema}
		Se $X$ é um espaço topológico conexo por caminhos, então $\grupofundamentalpontobase{X}{p} \cong \grupofundamentalpontobase{X}{q}$ para quaisquer $p,q \in X$.
	\end{teorema}
	
	No caso em que $X$ é um espaço espaços topológico conexo por caminhos denotaremos $\grupofundamental{X}=\grupofundamentalpontobase{X}{p}$ e $\caminhossempontobase{X}=\caminhospontobasegeral{p}{X}$.
	
	\section{Homomorfismos induzidos}
	Sejam $f:X\to Y$ uma aplicação contínua entre espaços topológicos e $\gamma \in \caminhospontobasegeral{p}{X}$, então temos a composição $\beta=f\circ \gamma \in \caminhospontobasegeral{f(p)}{Y}$. Sejam $\gamma' \in \caminhospontobasegeral{p}{X}$ tal que $\gamma \sim \gamma'$ e $F$ for a homotopia entre ambas, então $(f\circ F)(t,0) =  f(\gamma(t))$ e $(f\circ F)(t,1) =  f(\gamma'(t)) $, logo $G=f\circ F$ é uma homotopia entre $\beta=f\circ \gamma$ e $\beta' = f\circ \gamma'$ em $\caminhospontobasegeral{f(p)}{Y}$, assim, $\beta \sim \beta'$.
	
	\begin{lema}
		(Homomorfismo induzido) Seja $f:X\to Y$ uma aplicação contínua entre espaços topológicos, então a aplicação $f_{*}:\grupofundamentalpontobase{X}{p} \to \grupofundamentalpontobase{Y}{f(p)}$ dada por $f_{*}\classe{\gamma} = \classe{f\circ\gamma}$ é um homomorfismo.
	\end{lema}
	\begin{prova}
		Seja $\gamma \in \caminhospontobasegeral{p}{X}$ uma curva constante, então $\classe{\gamma} = Id_{p}$, logo $f_{*}Id_{p} = f_{*}\classe{\gamma} = \classe{f\circ\gamma} = Id_{f(p)}$, pois a composição $f\circ\gamma$ é uma curva constante em $Y$ com $(f\circ\gamma)(t) = f(p)$.
		
		Se $\classe{\gamma}, \classe{\gamma'}\in \grupofundamentalpontobase{p}{X}$, então 
		$$
		f_{*}(\classe{\gamma}.\classe{\gamma'}) = f_{*}(\classe{\gamma*\gamma'}) = \classe{f\circ(\gamma*\gamma')} = \classe{f\circ\gamma*f\circ\gamma'} =
		\classe{f\circ\gamma}.\classe{f\circ\gamma'}=	f_{*}\classe{\gamma}.f_{*}\classe{\gamma'}.
		$$
		Portanto $f_{*}$ é um homomorfismo de grupos.
	\end{prova}
	
	Como consequência do lema anterior o seguinte resultado mostra que o grupo fundamental é um invariante topológico.
	\begin{teorema}
		Seja $f:X\to Y$ um homeomorfismo entre espaços topológicos. Então $\grupofundamentalpontobase{X}{p}$ e $\grupofundamentalpontobase{Y}{f(p)}$ são isomorfos.
	\end{teorema}
	
	Dados $X, Y$ espaços topológicos, $p\in X$ e $q\in Y$ pontos base, então podemos construir o espaço topológico $X\times Y$ com o ponto base $(p,q)$.
	
	\begin{proposicao}\label{proposicao_produto_grupo_fundamental}
		Se $X, Y$ são espaços topológicos, $p\in X$ e $q\in Y$ são os respectivos pontos base, então $\grupofundamentalpontobase{X\times Y}{(p,q)} \cong \grupofundamentalpontobase{X}{p}\times \grupofundamentalpontobase{Y}{q}$
	\end{proposicao}
	\begin{prova}
		Dado o caminho $\Gamma \in \caminhospontobasegeral{(p,q)}{X\times Y}$ podemos escrever $\Gamma(t) = (\alpha(t), \beta(t)) \in X\times Y$ onde $\alpha \in \caminhospontobasegeral{p}{X}$ e $\beta \in \caminhospontobasegeral{q}{Y}$. Seja $\Gamma' \in \caminhospontobasegeral{(p,q)}{X\times Y}$. Então $\Gamma \sim \Gamma'$ implica que $ (\alpha, \beta) \sim (\alpha', \beta')$, logo $\alpha \sim \alpha'$ e $\beta \sim \beta'$. Portanto, temos a bijeção $I(\classe{ (\alpha, \beta)}) =  (\classe{\alpha}, \classe{\beta}) \in \grupofundamentalpontobase{p}{X}\times \grupofundamentalpontobase{q}{Y}$. Tomando $\classe{(\gamma, \lambda)} \in \grupofundamentalpontobase{(p,q)}{X\times Y}$, então $I(\classe{(\alpha, \beta)} .\classe{(\gamma, \lambda)} ) = I(\classe{(\alpha*\gamma, \beta*\lambda)} ) = (\classe{\alpha*\gamma}, \classe{\beta*\lambda})=(\classe{\alpha}, \classe{\beta}) .(\classe{\gamma}, \classe{\lambda}) = I(\classe{(\alpha, \beta)} ).I(\classe{(\gamma, \lambda)} )$, portanto é um isomorfismo.
	\end{prova}
	
	\begin{proposicao}\label{proposicao_grupo_fundamental_simplesmente_conexo}
		Se $X$ é um espaço topológico simplesmente conexo, então $\grupofundamental{X}$ é trivial.
	\end{proposicao}
	\begin{prova}
		Seja $\gamma, c \in \caminhospontobase{p}$, onde $c(t)=p$ para todo $t\in \circulo$. Como $X$ é simplesmente conexo, então toda curva pode ser deformada continuamente em $p=c(t)$, logo $\gamma \sim c$ e $\classe{\gamma} = \classe{c} = Id_{p}$. Portanto $\grupofundamental{X}$ é trivial.
	\end{prova}
	
	\section{Aplicação Grau e o Grupo Fundamental de $\circulo$}
	Nesta seção mostraremos que o grupo fundamental de $S^{1}$ é um grupo cíclico infinito pois é isomorfo a $\inteiros$. Para demonstrar este fato que, a cada caminho fechado $\gamma:[0,1] \to S^{1}$, associa um número $deg(\gamma) \in \inteiros$, chamado de \textit{grau de $\gamma$}, de modo que dois caminhos $\gamma, \beta$ em $S^{1}$ são homotópicos se, e somente se, $deg(\gamma) = deg(\beta)$ (possuem o mesmo grau). Finalmente, mostraremos que induz um isomorfismo entre $\pi_{1}(S^{1})$ e $\inteiros$.
	
	A proposição a seguir é necessária para a definição e também para o estudo das propriedades da aplicação grau e sua demonstração pode ser encontrada em $\cite{elon_grupo_fundamental}$.
	
	\begin{proposicao}\label{proposicao_levantamento_curvas}
		(Levantamento de caminhos) Seja $\gamma:[a,b] \to S^{1}$ uma aplicação contínua e $t_{a}\in \real{}$ tal que $\gamma(a) = e^{it_{a}}$. Existe uma única aplicação contínua $\alpha:[a,b] \to \real{}$ tal que $\gamma(t) = e^{i\alpha(t)}$ para todo $t\in [a,b]$ e $\alpha(a) = t_{a}$. A aplicação $\alpha$ é chamada de levantamento do caminho $\gamma$ e faz com que o diagrama abaixo comute:
		$$
		\xymatrix{
			& \real{}\ar[d]\ar[d]^{\text{exp}}
			\\
			[a,b]\ar[ur]^{\alpha} \ar[r]_{\gamma} & S^{1}
		}
		$$
	\end{proposicao}
	
	Seja $\gamma \in \caminhossempontobase{\circulo}$. Então podemos escrever $\gamma(t) = \exp(i\alpha(t))$, onde $\alpha(t) \in \reta$ é uma aplicação contínua. Como $\gamma^{-1}(\{0\})$ é um subconjunto do compacto $\intervalo$, então é um compacto e finito. Denote $t_{\gamma} = \max\{t \in \gamma^{-1}(\{0\})\}$ e defina os caminhos $\gamma_{0}(t) = \gamma(t_{\gamma}t)$ e $\gamma_{1}(t) = \gamma((1-t_{\gamma})t+t_{\gamma})$. Com isso, podemos escrever $\gamma = \gamma_{0}*\gamma_{1}$. Temos que $\gamma_{0}$ é um caminho fechado pois $\gamma_{0}(0) = \gamma_{0}(1)$ e $\gamma_{1}$ um caminho aberto. Além disso, $\gamma_{1}$ é contrátil e $\gamma = \gamma_{0}*\gamma_{1} \sim \gamma_{0}$. Portanto, qualquer $\gamma \in \caminhos(\circulo)$ é homotópica a um caminho fechado $\gamma_{0} \in \caminhos(\circulo)$.
	
	Vamos definir o grau de um caminho como sendo uma aplicação que associa um dado caminho em $\circulo$ a um multiplo de $2\pi$, isto é, o número de vezes que o tal caminho envolve $\circulo$. Na construção anterior vimos que todo caminho em $\circulo$ é homotópico a um caminho fechado. Assim, vamos restringir nossas hipóteses a caminhos fechados.

	\begin{definicao}
		(Aplicação grau) Sejam $p \in \circulo$ um ponto base e $deg: \caminhospontobasegeral{p}{\circulo} \to \inteiros$ a aplicação dada por $deg(\gamma) = (\alpha(1)-\alpha(0))/2\pi$, onde $\alpha:[0,1] \to \real{}$ é o levantamento de $\gamma$ da Proposição $\ref{proposicao_levantamento_curvas}$. A aplicação $deg$ é chamada de aplicação grau e o valor $deg(\gamma)$ é chamado grau do caminho $\gamma$.
	\end{definicao}
	
	Temos que $\gamma(0) = \gamma(1)$, o que é equivalente a $e^{i\alpha(0)} = e^{i\alpha(1)}$ pela proposição $\ref{proposicao_levantamento_curvas}$. Com isso, $e^{i(\alpha(1)-\alpha(0))} = 1$ e teremos $\alpha(1)-\alpha(0) = 2\pi k$ para algum $k \in \inteiros$. Portanto, $deg(\gamma) = (\alpha(1)-\alpha(0))/2\pi \in \inteiros$ e $deg$ esta bem-definida.
	
	\begin{proposicao}\label{proposicao_grau_aplicacao}
		(Propriedades da aplicação grau) Sejam $\gamma, \beta \in \caminhospontobasegeral{p}{\circulo}$, então
		\begin{enumerate}
			\item $deg(\caminhospontobasegeral{p}{\circulo}) = \inteiros$ e, se $\gamma(t) = e^{i2\pi t}$, então $deg(\gamma) = 1$.
			\item $deg(\gamma.\beta)=deg(\gamma)+deg(\beta)$.
			\item $\gamma\sim \beta$ se, e somente se, $deg(\gamma)=deg(\beta)$
		\end{enumerate}
	\end{proposicao}
	\begin{prova}
		\begin{enumerate}
			\item Supondo que $\gamma(t) = e^{i2\pi t}$, então $deg(\gamma) = (2\pi -0)/2\pi =1$. Dado $k \in \inteiros$ e supondo que $\beta(t) = e^{i2\pi kt}$ temos $deg(\beta) = k$, logo $deg$ é sobrejetora e $deg(\caminhospontobasegeral{p}{\circulo}) = \inteiros$.
			\item Suponha que $\gamma$ e $\beta$ sejam tais que $\gamma(1)= \beta(0) = p$ e que $\alpha$ e $\lambda$ sejam seus respectivos levatamentos, então temos que $\alpha(1) = \lambda(0)$. Pela justaposição de caminhos temos $(\gamma*\beta)(t) = e^{i\alpha(2t)}$ para $0\leq t\leq 1/2$ e  $(\gamma*\beta)(t) = e^{i\lambda(2t - 1)}$ para $1/2\leq t\leq 1$. Logo 
			$$
			\begin{aligned}
			deg(\gamma*\beta) &= (\lambda(1)- \alpha(0))/2\pi 
			\\
			&= (\lambda(1) -\lambda(0)+ \alpha(1)- \alpha(0))/2\pi
			\\
			&= deg(\gamma)+deg(\beta).
			\end{aligned}
			$$  
			\item Suponha que $h:[0,1]\times [0,1]\to S^{1}$ seja uma homotopia de extremos fixos entre $\gamma$ e $\beta$ tal que $h(t,0) = \gamma(t)$ e $h(t,1) = \beta(t)$. Então, para cada $s \in [0,1]$ fixo temos $h_{s}(0) = h_{s}(1)$, portanto $h_{s} \in \caminhospontobasegeral{p}{\circulo}$. Pela Proposição $\ref{proposicao_levantamento_curvas}$ podemos escrever $h_{s}(t) = e^{i\alpha_{s}t}$. Com isso, podemos escolher $s, s_{0 }\in [0,1]$ tais que $\norma{h_{s}(t)-h_{s_{0}}(t)} =\norma{e^{i\alpha_{s}(t)} - e^{i\alpha_{s_{0}}(t)}} <2$, ou seja, $h_{s}(t), h_{s_{0}}(t) \in \circulo$ não são anti-podais, logo $|\alpha_{s}(t)-\alpha_{s_{0}}(t)| <\pi$ para todo $t\in [0,1]$. Seja $0=s_{0}<s_{1}<s_{2}\dots s_{m-1}<s_{m} = 1$ uma partição do intervalo $[0,1]$, tal que $\norma{h_{s_{j+1}}(t)-h_{s_{j}}(t)}<2$ para $0\leq j \leq k-1$. A partição escolhida implica em $|\alpha_{j+1}(t)-\alpha_{s_{j}}(t)| <\pi$. Então
			$$
			\begin{aligned}
			2\pi|deg(h_{s_{j+1}})-deg(h_{s_{j}})| 
			&= |\alpha_{s_{j+1}}(1)-\alpha_{s_{j+1}}(0) - \alpha_{s_{j+1}}(1)+\alpha_{s_{j}}(0)|
			\\
			&\leq |\alpha_{s_{j+1}}(1)-\alpha_{s_{j}}(1)| + |\alpha_{s_{j+1}}(0)+\alpha_{s_{j}}(0)|
			\\
			&<2\pi,
			\end{aligned} 
			$$
			logo $|deg(h_{s_{j+1}})-deg(h_{s_{j}})| <1$. Portanto $deg(h_{s_{j+1}})=deg(h_{s_{j}})$ para todo $0\leq j \leq m-1$. Logo, 
			$$
			deg(\beta) = deg(h_{s_{m}})=deg(h_{s_{m-1}})=\dots=deg(h_{s_{0}}) = deg(\alpha).
			$$
			Por outro lado, vamos supor que $n = deg(\gamma)=deg(\beta)$. Considere os levantamentos $\alpha$ e $\lambda$, dos caminhos $\gamma$ e $\beta$, respectivamente. Seja $H:[0,1]\times [0,1] \to \real{}$ definida por $H(t,s) = (1-s)\alpha(t) + s\lambda(t)$. Então $H(t,0)=\alpha(t)$ e $H(t,1)=\lambda(t)$, logo $H$ é uma homotopia entre $\alpha$ e $\lambda$. Além disso 
			$$
			\begin{aligned}
			H(1,s) - H(0,s) 
			&= (1-s)\alpha(1) + s\lambda(1) - (1-s)\alpha(0) + s\lambda(0) 
			\\
			&= (1-s)(\alpha(1)-\alpha(0)) + s(\lambda(1)-\lambda(0))
			\\
			&=(1-s)deg(\gamma) +sdeg(\beta)
			\\
			&= n.
			\end{aligned}
			$$ 
			
			Seja a aplicação contínua $G(t, s) = e^{iH(s,t)}$. Então, para $s \in [0,1]$ fixo temos que $G_{s} \in \caminhospontobasegeral{p}{\circulo}$ com $deg(G_{s}) = n$. Além disso, $G(t,0) = e^{i\alpha(t)} = \gamma(t)$ e $G(t,1) = e^{i\lambda(t)} = \beta(t)$, logo $G$ é uma homotopia entre $\gamma$ e $\beta$, portanto $\gamma \sim \beta$.
		\end{enumerate}
	\end{prova}
	
	O seguinte resultado é uma consequência imediata aplicação grau e mostra que o grupo fundamental de $\circulo$ é um grupo abeliano cíclico infinito.
	
	\begin{proposicao}\label{proposicao_gerador_grupo_fundamental_ciruclo}
		O grupo $\grupofundamental{\circulo}$ é gerado por $\gamma(t) = e^{i2\pi t}$, onde $t \in [0,1]$, isto é, $\grupofundamental{\circulo} = <\classe{\gamma}>$.
	\end{proposicao}
	\begin{prova}
		Supondo $\beta \in \caminhospontobasegeral{p}{\circulo}$, então pela Proposição $\ref{proposicao_grau_aplicacao}$ podemos escrever $\beta(t)=e^{i2\pi \alpha(t)}$ e $deg(\gamma) = 1$, logo 
		$$
		deg(\beta) = k = \underbrace{1+\dots+1}_{k-vezes} = deg(\gamma)+\dots+deg(\gamma) = deg(\gamma \dots \gamma) = deg(\gamma^{n}).
		$$
		Portanto $\beta \sim \gamma^{n}$ e $\classe{\beta} = \classe{\gamma^{n}}=\classe{\gamma}^{n}$. Logo $\grupofundamental{\circulo} = <\classe{\gamma}>$.
	\end{prova}
	
	\begin{teorema}\label{teorema_grupo_fundamental_circulo}
		(Grupo fundamental de $\circulo$) $\grupofundamental{\circulo} \cong \inteiros$.
	\end{teorema}
	\begin{prova}
		Da proposição anterior temos que $\grupofundamental{\circulo} = <\classe{\gamma}>$. É evidente que aplicação $\grupofundamental{\circulo}  \ni \classe{\gamma}^{n} \mapsto n \in \inteiros$ é um isomorfismo.
	\end{prova}
	
	\section{Exemplos}
	\begin{exemplo}
		(Grupo fundamental $\grupofundamental{\real{n}}$) $\real{n}$ é conexo por caminhos e simplesmente conexo, então pela Proposição $\ref{proposicao_grupo_fundamental_simplesmente_conexo}$ temos que $\grupofundamental{\real{n}}$ é trivial.
	\end{exemplo}
	\begin{exemplo}
		(Grupo fundamental $\grupofundamental{T^{2}}$ do 2-toro) Seja $T^{2}=\circulo \times \circulo$ o 2-toro. Como $T^{2}$ é conexo por caminhos, então o grupo fundamental não depende do ponto base escolhido, logo temos $\grupofundamental{T^{2}} \cong \grupofundamental{\circulo} \times \grupofundamental{\circulo} \cong \inteiros \times \inteiros$, pelo Lema $\ref{proposicao_produto_grupo_fundamental}$ e o Teorema $\ref{teorema_grupo_fundamental_circulo}$. 
	\end{exemplo}
	
	\begin{exemplo}\label{exemplo_grupo_fundamental_plano_furo}
		(Grupo fundamental $\grupofundamental{\real{2}\backslash\{p\}}$) Seja $X = \real{2}\backslash \{(0,0)\}$, $p=(1,0) \in X$ o ponto base e $\gamma,c \in \caminhospontobase{p}$ onde $\gamma$ é o círculo envolvendo a origem e $c$ a curva constante. Se $\alpha \in \caminhospontobase{p}$ é um caminho fechado que não envolve a origem, então $\alpha$ pode ser deformada contínuamente para $p$, logo $\alpha \sim c$ e $\classe{\alpha} = Id$. Por outro lado, se $\beta \in \caminhospontobase{p}$ envolve a origem, então $\beta \sim \gamma^{n}$, onde $\gamma^{n}$ é a justaposição de $\gamma$ n-vezes e $n= deg(\beta)$. De fato, por definição $deg(\gamma) = 1$ e $deg(c) =0$, o que implica que $0= deg(c)=deg(\gamma.\gamma^{-1}) = 1 +deg(\gamma^{-1})$, portanto $deg(\gamma^{-1})=-1$. Definido $deg(\beta)=n$  temos $deg(\gamma^{n}) = n$, então pela Proposição $\ref{proposicao_grau_aplicacao}$ $\beta \sim \gamma^{n}$, portanto $\classe{\beta} =  \classe{\gamma^{n}}=\classe{\gamma}^{n}$. Logo, o grupo fundamental de $X$ é um grupo inifnito cíclico gerado por $\classe{\gamma}$, isto é, $\grupofundamental{X} = <\classe{\gamma}>$. A aplicação $\grupofundamental{X} \ni \classe{\gamma}^{n} \mapsto n \in \inteiros$ é um isomorfismo, portanto $\grupofundamental{X} \cong \inteiros$.
	\end{exemplo}
	
	\begin{exemplo}
		(Grupo fundamental $\grupofundamental{\real{2}\backslash\{p,q\}}$) Sejam $X = \real{2}\backslash\{p,q\}$ e $p ,q \in \real{2}$ tais que $p = (-1,0)$ e $q=(1,0)$. Definindo  $r=(0,0)\in \real{2}$ e $\gamma_{1}, \gamma_{2}, c \in \caminhospontobase{r}$, onde $\gamma_{1}$ é o circulo envolvendo apenas $p$, $\gamma_{2}$ é o cículo envolvendo apenas $q$ e $c$ é a curva constante, então um dado caminho $\gamma \in \caminhospontobase{r}$, tal que $deg(\gamma) = 1$, pertencerá as seguintes classes de equivalência: 1) se $\gamma$ não envolve nenhum dos pontos $p,q$, então $\gamma$ pode ser deformada continuamente ao ponto $r$, logo $\gamma \sim c$ e $\classe{\gamma} =\classe{c}= Id_{r}$. 2) se $\gamma$ envolver apenas $p$ ou apenas $q$, então $\gamma \sim \gamma_{1}$ ou $\gamma \sim \gamma_{2}$, logo $\classe{\gamma }=\classe{\gamma_{1}}$ ou $\classe{\gamma }=\classe{\gamma_{2}}$. 3) se $\gamma$ envolver $p$ e $q$, então $\gamma$ pode ser deformada continuamente no laço em formato de "8" que passa pela origem, mas esse laço pode ser deformado na justaposição $\gamma_{1}*\gamma_{2}$, ou seja, $\gamma \sim \gamma_{1}*\gamma_{2}$ e $\classe{\gamma} = \classe{\gamma_{1}}.\classe{\gamma_{2}}$. Analogamente ao Exemplo $\ref{exemplo_grupo_fundamental_plano_furo}$, qualquer classe de $\grupofundamental{X}$ pode ser escrita como $\classe{\gamma_{1}}^{n} \classe{\gamma_{2}}^{m}$, para dados $n,m \in \inteiros$. Com isso, o grupo fundamental de $X$ é um grupo cíclico infinito gerado por $\classe{\gamma_{1}}$ e $\classe{\gamma_{2}}$, isto é, $\grupofundamental{X} = <\classe{\gamma_{1}}, \classe{\gamma_{2}}>$. A aplicação $\grupofundamental{X} \ni \classe{\gamma_{1}}^{n} \classe{\gamma_{2}}^{m} \mapsto (n,m) \in \inteiros\times\inteiros$ é um isomorfismo, portanto $\grupofundamental{X}  \cong \inteiros\times\inteiros$.
	\end{exemplo}
		
	\chapter{Homologia}
	
	\section{Homologia singular}
	Para as próximas definições denotaremos por $X$ como um espaço topológico e $A$ por um anel.
	\begin{definicao}
		(Simplexo singular) Denotaremos por $\Delta_{k}$ o simplexo k-dimesional cujos vértices $e_{0}, \dots, e_{k}$ formam um base canônica de $\real{k+1}$ de modo que $\Delta_{k} = \{(x_{0}, \dots, x_{k}) \in \real{k+1}: x_{j}\geq 0, \;\sum_{j}x_{j}=1\}$. Um k-simplexo singular no espaço topológico $X$ é uma aplicação contínua $\sigma:\Delta_{k} \to X$.
	\end{definicao}
	
	Denotaremos por $\cadeia{k}{X}$ o A-módulo livre gerado pelas k-cadeias singulares de $X$. Consequentemente, cada um dos seus elementos é uma soma formal finita $\alpha = \sum_{\sigma} \alpha_{\sigma}.\sigma $ de k-simplexos singulares $\sigma$, onde $\alpha_{\sigma} \in A$.
	
	\begin{definicao}
		(Operador bordo) A i-ésima face do k-simplexo singular $\sigma: \Delta_{k} \to X$ é o (k-1)-simplexo singular $\partial^{i}\sigma:\Delta_{k-1} \to X$ onde $\partial^{i}\sigma = \sigma(t_{0}, \dots, t_{i-1},0,t_{i+1}, \dots, t_{k-1})$. O k-operador bordo é o homomorfismo denotado por $\bordo{k}: \cadeia{k}{X} \to \cadeia{k-1}{X}$ onde $\bordo{k}\sigma = \sum_{i} (-1)^{i}\partial^{i}\sigma$.
	\end{definicao}
	
	Como o $k$-operador bordo é um homomorfismo, então $ker(\bordo{k})$ e $Im(\bordo{k+1})$ são subgrupos abelianos de $\cadeia{k}{X}$, os quais denotamos por $\kernelbordo{k}{X}$ e $\imagembordo{k}{X}$, respectivamente.
	
	\begin{teorema}
		A composição $\bordo{k-1}\circ\bordo{k}: \cadeia{k}{x} \to \cadeia{k-2}{X}$ é o homomorfismo trivial para todo $k>0$.
	\end{teorema}
	
	Uma consequência imediata do teorema anterior é que $\imagembordo{k}{X} \subseteq \kernelbordo{k}{X}$, logo $\imagembordo{k}{X}$ é um submódulo normal de $\kernelbordo{k}{X}$ e o quociente $\kernelbordo{k}{X}/\imagembordo{k}{X}$ define um módulo quociente.
	
	\begin{definicao}
		(k-módulo de homologia singular) Seja $X$ um espaço topológico. Então para cada $k \in \inteirospos$ o módulo quociente
		$$
		\homologia{k}{X} = \frac{\kernelbordo{k}{X}}{\imagembordo{k}{X}}
		$$
		é o $k$-ésimo módulo de homologia singular de $X$ com coeficientes em $A$.
	\end{definicao}
	
	Um módulo graduado $G$ é uma coleção de módulos $\colecao{G}$ tal que as operações de $G$ induzidas em cada $G_{k}$ são fechadas para todo $k \in \inteiros$. Se $G$ e $G'$ são módulos graduados, então um homomorfismo $f:G\to G'$ de grau $r$, onde $r \in \inteiros$ é uma coleção de homomorfismos $\colecao{f}$, onde 
	$$
	f_{k}:G_{k}\to G'_{k+r}.
	$$
	
	Um subgrupo módulo graduado $H\subseteq G$ é um módulo graduado $H=\colecao{H}$, onde $H_{k} \subseteq G_{k}$ é um submódulo para $k \in \inteiros$. Nesse caso, o módulo quociente $G/H$ é o módulo graduado $\{G_{k}/H_{k} \}_{k\in \inteiros}$.
	
	Notemos que, dado um espaço topológico $X$, as coleções $\cadeia{*}{X} = \colecaoabrev{\cadeia{k}{X}}$, $\kernelbordo{*}{X}=\colecaoabrev{\kernelbordo{k}{X}}$, $\imagembordo{*}{X}=\colecaoabrev{\imagembordo{k}{X}}$ e $\homologia{*}{X}=\colecaoabrev{\homologia{k}{X}}$ são grupos graduados.
	
	O módulo graduado $\homologia{*}{X}$ é chamado de homologia singular do espaço $X$ e é denotado por
	$$
	\bigoplus_{k\in \inteiros}\homologia{k}{X}.
	$$
	
	\begin{definicao}
		(Complexo de cadeias) Um complexo de cadeias com coeficientes em $A$ é um A-módulo graduado $C_{*} = \colecao{C}$ juntamente com um homomorfismo $\bordo{}:C_{*} \to C_{*}$ (de grau -1)
		$$
		\xymatrix{
			\dots \ar[r]^{\bordo{k+1}}  & C_{k} \ar[r]^{\bordo{k}} & C_{k-1}\ar[r]^{\bordo{k-1}} &\dots
		}
		$$
		tal que a composição $\bordo{k-1}\circ\bordo{k} = 0$ para $k \geq 0$. Denotamos o complexo de cadeia por $(C_{*}, \bordo{*})$ e chamamos o homomorfismo $\bordo{*}$ de operador bordo do complexo de cadeia.
	\end{definicao}
	
	Note que o par $(\cadeia{k}{X}, \bordo{*})$, onde $\bordo{*}=\colecaoabrev{\bordo{k}}$, forma um complexo de cadeia.
	
	\begin{definicao}
		(Homologia do complexo de cadeia) Seja $C=(C_{*}, \bordo{*})$ um complexo de cadeias. O $k$-ésimo módulo de homologia do complexo de cadeia $C$ é o módulo quociente
		$\homologiaabrev{k}{C} = \kernelbordoabrev{k}{C}/\imagembordoabrev{k}{C}$. O módulo graduado $\homologiaabrev{*}{C} = \colecaoabrev{\homologiaabrev{k}{C}}$ é chamado homologia do complexo de cadeia $C$ e é denotado por
		$$
		\bigoplus_{k\in \inteiros}\homologiaabrev{k}{C}.
		$$				
	\end{definicao}

	\begin{definicao}
		(Aplicação de cadeias) Sejam $C$ e $C'$ dois complexos de cadeias. Uma aplicação de cadeias é um homomorfismo $f:C\to C'$ de grau zero tal que o diagrama abaixo comuta para todo $k \in \inteiros$
		$$
		\xymatrix{
			C_{k}\ar[d]_{\bordo{k}}\ar[r]^{f_{k}}  & C'_{k}\ar[d]^{\bordo{k}'} 
			\\
			C_{k-1}\ar[r]_{f_{k-1}} & C'_{k-1},
		}
		$$
		isto é, $\bordo{k}'\circ f_{k} = f_{k-1}\circ \bordo{k}$.
	\end{definicao}
	
	Dada uma aplicação de cadeias $f:C\to C'$, temos que $f(\imagembordoabrev{k}{C})\subseteq \imagembordoabrev{k}{C'}$ e $f(\kernelbordoabrev{k}{C})\subseteq \kernelbordoabrev{k}{C'}$. Logo, induz um homomorfismo $f_{*}:\homologiaabrev{*}{C}  \to \homologiaabrev{*}{C'}$ de grau 0 e definido por $f_{*}(\classe{a}) = \classe{f(a)}$.
	
	\begin{observacao}
		Note que, dadas as aplicações de cadeia $f:C\to C'$ e $f':C'\to C''$, a composição de aplicações de cadeia $f'\circ f:C\to C''$ é uma aplicação de cadeias.
	\end{observacao}
	
	Suponha que $f:X\to Y$ seja uma aplicação contínua entre espaços topológicos. Definimos o homomorfismo induzido por $f$ como sendo a aplicação $\induzida{f}:\cadeia{*}{X}\to \cadeia{*}{Y}$ tal que, dada $\phi \in \cadeia{k}{X}$, temos $\induzida{f}(\phi) = f\circ \phi$, para todo $k \in \inteiros$. Pode-se mostra que $\bordo{}'\induzida{f}=\induzida{f}\bordo{}$, ou seja, $\induzida{f}$ é uma aplicação de cadeias.
	
	O teorema a seguir mostra que a homologia singular é um invariante topológico.
	
	\begin{teorema}
		(Isomorfimo induzido) Sejam $f:X \to Y$ um homeomorfismo entre espaços topológicos e $C = \cadeia{*}{X}$ e $C'=\cadeia{*}{Y}$ os complexos de cadeias de $X$ e $Y$, respectivamente. Então $f_{*}: \homologiaabrev{*}{C} \to \homologiaabrev{*}{C'}$ é um isomorfismo.
	\end{teorema}
	
	Sejam $f, g: X\to Y$ duas aplicações contínuas entre espaços topológicos. Dizemos que $f$ e $g$ são homotópicas se existe uma aplicação contínua $h:\intervalo\times X \to Y$, tal que $h(0, .) = f$ e $h(1, .) = g$. Com isso, denotamos $f\sim g$ e aplicação $h$ é chamada homotopia entre $f$ e $g$.
	
	\begin{teorema}
		Sejam $f, g: X\to Y$ duas aplicações homotópicas entre espaços topológicos. Então $f_{*}=g_{*}: \homologiaabrev{*}{C}\to \homologiaabrev{*}{C'}$, onde $C$ e $C'$ são complexos de cadeia de $X$ e $Y$, respectivamente.
	\end{teorema}
	
	\begin{definicao}
		(Equivalência homotópica) Seja $f:X\to Y$ uma aplicação entre espaços topológicos. Dizemos que $f$ é uma equivalência homotópica se existe uma aplicação $g:Y \to X$ tal que $f\circ g \sim Id_{Y}$ e $g\circ f \sim Id_{X}$. Neste caso, dizemos que $X$ e $Y$ são homotopicamente equivalentes e denotamos por $X\sim Y$.
	\end{definicao}
	
	O resultado seguinte mostra que a equivalência de homotopia é condição suficiente para que os módulos de homologia sejam isomorfos.
	
	\begin{teorema}
		Se $f: X \to Y$ é uma equivalência homotópica entre espaços topológicos, então $f_{*}:\homologiaabrev{*}{C} \to \homologiaabrev{*}{C'}$ é um isomorfismo, onde $C$ e $C'$ são complexos de cadeia de $X$ e $Y$, respectivamente.
	\end{teorema}
	
	\section{Sequências exatas}
	\begin{definicao}
		Uma tripla $\xymatrix{C\ar[r]^{f} & D\ar[r]^{g} & E }$ de módulos abelianos e homomorfismos é chamada exata se $Im(f) = Ker(g)$. Uma sequência de módulos abelianos e homomorfismos
		$$
		\xymatrix{\dots \ar[r]& G_{1}\ar[r]^{f_{1}} & G_{2}\ar[r]^{f_{2}} & G_{3}\ar[r]^{f_{3}} & \dots \ar[r]\ar[r]^{f_{k-1}} & G_{k}\ar[r]^{f_{k}} &\dots}
		$$
		é chamada de sequência exata longa se cada tripla é exata, isto é, $Im(f_{k}) = Ker(f_{k+1})$ para todo $k\in \inteirospos$.
	\end{definicao}
	
	Dizemos que uma sequência do tipo $ \xymatrix{0 \ar[r] & C\ar[r]^{f} & D\ar[r]^{g} & E \ar[r]& 0}$ é uma sequência exata curta. Nesse caso, temos que $f$ é um monomorfismo e $g$ é um epimorfismo. Sejam $C, D, E$ são complexos de cadeias. Uma sequência exata curta de complexos de cadeias é uma coleção de sequências exatas
	$$ 
	\xymatrix{0 \ar[r] & C_{k}\ar[r]^{f_{k}} & D_{k}\ar[r]^{g_{k}} & E_{k} \ar[r]& 0}
	$$
	para todo $k \in \inteirospos$.
	
	Utilizando a sequência exata curta de complexos de cadeias, um homomorfismo entre as sequências exatas curtas, chamado homomorfismo conectante, será utilizado na construção da sequência exata longa. Considere o diagrama abaixo
	$$
	\xymatrix{
		 & \vdots \ar[d]^{\bordo{k+1}} & \vdots \ar[d]^{\bordo{k+1}'} & \vdots \ar[d]^{\bordo{k+1}''}& 
		\\
		0 \ar[r] & C_{k}\ar[d]^{\bordo{k}}\ar[r]^{f_{k}} & D_{k}\ar[d]^{\bordo{k}'}\ar[r]^{g_{k}} & E_{k} \ar[d]^{\bordo{k}''}\ar[r]& 0
		\\
		0 \ar[r] & C_{k-1}\ar[d]^{\bordo{k-1}}\ar[r]^{f_{k-1}} & D_{k-1}\ar[d]^{\bordo{k-1}'}\ar[r]^{g_{k-1}} & E_{k-1}\ar[d]^{\bordo{k-1}''} \ar[r]& 0
		\\
		 & \vdots & \vdots  & \vdots & 
	}
	$$
	Como $g$ é epimorfismo, dado $e \in \kernelbordoabrev{k}{E}$ existe $d \in D_{k}$ tal que $g_{k}(d) = e$. Pela comutatividade do diagrama, temos que $g_{k-1}(\bordo{k}'(d)) = \bordo{k}''(g_{k}(d)) = \bordo{k}''(e) = 0$. Portanto, $\bordo{k}'(d) \in Ker(g_{k}) = Im(f_{k})$, pela exatidão. Com isso, podemos tomar $c \in C_{k-1}$ tal que $f_{k-1}(c)=\bordo{k}'(d)$. Então $f_{k-2}(\bordo{k-1}(c)) = \bordo{k-1}'(f_{k-1}(c)) = \bordo{k-1}'(\bordo{k-1}'(d)) = 0$. Como $f$ é monomorfismo, então $\bordo{k-1}(c) \in \kernelbordoabrev{k-1}{C}$. Logo, temos uma correpondência $\kernelbordoabrev{k}{E} \ni e \mapsto c \in \kernelbordoabrev{k-1 }{C}$, a qual denotaremos por $\delta_{k}(e) = c$. 
	
	\begin{teorema}\label{teorema_homomorfismo_conectante}
		(Homomorfismo conectante) Se $ \xymatrix{0 \ar[r] & C\ar[r]^{f} & D\ar[r]^{g} & E \ar[r]& 0}$ é uma sequência exata curta de complexos de cadeias, então a sequência exata longa 
		$$
		\xymatrix{\dots \ar[r]^{f_{*}} & \homologiaabrev{k}{D}\ar[r]^{g_{*}} & \homologiaabrev{k}{E}\ar[r]^{\delta_{k}}& \homologiaabrev{k-1}{C}\ar[r]^{f_{*}} & \homologiaabrev{k-1}{D} \ar[r]^{g_{*}}& \dots} 
		$$
		é exata.
	\end{teorema}
	
	Como consequência do Teorema $\ref{teorema_homomorfismo_conectante}$ temos um importante método de cálculo da homologia de espaços topológicos. Dados $U, V$ subconjuntos abertos de um espaço topológico $X$ tal que $X = U\cup V$, considere a sequência exata curta de complexos de cadeias
	$$ 
	\xymatrix{0 \ar[r] & C_{k}(U\cap V)\ar[r]^{f} & C_{k}(U)\oplus C_{k}(V)\ar[r]^{g} & C_{k}(X) \ar[r]& 0},
	$$
	onde $f(x) = (x,-x)$ e $g(x) = x+y$.
	
	A sequência exata longa induzida como no Teorema $\ref{teorema_homomorfismo_conectante}$ é chamada sequência de Mayer-Vietoris.
	
	\begin{teorema}
		(Sequência de Mayer-Vietoris) Sejam $U, V$ subcojuntos abertos do espaço topológico $X$ tais que $X = U \cup V$. Então existe uma sequência exata longa 
		\[
		\xymatrix{\dots \ar[r]^{\delta_{k+1}} & \homologiaabrev{k}{U\cap V}\ar[r]^{f_{*}} & \homologiaabrev{k}{U}\oplus \homologiaabrev{k}{V}\ar[r]^{g_{*}}& \homologiaabrev{k}{X}\ar[r]^{\delta_{k}} & \homologiaabrev{k-1}{U \cap V} \ar[r]^{f_{*}}& \dots} 
		\]
	\end{teorema}
	
	Seja $U \subseteq X$ um subespaço do espaço topológico $X$ e considere o par topológico $(X, U)$. Caso $U = \emptyset$, identificaremos $(X, \emptyset)$ com $X$. Desse modo, a aplicação de inclusão $U \hookrightarrow X$ induz a aplicação de cadeias $\induzida{i}: \cadeia{*}{U} \to \cadeia{*}{X}$ tal que, para todo $k \in \inteirospos$, $i_{k}$ é um monomorfismo. Assim, podemos identificar $\cadeia{*}{U}$ como um subcomplexo de $\cadeia{*}{X}$ e podemos definir o quociente entre ambos de modo que
	
	\begin{definicao}
		O complexo singular de cadeia do par topológico $(X,U)$ é o complexo de cadeia $(\cadeia{*}{X,U},\bordorel{*} )$ onde 
		$$
		\cadeia{*}{X,U} = \frac{\cadeia{*}{X}}{\cadeia{*}{U}}
		$$
		e $\bordorel{k}: \cadeia{k}{X} \to \cadeia{k-1}{U}$ é definido por $\bordorel{k}(\classe{c}) = \classe{\bordo{k}(c)}$.
	\end{definicao}
	
	\begin{definicao}
		(Homologia relativa) Seja $(X, U)$ um par topológico. O $k$-ésimo grupo de homologia relativa de $X$ mod $U$ é o grupo quociente
		$$
		\homologia{k}{X,U} = \frac{\kernelbordo{k}{X,U}}{\imagembordo{k}{X, U}}.
		$$
	\end{definicao}
	
	\begin{proposicao}
		Dado um par topológico $(X, U)$ tal que $U$ seja um retrato de deformação de $X$, então $\homologia{*}{X,U} = 0$.
	\end{proposicao}
	
	\begin{teorema}
		(Sequência do exata par) Seja $(X, U)$ um par topológico. Então a sequência exata longa desse par é a sequência
		$$
		\xymatrix{\dots \ar[r]^{\delta_{k+1}} & \homologiaabrev{k}{U}\ar[r]^{i_{*}} & \homologiaabrev{k}{X}\ar[r]^{\pi_{*}}& \homologiaabrev{k}{X, U}\ar[r]^{\delta_{k}} & \homologiaabrev{k-1}{U} \ar[r]^{i_{*}}& \dots},
		$$
		onde $\delta_{k}$ é o homomorfismo conectante para $k \in \inteirospos$.
	\end{teorema}
	
	\begin{teorema}
		(Excisão) Seja $(X, U)$ um par topológico. Se $U' \subset U$ com $\overline{U'} \subset int(U)$, então a inclusão $i : (\complementar{X}{U'}, \complementar{U}{U'}) \hookrightarrow (X, U)$ induz um isomorfismo 
		$$
		i_{*}: \homologiaabrev{*}{\complementar{X}{U'}, \complementar{U}{U'}} \to \homologiaabrev{*}{X, A}.
		$$
	\end{teorema}
	
	
	Sejam $U'\subseteq U \subseteq X$ subespaços do espaço topológico $X$ e considere a tripla topológica $(X, U, U')$. Analogamente ao caso do par, o teorema seguinte garante a existência de uma sequência exata longa da tripla.
	
	\begin{teorema}
		(Sequência exata da tripla) Seja $(X, U, U')$ uma tripla topológica. Então a sequência exata longa da tripla dessa é a sequência
		$$
		\xymatrix{\dots \ar[r]^{\delta_{k+1}} & \homologiaabrev{k}{U, U'}\ar[r]^{i_{*}} & \homologiaabrev{k}{X, U'}\ar[r]^{\pi_{*}}& \homologiaabrev{k}{X, U}\ar[r]^{\delta_{k}} & \homologiaabrev{k-1}{U, U'} \ar[r]^{i_{*}}& \dots},
		$$
		onde $\delta_{k}$ é o homomorfismo conectante para $k \in \inteirospos$.
	\end{teorema}
	
	
	
	\section{CW-Homologia}\label{secao_cw_complexo}
	Um CW-complexo é um tipo de espaço topológico introduzido por J. H. C. Whitehead, que teve como objetivo inicial facilitar alguns cálculos em teoria de homotopia. A ideia é que um CW-complexo é construído com sucessivas colagens (identificações) de outros espaços mais simples (células), de modo que, para se determinar a homologia do todo basta determinar a homologia das partes mais simples, as células.
	\begin{definicao}
		(Colagem de célula) Sejam $X$ um espaço topológico, $D^{n}=\{x\in \mathbb{R}^{n} : ||x|| \leq 1\}$ e $S^{n-1} = \partial D^{n}=\{x\in \mathbb{R}^{n} : ||x|| = 1\}$. Se $f_{\partial}:S^{n-1} \to X$ é uma função contínua, denotaremos por $X\cup_{f_{\partial}}D^{n}$ o espaço quociente da união disjunta $X \coprod D^{n}$ onde $x \in \partial D^{x} = S^{n-1}$ é identificado com $f_{\partial}(x) \in X$. Diremos que $X\cup_{f_{\partial}}D^{n}$ é obtido a partir de $X$ colando uma $n-$célula e $f_{\partial}$ é chamado de mapa de colagem.
	\end{definicao}
	
	\begin{definicao}
		(CW-complexo) Dizemos que um espaço topológico $X$ tem uma CW-estrutura se existem uma sequência de espaços
		$$
		\skeleton{0} \subseteq \skeleton{1} \subseteq \dots \subseteq X = \bigcup \limits_{n\in \mathbb{N}} \skeleton{n}
		$$ 
		tais que:
		\begin{enumerate}
			\item $\skeleton{0}$ é um conjunto discreto de pontos.
			
			\item $\skeleton{n+1}$ é obtido anexando $(n+1)-$células a $\skeleton{n}$.
			
			\item $X$ tem uma topologia fraca, ou seja, um dado $A \subseteq X$ é dito um aberto se, e somente se, $A \cap \skeleton{n}$ for um aberto em $\skeleton{n}$ para todo $n \in \mathbb{N}$.
		\end{enumerate}
	\end{definicao}
	
	Um espaço $X$ com uma CW-estrutura é chamado de CW-complexo e cada subespaço $\skeleton{n}$ é chamado $n-$esqueleto do CW-complexo $X$. Uma aplicação $f_{\partial}:S^{n-1} \to \skeleton{n-1}$ estende a uma aplicação $f:D^{n} \to \skeleton{n}$ chamada aplicação característica. Chamaremos a imagem de $D^{n}$ por $f$ de célula fechada em $X$, e a imagem de $D^{n} - \partial D^{n}$ de célula aberta em $X$.
	
	\begin{exemplo}
		(n-esfera) Vamos exibir uma estrutura de CW-complexo para $S^{n}$. Fixemos um ponto-base $p \in S^{n}$ e definamos o $0-$esqueleto $\skeleton{0}=\{p\}$. Anexando uma $n-$célula a $\skeleton{0}$ teremos $f_{\partial}: \partial D^{n} \to \skeleton{0}$, isto é, $S^{n} \approx \skeleton{n} = \{p\}\cup_{f_{\partial}} \celula{n}{}$.
	\end{exemplo}
	
	\begin{exemplo}
		(Disco com alça) Sejam $p=(1,0), q=(-1,0) \in D^{2}$ e $I=[a,b] \subset \reta$. Temos $\partial I=\{a,b\}$. Definindo $f_{\partial_{0}}: \partial I \to D^{2}$ tal que $f_{\partial_{0}}(a)=p$ e $f_{\partial_{0}}(b)=q$ teremos o disco com alça $X=D^{2}\cup_{f_{\partial_{0}}}I$.   
	\end{exemplo}
	
	\begin{exemplo}
		(2-toro) Vamos exibir uma estrutura de CW-complexo para $T^{2}$. Representando o toro como o quadrado cujos os lados opostos estão identificados preservando a orientação, todos os vértices do quadrado serão identificados com um único ponto $p \in T^{2}$. Definamos o $0-$esqueleto como sendo $\skeleton{0} = \{p\}$. As arestas horizontais representam o mesmo $S^{1}$ no toro. Isso equivale a colar uma 1-célula ao 0-esqueleto, ou seja, $\skeleton{0}\cup_{f_{1\partial}}\celula{1}{1}$. Analogamente, as faces verticais também representam o mesmo $S^{1}$ no toro, o que indica que devemos anexar uma outra 1-célula a espaço anexado anteriormente, isto é, $\skeleton{0}\cup_{f_{1\partial}}\celula{1}{1}\cup_{f_{2\partial}}\celula{1}{2}$. Por fim, temos que anexar um 2-célula para cobrir o interior do quadrado. Então $T^{2} =\skeleton{2} = \skeleton{0}\cup_{f_{1\partial}}\celula{1}{1}\cup_{f_{2\partial}}\celula{1}{2}\cup_{f_{3\partial}}\celula{2}{3}$.
	\end{exemplo}
	
	\begin{exemplo}
		(n-espaço projetivo) Vamos exibir uma estrutura de CW-complexo para $\realprojetivo{n}$. Para $n=0$ temos que $\realprojetivo{0} = \{\classe{p}\}$, para um determinado $p \in \real{}$. Já para $n=1$, sabemos que existe um homeomorfismo $\realprojetivo{1} \approx S^{1}_{\sim} = \{\classe{p}: p \in S^{1},\; p \sim -p\}$. Note esse espaço quociente já possui, naturalmente, uma CW-estrutura pois, na passagem ao quociente, identificamos todos os pontos do equador com um único ponto desse conjunto. Digamos este ponto $p_{0} = (1,0)$, sem perda de generalidade. Isso quer dizer que ao colarmos uma 1-célula no ponto $p_{0}$ teremos $S^{1}_{\sim} \approx \{[p_{0}]\} \cup_{f}D^{1} \approx \realprojetivo{0}\cup_{f}D^{1} $ pois $\realprojetivo{0} \approx \{[p_{0}]\}$, portanto $ \realprojetivo{1} \approx \realprojetivo{0}\cup_{f}D^{1}$. Repetindo o procedimento anterior para $\realprojetivo{n} \approx S^{n}_{\sim} $ onde $p_{0} = (1,0,\dots, 0)$, teremos $\realprojetivo{n} \approx \realprojetivo{n-1} \cup_{f_{\partial}}D^{n}$. Assim, temos a CW-estrutura $\realprojetivo{j-1} \subseteq \realprojetivo{j}$ e $\realprojetivo{j} = \skeleton{j} \approx \skeleton{j-1}\cup_{f_{j\partial}}D^{j}$ para $1\leq j \leq n$.
	\end{exemplo}
	
	\begin{lema}\label{homologiacelular}
		(Homologia celular relativa) Sejam $A$ um anel comutativo com unidade e $X$ um CW-complexo, então
		$$
		\homologiarelskelesimpl{k}{n} \cong 
		\left\{
		\begin{array}{cc}
		\mathcal{C}_{n}(X), & k = n\\
		0, & k\neq n\\
		\end{array}
		\right.,
		$$
		onde $\mathcal{C}_{n}(X)$ é um $A-$módulo livre e finitamente gerado pelas $n-$células de $X$. Além disso,
		$$
		\mathcal{C}_{n}(X) \cong \somadir{\sigma} \homologiarelcel{n}{n}{\sigma} \cong \somadir{\sigma} A
		$$
		em que 
		$$
		\somadir{\sigma}f_{\sigma*}: \somadir{\sigma} \homologiarelcel{n}{n}{\sigma} \to \homologiarelskelesimpl{n}{n}
		$$
		denota o isomorfismo descrito.
	\end{lema}
	\begin{prova}
		Por definição, temos  $\skeleton{n} = \skeleton{n-1} \bigcup_{f_{\partial \sigma} } \celula{n}{\sigma}$ e também $\celula{n}{\sigma} \subset \skeleton{n}$, onde $f_{\sigma}:\celula{n}{\sigma} \to \skeleton{n}$ é a aplicação característica. Sejam $C_{\sigma}$ e $A_{\sigma}$ discos fechado e abertos, respectivamente, contendo o hemisfério norte de $f_{\sigma}(\celula{n}{\sigma})$. Definindo $N_{\sigma} = f_{\sigma}(\celula{n}{\sigma}) - C_{\sigma}$, $M_{\sigma} = f_{\sigma}(\celula{n}{\sigma}) - A_{\sigma}$ temos $\overline{N_{\sigma}} \subset M_{\sigma}$, e considerando $U = \skeleton{n} - \bigcup C_{\sigma}$, $Y = \skeleton{n} - \bigcup A_{\sigma}$ temos $U \subseteq Y$. Note que $\skeleton{n-1}$ é um retrato de deformação de $Y$, logo, pela invariância homotópica temos $\homologiarel{k}{\skeleton{n}}{\skeleton{n-1}} \cong  \homologiarel{k}{\skeleton{n}}{Y}$. Como $\skeleton{n} - U = \bigcup C_{\sigma}$ e $Y - U $ é homotópico a $\bigcup S^{n}_{\sigma}$, pelo teorema da excisão $\homologiarel{k}{\skeleton{n} - U}{Y- U} \cong \homologiarel{k}{\skeleton{n}}{Y}$. Portanto $\homologiarel{k}{\skeleton{n} - U}{Y- U} = \homologiarel{k}{\bigcup C_{\sigma}}{\bigcup S^{n}_{\sigma}} \cong \homologia{k}{\bigcup (\celula{n}{\sigma}, \celulabordo{n}{\sigma})} \cong \somadir{\sigma} \homologiarelcel{k}{n}{\sigma}$, pois $C_{\sigma} \approx \celula{n}{\sigma}$ e $S^{n}_{\sigma} = \celulabordo{n}{\sigma}$. Enfim, temos o diagrama comutativo:
		\[
		\xymatrix{
			\somadir{\sigma} \homologiarelcel{k}{n}{\sigma} \ar[r]^{id_{*}} \ar[d]^{\cong} & 
			\somadir{\sigma} \homologiarelcel{k}{n}{\sigma} \ar[r]^{id_{*}} \ar[d]^{\somadir{\sigma}f_{\sigma*}} & 
			\somadir{\sigma} \homologiarelcel{k}{n}{\sigma} \ar[d]^{\somadir{\sigma}f_{\sigma*}} 
			\\
			\homologiarel{k}{\skeleton{n} - U}{Y- U} \ar[r]^{\cong} & \homologiarel{k}{\skeleton{n}}{Y} \ar[r]^{\cong} & 
			\homologiarelskelesimpl{k}{n}.
		}
		\]
		Por fim, sabemos que $\homologiarelcel{k}{n}{\sigma} \cong A$ para $k=n$ e é trivial para $k\neq n$, então pela sequência anterior temos $\homologiarelskelesimpl{k}{n} \cong \somadir{\sigma}\homologiarelcel{k}{n}{\sigma} \cong \somadir{\sigma} A$ se $k=n$ e é trivial caso $k\neq n$, como desejávamos.
	\end{prova} 
	
	\begin{definicao}
		(Aplicação de Pares) Seja $X = \skeleton{n}$ um CW-complexo e tome $p \in \skeleton{n-1}$ como um ponto-base. Identificaremos um dado $q \in \skeleton{n}$ com o ponto-base se $q \in \skeleton{n-1}$, e diremos que $q \sim p$. Definimos $\skeleton{n}/\skeleton{n-1} = \{[q]: q \in \skeleton{n}, \; q \nsim p\}$ e a aplicação quociente $\pi : \skeleton{n} \to \skeleton{n}/\skeleton{n-1}$ por:
		$$
		\pi(q) = 
		\left\{
		\begin{array}{cc}
		\classe{p}, & q \in \skeleton{n-1}\\
		\classe{q}, & q \notin \skeleton{n-1}\\
		\end{array}
		\right..
		$$
		Seja $\bigvee_{\sigma} S^{n}_{\sigma}$ o buquet de $n-$esferas com o ponto-base $p$, então $\skeleton{n}/\skeleton{n-1} \approx \bigvee_{\sigma} S^{n}_{\sigma}$. Agora, definindo $s_{\sigma} : \skeleton{n}/\skeleton{n-1} \to S^{n}_{\sigma}$ por 
		$$
		\funcaocond{s_{\sigma}([q])}{q}{q \in \celula{n}{\sigma}}{p}{q \notin \celula{n}{\sigma}}
		$$
		chamamos de $\sigma-$aplicação de pares $p_{\sigma} = s_{\sigma} \circ \pi : (\skeleton{n}, \skeleton{n-1}) \to (S^{n}_{\sigma}, \{p\})$.
	\end{definicao}
	
	Denotaremos por $\Psi_{n}:\mathcal{C}_{k}(X) \to \homologiarelskelesimpl{k}{n}$ o isomorfismo definido no lema anterior dado por 
	$$
	\Psi(\sum_{\sigma} n_{\sigma} \sigma) = \sum_{\sigma} n_{\sigma} f_{\sigma *}[D^{n}],
	$$
	onde $[D^{n}]$ é um gerador do módulo $\homologiarelcel{n}{n}{}$.
	
	\begin{lema}
		(Inversa de $\Psi_{n}$) A aplicação inversa $\Phi_{n} : \homologiarelskelesimpl{n}{n} \to \mathcal{C}_{n}(X)$ do isomorfismo definido anteriormente é dada por
		$$
		\Phi_{n}(\alpha) = \sum_{\sigma} \phi_{n}(p_{\sigma *}\alpha)\sigma,
		$$
		onde $\phi_{n}: \homologiarel{n}{S^{n}}{\{p\}} \to \Lambda$ é o único homomorfismo tal que $\phi_{n}([S^{n}])=1$ e $[S^{n}]$ é a classe fundamental do par $(S^{n}, \{p\})$.
	\end{lema}
	\begin{prova}
		Mostremos a unicidade do homomorfismo. Sabemos que o grupo $\homologiarel{n}{S^{n}}{\{p\}}$ tem como geradores as classes $\{[S^{n}], [0]\}$ e como $\phi_{n}$ é homomorfismo, então $\phi_{n}([0]) = 0$. Definindo $\phi_{n}([S^{n}]) = 1$ e supondo que exista outro homomorfismo tal que $\phi_{n}^{'} ([S^{n}]) = 1$, então ambos homomorfismos coincidem quando avaliados nos geradores, logo $\phi_{n}^{'}=\phi_{n}$ o que é uma contradição, portanto $\phi_{n}$ é único. Sabemos o que $\Psi_{n}$ é um isomorfismo, então existe uma única aplicação $\Phi_{n}$ tal que $\Phi_{n} \circ \Psi_{n} = 1$. Tomando $\sigma$ uma $n-$célula geradora de $\mathcal{C}_{n}(X)$,
		$$
		\begin{aligned}
		\Phi_{n}(\Psi_{n}(\sigma)) 
		&= \sum_{\beta}\phi_{n}(p_{\beta *}\Psi_{n}(\sigma))\beta
		\\
		&= \sum_{\beta}\phi_{n}(p_{\beta *}f_{\partial\sigma *}[D^{n}])\beta
		\\
		&= \sum_{\beta}\phi_{n}((p_{\beta}\circ f_{\partial\sigma})_{*}[D^{n}])\beta
		\\
		&= \phi_{n}((p_{\sigma}\circ f_{\partial\sigma})_{*}[D^{n}])\sigma
		\\
		&= \phi_{n}([S^{n}])\sigma
		\\
		&= \sigma	
		\end{aligned},
		$$
		e como $\sigma \in \mathcal{C}_{n}(X)$ é arbitrário, então $\Phi_{n} \circ \Psi_{n} = 1$, como desejávamos.
	\end{prova}
	
	\begin{definicao}
		(Grau homológico) Seja $f: S^{n} \to S^{n}$ uma aplicação contínua e $f_{*}: \homologia{n}{S^{n}} \to \homologia{n}{S^{n}}$ o homomorfismo induzindo. Seja $[S^{n}] \in \homologia{n}{S^{n}}$ o gerador não-trivial desse grupo, então $f_{*}[S^{n}] = k[S^{n}]$ para algum $k \in \Lambda$. Denominamos $k=deg(f)$ o grau homológico da aplicação $f$.
	\end{definicao}
	
	\begin{definicao}
		(Aplicação CW-bordo) Tome a tripla $(\skeleton{n}, \skeleton{n-1}, \skeleton{n-2})$ e a composição abaixo
		\[
		\xymatrix{
			\mathcal{C}_{n}(X) \ar[r]^{\Psi_{n}\qquad} &
			\homologiarelskelesimpl{n}{n} \ar[r]^{\delta_{*}} & 
			\homologiarelskele{n-1}{n-1}{n-2} \ar[r]^{\qquad \Phi_{n-1}}&
			\mathcal{C}_{n-1}(X)
		}
		\]
		onde $\delta_{*}$ é o homomorfismo de conexão da sequência da tripla. Denominamos por operador CW-bordo o homomorfismo $\partial_{n} = \Phi_{n-1} \circ \delta_{*} \circ \Psi_{n} : \mathcal{C}_{n}(X) \to \mathcal{C}_{n-1}(X)$.
	\end{definicao}
	
	\begin{teorema}
		(CW-bordo) A aplicação CW-bordo é um homomorfismo tal que $\partial_{n-1}\circ\partial_{n} = 0$ e é dado por:
		$$
		\partial_{n}(\sigma) = \sum_{\beta}[\beta:\sigma]\beta,
		$$
		onde $[\beta:\sigma]$ é o grau homológico da aplicação $p_{\beta} \circ f_{\partial\sigma}:\celulabordo{n}{\sigma} \to S^{n-1}_{\sigma}$.
	\end{teorema}
	\begin{prova}
		Por definição temos que $\partial_{n} = \Phi_{n-1} \circ \delta_{*} \circ \Psi_{n}$, logo é um homomorfismo.
		
		Consideremos o diagrama comutativo tal que na vertical temos a sequência exata longa do par $(\skeleton{n-1}, \skeleton{n-2})$
		$$
		\xymatrix{
			& \homologiaabrev{n-2}{\skeleton{n-2}}\ar[rd]^{j_{*}}
			\\
			\homologiarelskele{n}{n}{n-1} \ar[r]^{\delta_{*} \qquad}\ar[rd]_{\delta_{n}} &
			\homologiarelskele{n-1}{n-1}{n-2} \ar[u]^{\delta_{n-1}} \ar[r]^{ \delta_{*}}&
			\homologiarelskele{n-2}{n-2}{n-3}
			\\
			& \homologiaabrev{n-1}{\skeleton{n-1}}\ar[u]^{j_{*}}
		}
		$$
		Note que $\delta_{*} \circ \delta_{*} = j_{*} \circ \delta_{n-1} \circ j_{*} \circ \delta_{n}$. Pela exatidão da sequência vertical temos $Im(j_{*}) = Ker(\delta_{n-1})$, logo $\delta_{*}^{2}=0$. Com isso, temos o composição do CW-bordo $\partial_{n-1}\circ \partial_{n} = \Phi_{n-2} \circ \delta_{*} \circ \Psi_{n-1} \circ \Phi_{n-1} \circ \delta_{*} \circ \Psi_{n} = \Phi_{n-2} \circ \delta_{*}^{2} \circ \Psi_{n} =0$, pois $\Psi_{n-1} \circ \Phi_{n-1}=1$.
		
		Por definição temos $f_{\partial\sigma}: \celulabordo{n}{\sigma} \to \skeleton{n-1}$, assim temos o homomorfismo induzido $f_{\partial\sigma*}: \homologia{n-1}{\celulabordo{n}{\sigma} }\to \homologia{n-1}{\skeleton{n-1}}$. Analogamente, temos o homomorfismo $f_{\sigma*}:\homologiarelcel{n}{n}{\sigma} \to \homologiarelskelesimpl{n}{n}$ e o homomorfismo conectante $\delta_{n} : \homologiarelcel{n}{n}{\sigma} \to \homologia{n-1}{\celulabordo{n}{\sigma}}$ de modo que, tomanto $[\celula{n}{\sigma}] \in \homologiarelcel{n}{n}{\sigma}$ como um elemento gerador, então $\delta_{n}\circ f_{\sigma*}[\celula{n}{\sigma}] \in \homologia{n-1}{\skeleton{n-1}}$ é um elemento gerador. Por outro lado $f_{\partial\sigma*}\circ \delta_{n}[\celula{n}{\sigma}] \in \homologia{n-1}{\skeleton{n-1}}$ também é um elemento gerador, logo $f_{\partial\sigma*}\circ \delta_{n}[\celula{n}{\sigma}] = \lambda \delta_{n}\circ f_{\sigma*}[\celula{n}{\sigma}]$, para algum $\lambda \in \Lambda$. Como sempre podemos escolher um mapa caracteristico $f_{\sigma *}$ tal que $\lambda = 1$, temos $f_{\partial\sigma*}\circ \delta_{n} = \delta_{n}\circ f_{\partial\sigma*}$, e como $\delta_{*} = j_{*}\circ\delta_{n}$ então $f_{\partial\sigma*}\circ \delta_{*} = \delta_{*}\circ f_{\partial\sigma*}$. Assim, temos o operador CW-bordo
		$$
		\begin{aligned}
		\partial_{n}(\sigma) &= \Phi_{n-1}\circ\delta_{*}\circ\Psi_{n}(\sigma)
		\\
		&= \Phi_{n-1}\circ\delta_{*}\circ f_{\sigma*}([\celula{n}{\sigma}])
		\\
		&= \Phi_{n-1}\circ f_{\partial\sigma*}\circ\delta_{*}([\celula{n}{\sigma}])
		\\
		&= \Phi_{n-1}\circ f_{\partial\sigma*}\circ (j_{*}\circ \delta_{n}) ([\celula{n}{\sigma}])
		\\
		&= \Phi_{n-1} \circ f_{\partial\sigma*}([\celulabordo{n}{\sigma}])
		\\
		&= \sum_{\beta} \phi_{n-1}(p_{\beta*}\circ f_{\partial\sigma*}[\celulabordo{n}{\sigma}])\beta
		\\
		&= \sum_{\beta} \phi_{n-1}((p_{\beta}\circ f_{\partial\sigma})_{*}[S^{n-1}])\beta
		\\
		&= \sum_{\beta} \phi_{n-1}(deg(p_{\beta}\circ f_{\partial\sigma})[S^{n-1}])\beta
		\\
		&= \sum_{\beta} deg(p_{\beta}\circ f_{\partial\sigma})\phi_{n-1}([S^{n-1}])\beta
		\\
		&= \sum_{\beta} deg(p_{\beta}\circ f_{\partial\sigma})\beta,
		\end{aligned}
		$$
		como desejávamos.
	\end{prova}
	\begin{teorema}\label{teorema_cw_homologia}
		(CW-homologia) Seja $X$ um CW-complexo, então existe uma identificação natural entre a CW-homologia $\mathcal{C}_{*}(X)$ e a homologia singular $\homologia{*}{X}$, isto é 
		$$
		\homologia{k}{X} \cong \homologia{k}{\mathcal{C}_{*}(X)}\; \forall k \in \inteiros.
		$$
	\end{teorema}
	\begin{proof}
		Para a demonstração desse resultado vamos considerar a sequência 
		$$
		\xymatrix{
			\mathcal{C}_{k+1}(X) \ar[r]^{\partial_{k+1}} & \mathcal{C}_{k}(X) \ar[r]^{\partial_{k}} & \mathcal{C}_{k-1}(X).
		}
		$$
		Por definição temos $\homologia{k}{\mathcal{C}_{*}(X)} = Ker(\partial_{k})/Im(\partial_{k+1})$, e com isso provaremos que 
		$$
		Ker(\partial_{k})/Im(\partial_{k+1}) \cong \homologia{k}{X}
		$$ 
		e então concluir a equivalência entre a CW-homologia e a homologia singular do espaço topológico $X$.
		
		Tomemos a sequência longa exata vertical da tripla $(\skeleton{k+1}, \skeleton{k-1}, \skeleton{k-2})$ e a sequência longa exata horizontal da tripla $(\skeleton{k+1}, \skeleton{k}, \skeleton{k-1})$  no diagrama abaixo:
		$$
		\xymatrix{
			& & \homologiarelskele{k}{k-1}{k-2}= 0 \ar[d]^{i_{*}} &
			\\
			& & \homologiarelskele{k}{k+1}{k-2} \ar[d]^{j_{*}} &
			\\
			\homologiarelskele{k+1}{k+1}{k} \ar[r]^{\quad\delta_{1*}} &		\homologiarelskele{k}{k}{k-1} \ar[r]^{i_{*}} \ar[rd]^{\delta_{2*}} & \homologiarelskele{k}{k+1}{k-1} \ar[r]^{j_{*}} \ar[d]^{\delta_{3*}} & \homologiarelskele{k}{k+1}{k}=0
			\\
			& & \homologiarelskele{k-1}{k-1}{k-2} &
		}
		$$
		onde $i_{*}, \; j_{*}$ e $\delta_{*}$ são as inclusões induzidas e o homomorfismo conectante, respectivamente. Seja $\classe{\alpha} \in \homologiarelskelesimpl{k}{k}$, então $\delta_{3*}\circ i_{*}\classe{\alpha} = \delta_{2*}\classe{\alpha}$.
		
		Vamos agora caracterizar $Ker(\delta_{2*})$. Dado $[\alpha] \in Ker(\delta_{2*})$, então $\delta_{3*}\circ i_{*}\classe{\alpha} = \delta_{2*}\classe{\alpha} = 0$. Como $i_{*}$ é um epimorfismo e $j_{*}$ é monomorfismo, então existe um único $\classe{\beta} \in \homologiarelskele{k}{k+1}{k-2}$ tal que $i_{*} \classe{\alpha} = j_{*} \classe{\beta}$. 
		
		Afirmo que $\phi: Ker(\delta_{2*}) \to \homologiarelskele{k}{k+1}{k-2}$ dado por $\phi(\classe{\alpha}) = \classe{\beta}$ é um epimorfismo. Seja $\classe{\beta'} \in \homologiarelskele{k}{k+1}{k-2}$, então existe um $\classe{\alpha'} \in \homologiarelskele{k}{k}{k-1}$ tal que $i_{*} \classe{\alpha'} = j_{*} \classe{\beta'}$. Com isso $\delta_{2*}\classe{\alpha'} = \delta_{3*}\circ i_{*}\classe{\alpha'} = \delta_{3*}\circ j_{*}\classe{\beta'} = 0$ pois $Im(j_{*}) = Ker(\delta_{3*})$, logo $\classe{\alpha'} \in Ker(\delta_{2*})$ e $\phi$ é epimorfismo.
		
		Como $\phi$ é sobrejetor, existe $\classe{\alpha} \in Ker(\delta_{2*})$ tal que $\phi(\classe{\alpha}) = 0$. Pela comutatividade do diagrama temos $i_{*}{\classe{\alpha}} = j_{*}\classe{0} = 0$, pois $j_{*}$ é monomorfismo, portanto $\classe{\alpha} \in Ker(i_{*})$ e, pela exatidão, temos $Ker(i_{*})=Im(\delta_{1*})$, logo $\classe{\alpha} \in Im(\delta_{1*})$. Com isso podemos concluir que $Ker(\phi) = Im(\delta_{1*})$. Pelo teorema fundamental do isomorfismo de grupos temos que $Ker(\delta_{2*})/Ker(\phi) \cong \homologiarelskele{k}{k+1}{k-2}$, ou seja, $Ker(\delta_{2*})/Im(\delta_{1*}) \cong \homologiarelskele{k}{k+1}{k-2}$.
		
		Sem perda de generalidade, vamos assumir que $X$ seja um CW-complexo de ordem $n$, isto é, $X= \skeleton{n}$. Fixemos um $0 \leq j \leq n$ e tomemos o $j-$ésimo esqueleto $\skeleton{j}$ e definamos $\skeleton{-1}$. Com isso, podemos escrever a sequência de homomorfismos de inclusão de pares:
		$$
		\xymatrix{
			\homologia{k}{\skeleton{j}} = \homologiarel{k}{\skeleton{j}}{\skeleton{-1}}\ar[r]& \homologiarel{k}{\skeleton{j}}{\skeleton{0}} \ar[r] & \dots \ar[r] & \homologiarel{k}{\skeleton{j}}{\skeleton{k-2}}
		}
		$$
		onde $k-2 \leq j$ e para cada $i-$ésimo termo $\homologiarelskele{k}{j}{i}$ no centro do diagrama abaixo, teremos a sequência exata de triplas nas verticais $(\skeleton{j}, \skeleton{i}, \skeleton{i-1})$, com $0\leq i +1\leq j$ com $h_{i}$ sendo os homomorfismos de inclusão:
		$$
		\xymatrix{
			\homologiarel{k}{\skeleton{i-1}}{\skeleton{i-2}}=0 \ar[d] & \homologiarel{k}{\skeleton{i}}{\skeleton{i-1}}=0 \ar[d] & \homologiarel{k}{\skeleton{i+1}}{\skeleton{i}}=0 \ar[d] &	
			\\
			\homologiarel{k}{\skeleton{n}}{\skeleton{i-2}} \ar[d]^{h_{i-1}} & \homologiarel{k}{\skeleton{n}}{\skeleton{i-1}} \ar[d]^{h_{i}} & \homologiarel{k}{\skeleton{n}}{\skeleton{i}} \ar[d]^{h_{i+1}}
			\\
			\homologiarel{k}{\skeleton{n}}{\skeleton{i-1}} \ar[r]\ar[d]^{\delta_{(i-1)*}}& \homologiarel{k}{\skeleton{n}}{\skeleton{i}} \ar[r] \ar[d]^{\delta_{i*}} &  \homologiarel{k}{\skeleton{n}}{\skeleton{i+1}} \ar[d]^{\delta_{(i+1)*}} 
			\\
			\homologiarelskele{k-1}{i-1}{i-2}=0& \homologiarel{k-1}{\skeleton{i}}{\skeleton{i-1}}=0 &  \homologiarel{k}{\skeleton{i+1}}{\skeleton{i}}=0. &		
		}
		$$
		Do Lema \ref{homologiacelular} temos que $\homologiarelskele{k}{i}{i-1} =0$ caso $k \neq i$, logo os grupos nas extemidades verticais do diagrama serão os triviais. Pela exatidão das sequências verticais temos $Im(h_{i}) = Ker(\delta_{i*})$, mas como $Im(\delta_{i*}) = 0 \Rightarrow Ker(\delta_{i*}) = \homologiarel{k}{\skeleton{n}}{\skeleton{i}}$, logo $h_{i}$ é um epimorfismo, portanto um isomorfismo, isto é, $\homologiarel{k}{\skeleton{n}}{\skeleton{i-1}} \cong \homologiarel{k}{\skeleton{n}}{\skeleton{i}}$, o que nos pertmite escrever a cadeia de isomorfismos 
		$$
		\begin{aligned}
		\homologia{k}{\skeleton{j}} &= \homologiarel{k}{\skeleton{j}}{\skeleton{-1}} 
		\\
		&\cong  \homologiarel{k}{\skeleton{j}}{\skeleton{0}} \cong \dots \cong  \homologiarel{k}{\skeleton{j}}{\skeleton{i}} \cong  \dots \cong \homologiarel{k}{\skeleton{j}}{\skeleton{k-2}},
		\end{aligned}
		$$
		logo $\homologia{k}{\skeleton{j}} \cong \homologiarel{k}{\skeleton{j}}{\skeleton{i}}$.
		
		Por fim, como supusemos que $X = \skeleton{n}$ e a construção anterior vale para $j = n$, então $\homologia{k}{X} = \homologia{k}{\skeleton{n}} \cong \homologiarelskele{k}{n}{i}$.
		
		Assim, $\homologia{k}{X} \cong \homologiarel{k}{\skeleton{k+1}}{\skeleton{k-2}} \cong Ker(\delta_{2*})/Im(\delta_{1*})$. Mas como $\partial_{k} = \Phi_{n-1}\circ\delta_{*}\circ\Psi_{n}$, então $Ker(\delta_{2*}) \cong Ker(\partial_{k})$ e $Im(\delta_{1*}) \cong Im(\partial_{k+1})$, logo $Ker(\delta_{2*})/Im(\delta_{1*}) \cong Ker(\partial_{k})/Im(\partial_{k+1}) = \homologia{k}{\mathcal{C}_{*}}$, logo $\homologia{k}{X} \cong \homologia{k}{\mathcal{C}_{*}}$ que é a equivalência entre as homologias, como desejávamos.
	\end{proof}
	
	\begin{exemplo}
		(CW-homologia da n-esfera)
		Vamos exibir uma estrutura de CW-complexo para $S^{n}$. Para isso tomemos um ponto $p \in S^{n}$ e definamos o $0-$skeleton $\skeleton{0}=\{p\}$. Em seguida, anexemos uma $n-$célula a $\skeleton{0}$ onde $f_{\partial}: \celulabordo{n}{} \to \skeleton{0}$, isto é, $\skeleton{n} = \{p\}\cup_{f_{\partial}} \celula{n}{}$. Pelo teorema da CW-homologia temos que $\homologia{k}{S^{n}} \cong \homologiarelskelesimpl{k}{k}$, logo $\homologia{0}{S^{n}} \cong \homologiarelskelesimpl{0}{0} \cong \Lambda$, $\homologia{n}{S^{n}} \cong \homologiarelskelesimpl{n}{n} \cong \Lambda$ e $\homologia{k}{S^{n}} \cong \homologiarelskelesimpl{k}{j} =0$ caso $k \neq j$, logo
		$$
		\homologia{*}{S^{n}} = \homologia{0}{S^{n}}\oplus\homologia{n}{S^{n}} \cong \Lambda\oplus\Lambda.
		$$
	\end{exemplo}
	
	\begin{exemplo}
		(CW-homologia do 2-toro) Vamos exibir uma estrutura de CW-complexo para $T^{2}$. Para isso tomemos a identificação do toro com o quadrado cujo os lados opostos serão identificados, assim os vertices do quadrado serão um ponto $p \in T^{2}$ e definindo o $0-$skeleton $\skeleton{0} = \{p\}$, agora vamos anexar às faces do quadrado duas $1-$células, isto é, $\skeleton{1} = \skeleton{0}\cup_{f_{1\partial}}\celula{1}{1}\cup_{f_{2\partial}}\celula{1}{2}$, e por fim, cobrir o centro do quandrado anexando um $2-$célula, com isso, $\skeleton{2} = \skeleton{1}\cup_{f_{3\partial}}\celula{2}{3}$. Então
		$$
		T^{2} =\skeleton{2} = \skeleton{0}\cup_{f_{1\partial}}\celula{1}{1}\cup_{f_{2\partial}}\celula{1}{2}\cup_{f_{3\partial}}\celula{2}{3}.
		$$
		Teremos os grupos de homologia não-triviais:
		$$
		\begin{aligned}
		\homologia{0}{T^{2}} &\cong \homologiarelskele{0}{0}{-1} \cong \Lambda,
		\\
		\homologia{1}{T^{2}} &\cong \homologiarelskele{1}{1}{0} \cong \somadir{i=1,2}\homologiarelcel{1}{1}{i} \cong \somadir{i=1,2}\Lambda
		\\
		\homologia{2}{T^{2}} &\cong \homologiarelskele{2}{2}{1} \cong \Lambda.
		\end{aligned}
		$$
		Logo,
		$$
		\\
		\homologia{*}{T^{2}} = \homologia{0}{T^{2}}\oplus\homologia{1}{T^{2}} \oplus\homologia{2}{T^{2}}\cong \Lambda\oplus\Lambda\oplus\Lambda\oplus\Lambda.
		$$
	\end{exemplo}	
	
	
	\chapter{Teoria de Morse}
	Na investigação da topologia de variedades o principal objetivo é a determinação de seus invariantes topológicos, ou seja, características das variedades que são invariantes por homeomorfismos. Algumas abordagens são algébricas, tais como: a determinação de seus grupos de homotopia, seus grupos de homologia e cohomologia. Outras são diferenciais, tais como: teoremas de mergulho, transversalidade, teorema de Sard, etc. A Teoria de Morse faz uma conexão entre as duas metodologias. Através de uma função suave definida na variedade, determina-se seus pontos críticos, e através deles se constrói um $CW$-complexo cuja homologia coincide com a homologia singular da variedade, o que pode ser encontrado na Seção $\ref{secao_cw_complexo}$. O que torna a Teoria de Morse uma das construções matemáticas mais bonitas do século XX é justamente essa conexão entre as diferentes descrições.
	
	O propósito desse capítulo é de apresentação rápida do formalismo e alguns dos principais resultados para que possamos estender a construção aqui feita para a homologia de variedades de dimensão infinita (Homologia de Floer). Os detalhes das demonstrações e técnicas utilizadas podem ser encontrados em $\cite{milnor}$ e $\cite{banyaga_morse_homology}$.
	
	De agora em diante $M$ será uma n-variedade Riemanniana diferenciável fechada, onde variedade fechada será uma variedade compacta e sem bordo.
	
	\begin{comment}
		\section{Variedades Riemannianas}\label{secao_variedade_riemanniana}
		
		Parte das construções adiante utilizarão a definição de aplicação exponencial para exibir um atlas, e consequentemente, uma estrutura de variedade, para espaços de funções. Já as definições de métricas riemannianas e conexões afins aparecerão em um determinado momento, mas apenas sua citaçao será feita, portanto, caso tenha familiaridade com esse conceitos, o capítulo não se faz necessário.
		
		\begin{definicao}\label{definicao_variedade_riemanniana}
			(Variedade Riemanniana) Sejam $M$ uma n-variedade diferenciável e $g:T_{p}M \times T_{p}M \to \real{}$, um produto interno positivo-definido para todo $p \in M$, então o par $g$ é chamada de métrica Riemanniana e o par $(M, g)$ é chamado de n-variedade Riemanniana.
		\end{definicao}
		
		O conceito de conexão afim esta intimamente relacionado com a forma de comparar um campo vetorial avaliado em pontos distintos da variedade. Uma das estratégias de se efetuar essa comparação é chamada de transporte paralelo e uma boa discussão pode ser encontrada em \cite{nakahara}. Por fim, veremos que a conexão afim é uma generalização do conceito de diferenciação de uma aplicação definida no espaço euclidiano.
		
		\begin{definicao}
			(Conexão afim) Uma conexão afim $\nabla$ em uma n-variedade diferenciável é a aplicação $\nabla: \campossuaves{M} \times \campossuaves{M} \to \campossuaves{M}$ tal que, dadas $f,h \in \funcoessuaves{M}$ e $X,Y,Z \in \campossuaves{M}$:
			\begin{enumerate}
				\item $\nabla_{fX+hY}Z = f\nabla_{X}Z+h\nabla_{Y}Z$
				\item $\nabla_{X}(Y+Z) = \nabla_{X}Y+ \nabla_{X}Z$
				\item $\nabla_{X}(fY) = X(f)Y+f\nabla_{X}Y$.
			\end{enumerate}
		\end{definicao}
		
		\begin{observacao}\label{observacao_conexao_afim}
			Seja $\{\partial_{j}(p)\}$ uma base ortonormal de $T_{p}M$ onde $\partial_{j} = \partial/\partial x_{j}$. Pode-se mostrar que, dados $X=\sum X_{j}\partial_{j}, Y=\sum Y_{j}\partial_{j} \in T_{p}M$, temos:
			$$
			\begin{aligned}
			\nabla_{X}Y &= 
			\sum_{k} \Big( \sum_{ij} X(Y_{k}) + X_{i}Y_{j} \Gamma^{k}_{ij}\Big)\partial_{k} 
			\\
			&= 
			\sum_{k} \Big( \sum_{ij} X_{i} (\partial_{i}(Y_{k}) + Y_{j} \Gamma^{k}_{ij})\Big)\partial_{k} 
			\\
			&= \sum_{k} (\nabla_{X}Y)^{k}\partial_{k}.
			\end{aligned} 
			$$
			
			Temos o operador linear $\nabla_{\partial_{i}}: \campossuaves{M} \to \campossuaves{M}$ tal que $\nabla_{\partial_{i}}Y = \sum_{j}  (\partial_{i}(Y_{k}) + Y_{j} \Gamma^{k}_{ij})\partial_{k} $. Pode-se mostrar que no caso em que a n-variedade seja o $\real{n}$, então $\Gamma_{ij}^{k}=0$ para todos $1\leq i,j,k \leq n$. Suponha que $\campossuaves{\real{n}} \ni Y = f\partial_{j}$ para algum $0 \leq j \leq n$ e todas as outras componentes nula, então $\nabla_{\partial_{i}}Y = \partial_{i}(f)\partial_{j} $, isto é, a conexão afim se reduz a derivada direcional em $\real{n}$.
		\end{observacao}
		
		\begin{observacao}\label{observacao_transporte_paralelo}
			(Transporte paralelo) Um meio de comparar campos vetoriais em espaços tangentes distintos de $M$ é através do transporte paralelo. Suponha que $\gamma:[0,1] \to N$ uma curva suave e $Y \in TN$. Então o transporte paralelo de $Y \in TM$ ao longo de $\gamma$ é dado por 
			$\nabla_{\frac{d\gamma}{dt}}Y$. Mais detalhes sobre podem ser encontrados em $\cite{nakahara}$.
		\end{observacao}
		
		Dizemos um campo $X \in \campossuaves{M}$ é paralelamente transportado ao longo de uma curva $\gamma:\real{} \to M$ se $\nabla_{\gamma'}X=0$. Uma curva na variedade é chamada de geodésica se o seu campo de velocidades $v(t) = \gamma'(t)$ é paralelamente transportado ao logo dela, isto é, $\nabla_{v}v=0$, o que implica que $|v| = constante$.
		
		Seja $\gamma:[0,1] \to M$ a geodésica definida por $\gamma(t,p,v)$ tal que $\gamma(0,p,v) = p$ e $\gamma'(0,p,v) = v(p)$ com $|v|$ constante. Então o comprimento de arco de $\gamma$ é definido por 
		$$
		L(\gamma) =  \int_{0}^{1}|\gamma'|dt = \int_{0}^{1}|v|dt = |v|,
		$$
		logo $\gamma([0,1]) \subset M$ é um arco iniciado em $p \in M$ cujo comprimento é $|v|$.
		\begin{definicao}\label{definicao_aplicacao_exponencial}
			(Aplicação exponencial) Definimos $exp:U \subset TM \to M$ tal que $exp(p,v) = \gamma(1, p, v)$, onde $\gamma$ é a geodésica definida anteriormente. essa aplicação é chamada aplicação exponencial.
		\end{definicao}
		
		Restringindo a aplicação expoencial a um ponto $p \in M$ arbitrário temos $exp_{p}:T_{p}M \to M$, isto é, $exp_{p}(v)$ é um ponto de $M$ conectado a $p$ por uma geodésica cujo comprimento de arco é $|v|$. 
		
		A proposição a seguir, que pode ser encontrada em $\cite{manfredo_riemannian_geo}$, será utilizada na definição de uma aplicação exponencial para construirmos estruturas de variedade de dimensão infinita (variedade de Banach).
		
		\begin{proposicao}\label{proposicao_difeomorfismo_exponencial}
			(Difeomorfismo exponencial) Seja  $exp_{p}:T_{p}M \to M$ a aplicação exponencial anterioemente definida. Então existem $\epsilon>0$ e uma vizinhança aberta $B_{\epsilon}(0)$ do vetor nulo $0 \in T_{p}M$ tal que a restrição $exp_{p}:B_{\epsilon}(0) \to W \subset M$ é um difeomorfismo sobre algum aberto $W \subset M$.
		\end{proposicao}
		
		\begin{definicao}\label{definicao_gradiente_hessiana}
			(campo gradiente e a Hessiana) Sejam $M$ uma n-variedade diferenciável Riemanniana e $f\in \funcoessuaves{M}$. Então o gradiente de $f$ é definido como sendo o campo vetorial $\gradiente \in \campossuaves{M}$ tal que $df_{p}(v) = g(\gradiente, v)$ para todo $v \in T_{p}M$. A Hessiana de $f$ e a aplicação bilinear $H_{p}(f): T_{p}M\times T_{p}M \to \reta$ dada pelo diferencial do gradiente de $f$, isto é, $H_{p}(f) = d\gradiente(p)$.
		\end{definicao}
		
	\end{comment}
	
	\section{Teoria de Morse Clássica}\label{secao_morse_classica}
	
	\begin{definicao}
		(Função de Morse) Sejam $M$ uma n-variedade fechada, $f \in \funcoessuaves{M}$ e $\pontoscriticos{f} = \{p \in M: df_{p} = 0\}$ o conjuntos dos pontos críticos de $f$. Dizemos que $f$ é uma função de Morse se a hessiana $H_{p}(f)$ é não-degenerada para todo $p \in \pontoscriticos{f}$. O conjunto das funções de Morse definidas em $M$ será denotado por $\funcoesmorse{M}$. 
	\end{definicao}

	O índice de Morse de um dado $p \in \pontoscriticos{f}$ é a dimensão dos subespaço $V\subset T_{p}M $ tal que \ hessiana é negativa-definita, isto é, $H_{p}(f)(v,u)<0$ para todo $v,u \in V$. Denotaremos esse índice por $\lambda_{p} = dim(V)$. Como a hessiana é não-degenerada, então $H_{p}(f)$ é diagonalizável e o número de auto-valores negativos é o índice $\lambda_{p}$.
	
	\begin{lema}
		(Lema de Morse) Sejam $f \in \funcoesmorse{M}$ e $p \in \pontoscriticos{f}$ cujo índice é $\lambda_{p}$. Então existe uma carta $\{U, \phi\}$ de $p$ com $\phi(p)=0 \in \real{n}$ tal que 
		$$
		\begin{aligned}
		(f\circ \phi^{-1})(x_{1}, \dots, x_{n}) &= f(p)-x_{1}^{2}-\dots -x^{2}_{\lambda_{p}}+x^{2}_{\lambda_{p}+1}+\dots + x^{2}_{n}
		\\
		&=f(p)+x^{t}Dx,
		\end{aligned}
		$$
		onde $D$ é a representação diagonal de $H_{p}(f)$.
	\end{lema}
	
	\begin{observacao}
		Como consequência do Lema de Morse, pode-se mostrar que os ponto críticos de uma função de Morse $f \in \funcoesmorse{M}$ são isolados. Pela compacidade de $M$ tem-se que os pontos isolados são finitos.
	\end{observacao}
	
	
	A existência das funções de Morse é ilustrada pelo seguinte exemplo. Seja $f:M\to \reta$ tal que $f(x_{1}, \dots, x_{n}) = x_{n}$. Essa função é chamada de função altura e pode-se mostrar que $f$ é uma função de Morse, logo $\funcoesmorse{M} \neq \emptyset$.
	
	\begin{exemplo}
		Sejam $S^{2} \subset \real{3}$ a 2-esfera centrada na origem e $f:S^{2}\to \reta$ a função altura dadar por $f(x,y,z) = z$. Os pontos críticos de $f$ são $p_{\pm} = \{(0,0,\pm 1)\}$, cujos índices são $\lambda_{- } = 0$ e $\lambda_{+ } = 2$.
	\end{exemplo}
	
	As funções de Morse não são um caso raro nessa descrição, muito pelo contrário. O seguinte teorema garante que tais funções são abundantes no conjunto das funções suaves e tal resultado pode ser encontrado em $\cite{amyia_diff_topology}$.
	
	\begin{teorema}
		Seja $g\in \funcoessuaves{M}$. Então existe $f \in \funcoesmorse{M}$ suficientemente próxima a $g$, isto é, $\funcoesmorse{M}$ é denso em $\funcoessuaves{M}$.
	\end{teorema} 
	\begin{comment}
		
		As seguintes definições nos permitirão a definir o tipo de homotopia de variedade $M$ em termos dos pontos críticos de uma dada função de Morse $f$. A estratégia é fatiar a variedade em níveis e construirmos os $CW$-complexos homotópicos associado a cada um deles.
		
	\end{comment}
	Dado $a \in \reta$, definimos o conjunto $M^{a}= f^{-1}((-\infty, a]) = \{p \in M: f(p)\leq a\}$ como sendo o conjunto em $M$ de nível $a$. Uma consequência imediata é que, dados $a\leq b \in \reta$, então $M^{a} \subseteq M^{b}$.
	
	\begin{teorema}
		Sejam $f \in \funcoesmorse{M}$ e $a<b \in \reta$ tais que $f^{-1}([a,b])\subset M$ é um compacto e não contém pontos críticos de $f$. Então $M^{a}$ é difeomordo a $M^{b}$. Além disso, $M^{a}$ é um retrato de deformação de $M^{b}$, de modo que a inclusão  $M^{a} \hookrightarrow M^{b}$ é uma equivalência homotópica.
	\end{teorema}
	
	O seguinte teorema afirma que, fixando $a \in \reta$ e variando $t \in \reta$, se $f^{-1}([a,t]) \cap \pontoscriticos{f} \neq \emptyset$, os conjuntos de nível $M^{a}$ e $M^{t}$ não podem ser deformados um no outro.
	
	\begin{teorema}\label{teorema cw_complexo_ponto_critico_morse}
		Sejam $f\in \funcoesmorse{M}$ e $p\in \pontoscriticos{f}$ com índice $\lambda$ tal que $f(p) = c$. Suponhamos que $f^{-1}([c-\epsilon,c+\epsilon])$ seja compacto e $f^{-1}([c-\epsilon,c+\epsilon])\cap \pontoscriticos{f} = \{p\}$ para algum $\epsilon>0$. Então o conjunto de nível $M^{c+\epsilon}$ tem o mesmo tipo de homotopia de $M^{c+\epsilon}$ com uma $\lambda$-célula colada, isto é, $M^{c+\epsilon} \simeq M^{c-\epsilon}\cup_{f_{\partial}} D^{\lambda}$.
	\end{teorema}
	
	\begin{observacao}
		O teorema anterior tem como hipótese a exitência de apenas um ponto crítico em $f^{-1}([c-\epsilon,c+\epsilon])$. No caso em que $f^{-1}([c-\epsilon,c+\epsilon]) \cap \pontoscriticos{f} = \{p_{j}\}_{j=1}^{r}$, teremos $M^{c+\epsilon} \simeq M^{c-\epsilon}\cup_{f_{\partial_{1}}} D^{\lambda_{1}}\dots  \cup_{f_{\partial_{r}}} D^{\lambda_{r}}$.
	\end{observacao}
	
	\begin{observacao}
		Uma consequência imediata do teorema anterior é que, supondo $p \in \pontoscriticos{f}$ e tomando $a = f(p)$, temos que $M^{a}$ é um $CW$-complexo. 
	\end{observacao}
	
	Supondo que $M$ seja compacto e conexo, então $f(M) = [a,b] \subset \reta$ é um compacto. Suponha que $\pontoscriticos{f} = \{p_{j}\}_{j=1}^{k}$, $\lambda_{j}$ seja o índice do j-ésimo ponto crítico e que exista uma partição $t_{1} = a < t_{2}< \dots< t_{k+1} = b$ tal que $f^{-1}((t_{k}, t_{k+1})) \cap \pontoscriticos{f} = \{p_{k}\}$. Ao variarmos $t \in [a,b]$ teremos a construção do $CW$-complexo
	$$
	\begin{aligned}
	M^{t_{1}} &\simeq \{p_{1}\}
	\\
	M^{t_{2}} & \simeq \{p_{1}\} \cup_{f_{\partial_{1}}} D^{\lambda_{1}}
	\\
	\vdots&
	\\
	M = M^{t_{k+1}} &\simeq\{p_{1}\} \cup_{f_{\partial_{1}}} D^{\lambda_{1}}\dots  \cup_{f_{\partial_{k}}} D^{\lambda_{k}}.
	\end{aligned}
	$$
	
	Caso existam pontos críticos distintos com valores críticos coincidentes a mesma construção pode ser feita perturbando a função de Morse $f$ de modo a obter uma outra $f' \in \funcoesmorse{M}$ com os mesmos pontos críticos agora com valores críticos todos distintos. Essa construção é viabilizada pela densidade das funções de Morse em $\funcoessuaves{M}$.
	
	\begin{comment}
			\begin{exemplo}
			(2-toro) Seja $\phi:[0,2\pi]\times [0,2\pi] \to \real{3}$ uma parametrização do toro $T^{2}$ dada por
			$$
			\varphi(\theta, \phi) = ((1+2cos\phi)cos\theta, (1+2cos\phi)sin\theta, 2sin\phi).
			$$
			Esse é um toro centrado na origem do plano $Oy\times Ox = \{(x, y ,0) \in \real{3}\}$. Com isso, temos que o espaço tangente $T_{p}T^{2} $ é gerado por $ \{\derivadaparcialabrev{\theta}, \derivadaparcialabrev{\phi} \}|_{p}$ onde
			$$
			\begin{aligned}
			\derivadaparcialabrev{\theta} &= -(1+2cos\phi)sin\theta \derivadaparcialabrev{x}+(1+2cos\phi)cos\theta \derivadaparcialabrev{y} 
			\\
			\derivadaparcialabrev{\phi} &=  - 2sin\phi cos\theta 	\derivadaparcialabrev{x} - 2sin\phi sin\theta 	\derivadaparcialabrev{y} +2cos\phi				\derivadaparcialabrev{z}.
			\end{aligned} 
			$$
			
			
			Seja $f:T^{2} \to \reta$ a função largura $f(x,y,z)=x$. Temos que o diferencial de $f$ e $df_{p} = \derivadaparcialabrev{x}$. Com isso, dado $v \in \real{3}$ temos $df_{p}(v) = \produtointerno{\nabla f(p)}{v}  = \produtointerno{(1,0,0)}{(v_{x}, v_{y}, v_{z})} =v_{x}$. Assim, caso $df_{p}(v) = 0$ implica que $v_{x} = 0$, ou seja, os vetores dos espaços tangentes não podem ter componentes na direção $Ox$, mas basta que os elementos da base não o tenham, isto é, $sin\phi = sin\theta = 0$. Portanto, $\phi, \theta \in \{0, \pi\}$ e $\pontoscriticos{f} = \{(\pm 3,0,0), (\pm 1,0,0)\}$, de modo que $\varphi(0,0) = (3,0,0)$, $\varphi(0,\pi) = (-1,0,0)$, $\varphi(\pi,0) = (-3,0,0)$ e $\varphi(\pi,\pi) = (1,0,0)$.
			
			Temos a representação matricial da Hessiana $H_{p}(f)$
			$$
			H(\theta, \phi) = 
			\left(
			\begin{array}{cc}
			-(1+2cos\phi)cos\theta & 2sin\phi sin\theta  
			\\
			2sin\phi sin\theta   & -2cos\phi cos\theta  
			\end{array}
			\right).
			$$
			Avaliando a hessiana nos pontos críticos temos
			$$
			H(0, 0) = 
			\left(
			\begin{array}{cc}
			-3 & 0
			\\
			0& -2
			\end{array}
			\right),
			H(0, \pi) = 
			\left(
			\begin{array}{cc}
			1 & 0
			\\
			0& 2
			\end{array}
			\right)
			$$
			$$
			H(\pi, 0) = 
			\left(
			\begin{array}{cc}
			3 & 0
			\\
			0& 2
			\end{array}
			\right),
			H(\pi, \pi) = 
			\left(
			\begin{array}{cc}
			-1 & 0
			\\
			0& -2
			\end{array}
			\right)
			$$
			\vermelho{Não entendo a diferença entre os índices dos pontos críticos....!!!!!!!!!!}
			\end{exemplo}
			
	\end{comment}

	A relação entre a topologia de $M$ e os pontos críticos da função de Morse $f:M \to \reta$, originalmente foi data em termos de desigualdades, chamadas desigualdades de Morse.
	
	\begin{definicao}
		(Números de Betti) O j-ésimo número de Betti de $M$ é o inteiro $\beta_{j}(M) = dim(H_{j}(M))$, onde $H_{j}(M)$ é o j-ésimo grupo de homologia singular de $M$.
	\end{definicao}
	
	Como os grupos de homologia de $M$ são invariantes topológicos, então os números de Betti de $M$ também são.
	
	Seja $f \in \funcoesmorse{M}$. O número de pontos críticos de índice $k$ é denotado por $\nu_{k}$. Note que $\beta_{k}(M)$ contém as informações sobre a topologia da variedade, por outro lado, $\nu_{k}$ contém as informações sobre os pontos críticos de $f$.
	
	\begin{teorema}
		(Desigualdades de Morse) Sejam $f \in \funcoesmorse{M}$ e $\nu_{k}$ o número de pontos críticos de $f$ com índice de Morse $k$. Então valem as seguintes desigualdades:
		\begin{enumerate}
			\item $\beta_{k}(M) \leq \nu_{k}$ para $0\leq k\leq n$
			
			\item $\sum_{j = 0}^{k}(-1)^{k-j}\beta_{j}(M) \leq \sum_{j = 0}^{k}(-1)^{k-j}\nu_{j} $ para $0 \leq k \leq n$ e vale a igualdade para o caso em que $k=n$.
		\end{enumerate}
	\end{teorema}
	
	\begin{observacao}
		No caso da igualdade do segundo item do teorema temos a característica de Euler-Poincaré $\chi(M) = \sum_{j = 0}^{n}(-1)^{n-j}\beta_{j}(M)$, que também é um invariante topológico e é a generalização do teorema de Euler para poliedros convexos $V-A+F = 2$, onde $V$ é o número de vértices, $A$ é o número de arestas e $F$ é o número de faces.
	\end{observacao}
	
	\section{Fluxos Gradiente e Variedades de Conexão}\label{secao_fluxo_gradiente}
	Sejam $X \in \campossuaves{M}$ um campo vetorial suave em $M$ e $p \in M$. Sabe-se que existe uma curva $\gamma: \reta\to M$ que é solução do sistema de equações diferenciais 
	$$
	\derivada{\gamma(t)}{t} = X(\gamma(t)), \; \gamma(0) = p.
	$$
	Como $M$ é compacta e sem bordo, então a solução $\gamma = \gamma_{p}$ existe para todo $t\in \reta$. A aplicação $\phi: \retacartesianovariedade\to M$ definida por $\phi(t,p) = \gamma_{p}(t)$ é chamada de fluxo gerado por $X$ e, fixado $p\in M$, a curva $\gamma_{p}:\reta\to M$ é chamada de linha do fluxo de $X$. Como o fluxo $\phi$ está bem-definido para todo $t \in \reta$, então podemos efetuar a composição $\phi_{s}\circ\phi_{t}(p) = \phi(s+t, p)$ para todo $p\in M$, logo $\phi_{s}\circ\phi_{t} = \phi_{s+t}$ e $\phi_{0} = Id$.
	\begin{definicao}
		(Órbitas) A órbita de $p \in M$ pelo fluxo $\phi$ é a imagem da curva $\phi^{p} = \phi(.,p):\reta\to M$ e será denotada por $\orbitaponto{p}$. As órbitas podem ser de três categorias
		\begin{enumerate}
			\item Singular, se $\orbitaponto{p}$ = \{p\}.
			
			\item Fechada, se existe $\tau \in \reta$ tal que $\phi_{\tau+t}(p) = p$ para todo $t \in \reta$.
			
			\item Regular, quando não é singular e não é fechada.
		\end{enumerate}
		
	\end{definicao}
	
	Pela compacidade de $M$ e pela unicidade da solução do problema de valor inicial anteriormente descrito, temos que $\orbitaponto{p}\subset M$ é uma imersão injetiva quando é uma órbita regular. Vista como um subconjunto de $\real{m}$, para um inteiro $m>0$ suficientemente grande (Teorema de Megulho de Whitney $\cite{guillemin_differential_topology}$), $M$ é um conjunto limitado, logo $\orbitaponto{p}$ também é limitado. Assim, tal órbita admite pontos limites. Os conjunto $\alpha$-limite e $\omega$-limite de $p \in M$ são definidos por $\alpha(p) = \{q \in M: \phi_{t}(p) \to q, t \to -\infty\}$ e $\omega(p) = \{q \in M: \phi_{t}(p) \to q, t \to \infty\}$. O seguinte resultado sobre a topologia dos conjuntos limites é feito em $\cite{palis_dynamical_systems}$.
	
	\begin{proposicao}
		Sejam $M$ uma variedade é compacta e $X\in \campossuaves{M}$. Então para $p \in M$ tem-se que $\alpha(p)$ e $\omega(p)$ são fechados, conexos e invariantes pelo fluxo de $X$, isto é, são a união de órbitas de $X$.
	\end{proposicao}
	
	Vamos trabalhar com o campo gradiente da função de Morse $f$ pois dele podemos extrair informações sobre o comportamento dessa função. Munindo $M$ com uma métrica Riemanniana $g: T_{p}M \times T_{p}M \to \reta$, temos que $df_{p}(v) = g(\nabla f(p), v)$, onde $v \in T_{p}M$. Sejam $-\gradiente \in \campossuaves{M}$ e $\gamma$ a curva integral de $-\gradiente $ tal que $\gamma(0) = p\in M$. Então
	$$
	\begin{aligned}
	\derivada{}{t}(f \circ \gamma)(t) &= g(\gradiente(\gamma(t)), \dot{\gamma}(t)) 
	\\
	&=g(\gradiente(\gamma(t)), -\gradiente(\gamma(t))) 
	\\
	&= -\norma{\gradiente(\gamma(t))}^{2}
	\\
	&\leq 0,
	\end{aligned}
	$$
	para todo $t \in \reta$.
	
	Isso mostra que a função de Morse $f$ é decrescente ao longo das linhas de fluxo do campo gradiente negativo. Além disso, supondo que $\gamma(0) =p\in \pontoscriticos{f}$, então a desigualdade acima atinge seu maior valor em $t=0$, pois $df_{p }= 0$. Como $f$ é decrescente e atinge seu máximo em $t=0$, então a órbita $\orbitaponto{p}$ é regular e não-fechada. Em $\cite{palis_dynamical_systems}$ mostra-se que, para todo $q \in M$ tem-se que $\orbitaponto{q}$ intersecta $f^{-1}(f(q))$ transversalmente. Além disso, os pontos limites das órbitas são pontos críticos, ou seja, $\alpha(q)\cup\omega(q) \subset \pontoscriticos{f}$.
	
	Sabemos que, se $f \in \funcoesmorse{M}$, então $\pontoscriticos{f}$ é um conjunto finito. Com isso, pode-se mostrar, 
	
	\begin{lema}\label{lema_conjunto_limite_funcao_morse}
		Se 
		$p \in M$. Então $\alpha(p)  = \{q\}$ e $\omega(p) = \{r\}$ onde $q, r \in \pontoscriticos{f}$.
	\end{lema}
	
	\begin{definicao}
		(Variedades instáveis/estáveis)  As variedades instável e estável de um ponto $p \in M$ são os conjutos $\variedadeinstavel{p} = \{q\in M: \phi_{t}(q) \to p,\; t\to -\infty\}$ e $\variedadeestavel{p} = \{q\in M: \phi_{t}(q) \to p,\; t\to \infty\}$.
	\end{definicao}
	
	\begin{observacao}
		Em termos de pontos limite, podemos reescrever as variedades instáveis e estaveis de $p \in \pontoscriticos{f}$ como sendo $\variedadeinstavel{p} = \{q\in M: \alpha(q)=p\}$ e $\variedadeestavel{p} = \{q\in M: \omega(q)=p\}$.
	\end{observacao}
	
	Da observação anterior podemos afirmar que ambas as variedades instável e estável dos pontos críticos são contráteis. De fato, defina $Id: M\to M$ como sendo a aplicação identidade e $c:M\to M$ como sendo a aplicação constante $c(M) =\{p\} $, onde $p \in \pontoscriticos{f}$. Então $h:\intervalo\times \variedadeinstavel{p} \to \variedadeinstavel{p}$ tal que $h(t,q) = \phi(t/(1-t), q)$ é uma homotopia entre $Id$ e $c$, pois é contínua e $h(0, q) = Id(q)$ e $\lim_{t \to 1}h(t, q) = c(q)$ e a variedade instável é contrátil. Com uma argumento análogo mostra-se que $\variedadeestavel{p}$ é contrátil.
	
	Definimos o espaço tangente instável como sendo o subespaço $\espacotangentevariedadeinstavel\subset \espacotangentevariedade$ tal que a restrição da Hessiana $\hessiana$ a $\espacotangentevariedadeinstavel$ é negativa-definida. Analogamente temos o espaço tangente estável $\espacotangentevariedadeestavel \subset \espacotangentevariedade$, onde a Hessiana é positiva-definida. Com isso, segue o teorema da variedade estável, cuja demonstração pode ser encontrada em $\cite{banyaga_morse_homology}$.
	
	\begin{teorema}\label{teorema_variedade_instavel_estavel}
		(Teorema da variedade instável/estável) Sejam $f \in \funcoesmorse{M}$ e $p \in \pontoscriticos{f}$. Então temos a decomposição $\espacotangentevariedade=\espacotangentevariedadeinstavel\oplus\espacotangentevariedadeestavel$. Além disso, existem mergulhos suaves e sobrejetores $\espacotangentevariedadeinstavel \hookrightarrow \variedadeinstavel{p} \subseteq M$ e $\espacotangentevariedadeestavel \hookrightarrow \variedadeestavel{p} \subseteq M$. Com isso, $\variedadeinstavel{p}$ e $\variedadeestavel{p}$ são subvariedades sem bordo com dimensão $\lambda_{p}$ e $n-\lambda_{p}$, respectivamente.
	\end{teorema}
	
	\begin{observacao}
		Do mergulho teorema anterior temos que as variedades instável e estável possuem a mesma homotopia de um disco aberto cujas dimensões são $\lambda_{p}$ e $n-\lambda_{p}$, respectivamente.
	\end{observacao}

	Podemos decompor a variedade $M$ como a união disjunta das variedades instáveis ou união disjunta da variedades estáveis, o que é garantido pelo resultado a seguir.
	
	\begin{proposicao}
		Se $f \in \funcoesmorse{M}$, então
		$$
		M = \dot{\bigcup_{p \in \pontoscriticos{f}}}\variedadeestavel{p} = \dot{\bigcup_{p \in \pontoscriticos{f}}}\variedadeinstavel{p}.
		$$
	\end{proposicao}

	 O propósito das definições desse ponto em diante é a construção de um complexo de cadeias associado ao fluxo gradiente de uma função de Morse com uma propriedade adicional, que chamaremos de propriedade de transversalidade entre as variedades instáveis e estáveis.
	 
	 \begin{definicao}
	 	(Variedade Conectante e o Espaço Moduli) Sejam $f \in \funcoesmorse{M}$ e $p,q \in \pontoscriticos{f}$. A variedade conectante de $p$ e $q$ é definida por $\variedadeconectantepontos{p}{q} = \variedadeinstavel{p}\cap \variedadeestavel{q}$. Se $a = f(q)$, $b = f(p)$ e tomando $c \in (a, b) \subset \reta$ um valor regular de $f$, o espaço moduli de $p$ e $q$ é definido por $\espacomoduli{p}{q} = \variedadeconectantepontos{p}{q}\cap f^{-1}(c)$.
	 \end{definicao}
	 
	 Sejam $f: N\to M$ e $g: Z \to M$ duas aplicações suaves entre variedades diferenciáveis. Dizemos que $f$ é transversal a $g$ e denotemos $f \pitchfork g$ sempre que $f(x) = g(z) = y$ tem-se $df_{x}(\espacotangenteponto{x}{N}) + dg_{z}(\espacotangenteponto{z}{Z}) = \espacotangenteponto{y}{M} $. Se $Z \subseteq M$ e $g$ é a aplicação de inclusão, então denotaremos a transversalidade por $f\pitchfork Z$. Trataremos constatemente os casos em que $N, Z \subseteq M$ e $f$ e $g$ são as inclusões e denotaremos a transversalidade por $N \pitchfork Z$.
	 
	 \begin{definicao}
	 	(Funções de Morse-Smale) Dizemos que o gradiente de $f \in \funcoesmorse{M}$ satisfazem a condição de Morse-Smale se $\variedadeinstavel{p}\pitchfork \variedadeestavel{q}$ para todos $p,q \in \pontoscriticos{f}$. O conjuntos dessas funções é denotado por $\funcoesmorsesmale{M}$.
	 \end{definicao}
	 
	 \begin{teorema}
	 	Sejam $f\in \funcoesmorsesmale{M}$ e $p,q \in \pontoscriticos{f}$. Então a variedade conectante $\variedadeconectantepontos{p}{q}$ e o espaço moduli $\espacomoduli{p}{q}$ são vazios ou subvariedades de $M$ sem bordo cujas dimensões são $dim(\variedadeconectantepontos{p}{q}) = \lambda_{p} -\lambda_{q}$ e $dim(\espacomoduli{p}{q}) = \lambda_{p} -\lambda_{q}-1$. 
	 \end{teorema}
	 
	 \begin{proposicao}
	 	Sejam $f \in \funcoesmorsesmale{M}$ e $p,q \in \pontoscriticos{f}$.
	 	\begin{enumerate}
	 		\item Se $\lambda_{p}<\lambda_{q}$, então $\variedadeconectantepontos{p}{q} = \emptyset$,
	 		
	 		\item $\variedadeconectantepontos{p}{p} = \{p\}$
	 		
	 		\item Se $\lambda_{p} = \lambda_{q}$ e $p\neq q$, então $\variedadeconectantepontos{p}{q} = \emptyset$,
	 		
	 		\item Se $p \neq q$ tal que $\variedadeconectantepontos{p}{q} \neq \emptyset$, então $\lambda_{p}>\lambda_{q}$.
	 	\end{enumerate}
	 \end{proposicao}

	\begin{observacao}
		Uma das consequências da proposição anterior é o fato de que, dada uma função de Morse-Smale, as óbitas não-singulares do fluxo do gradiente negativo dessa função sempre partem de um ponto crítico para um outro ponto crítico de índice inferior.
	\end{observacao}
	
	\begin{proposicao}
		Sejam $f \in \funcoesmorsesmale{M}$ e $p,q \in \pontoscriticos{f}$ de índice relativo 1, isto é, $\lambda_{p} - \lambda_{q} = 1$. Então $\overline{\variedadeconectantepontos{p}{q}} = \variedadeconectantepontos{p}{q} \cup \{p,q\}$. Além disso, o número de órbitas conectando $p$ a $q$ é finito.
	\end{proposicao}

	\section{Complexo de Morse-Smale-Witten}
	
	Sejam $V$ um n-espaço vetorial, $B=\{e_{j}\}_{j=1}^{n}$ e $B'=\{e'_{j}\}_{j=1}^{n}$ duas bases ordenadas de $V$. Dizemos que $B$ e $B'$ possuem a mesma orientação se o determinante da matriz de mudança de base, $A: B \to B'$, definida por $e_{j} = \sum_{i=1}^{n}A_{ji}e'_{i}$, possui determinante positivo. 
	
	Uma orientação em um n-espaço vetorial $V$ é uma classe de equivalência entre bases ordenadas de $V$. Um espaço vetorial munido de um orientação é um espaço vetorial orientado. tal orientação pode ser positiva ou negativa, de acordo com o determinande da matriz de mudança de base for positiva ou negativa.
	
	Sejam $M$ uma n-variedade diferenciável. A n-upla ordenada $B=\{e_{j}\}_{j=1}^{n}$ é um referencial local se $B(p)=\{e_{j}(p)\}_{j=1}^{n}$ é uma base para $\espacotangenteponto{p}{M}$ ordenada para todo $p \in M$. Dizemos que $B$ é um referencial positivamente orientado se $B(p)$ é positivamente orientado para todo $p \in M$. Seja $A: B \to B'$ uma aplicação onde $A(p)$ é a matriz de mudança de base $B(p) $ para $B'(p)$. Se $det(A):M \to \reta$ for uma aplicação contínua tal que $det(A)(p) = det(A(p))>0$ para todo $p \in M$, então dizemos que $B$ possui orientação continuamente positiva. Analogamente, se tivermos $det(A)(p)<0$ diremos que $B$ possui uma orientação continuamente negativa.
	
	\begin{definicao}
		(Variedade orientável) Seja $M$ uma n-variedade diferenciável com uma referencial $B$ continuamente orientado. Então a classe de equivalência desses referenciais $o(M)$ é chamada de orientação de $M$ e dizemos que a variedade é orientável se existe uma orientção $o(M)$.
	\end{definicao}
	
	A questão de orientação de variedades e subvariedades é crucial no processo de construção do complexo de Morse-Smale-Witten.
	
	\begin{teorema}\label{teorema_orientacao_variedade_instavel}
		Sejam $f \in \funcoesmorsesmale{M}$. Fixando as orientações $o(\variedadeinstavel{p})$ para todo $p \in \pontoscriticos{f}$ tal que $\lambda_{p}>0$, então para todos $p,q \in \pontoscriticos{f}$ temos que $\variedadeconectantepontos{p}{q}$ e $\espacomoduli{p}{q}$ são variedades com orientações $o(\variedadeconectantepontos{p}{q})$ e $o(\espacomoduli{p}{q})$ induzidas pela orientação de $\variedadeinstavel{p}$.
	\end{teorema}
	
	\begin{observacao}
		Note que no teorema anterior não foi necessária a orientabilidade de $M$, mas apenas das variedades instáveis dos pontos críticos. O procedimento para a construção da orientação induzida da variedade conectante é:
		\begin{enumerate}
			\item Para cada $p\in \pontoscriticos{f}$ com $\lambda_{p}>0$ fixa-se uma orientação $o(\variedadeinstavel{p})$
			
			\item Considere um subespaço tangente $\espacotangenteponto{p}{\variedadeestavel{p}}$ com a orientação compatível com $\espacotangenteponto{p}{\variedadeinstavel{p}}$
			
			\item Como $\variedadeconectantepontos{p}{q} = \variedadeinstavel{p}\cap\variedadeestavel{q}$ e temos a transversalidade $\variedadeinstavel{p}\pitchfork\variedadeestavel{q}$, então a orientação $o(\variedadeconectantepontos{p}{q})$ é determinada pelo isomorfismo $\espacotangenteponto{x}{\variedadeinstavel{p}}\cong \espacotangenteponto{x}{\variedadeconectantepontos{p}{q}}\oplus \espacotangenteponto{x}{\variedadeestavel{q}}$, onde $x \in \variedadeconectantepontos{p}{q}$.
		\end{enumerate}
	\end{observacao}

	Sejam $M$ uma n-variedade orientável, $f \in \funcoesmorsesmale{M}$, $p,q\in \pontoscriticos{f}$ tais que $\lambda_{p}-\lambda_{q} = 1$ e $\gamma:\retacartesianovariedade\to M$ uma linha do fluxo gradiente onde 
	$$
	\derivada{}{t}\gamma(t) = -\gradiente(\gamma(t)), \; \lim_{t \to -\infty}\gamma(t) = p\;\;\text{e}\; \lim_{t \to \infty}\gamma(t) = q.
	$$
	Tomando um ponto $x \in \gamma(\reta) \subset \variedadeconectantepontos{p}{q}$, juntamente com o campo $-\gradiente$ podemos definir um referencial $B^{u}$ em $M$ tal que $\{-\gradiente(x), B^{u}(x)\}$ seja uma base de $\espacotangenteponto{x}{\variedadeinstavel{p}}$. Pelo Teorema $\ref{teorema_variedade_instavel_estavel}$ temos que $\espacotangenteponto{x}{M}=\espacotangenteponto{x}{\variedadeinstavel{p}}\oplus\espacotangenteponto{x}{\variedadeestavel{p}}$. Com isso, podemos afirmar que existe um referencial $B^{s}$ definido em $\variedadeestavel{p}$ e um referencial $B_{\gamma}$ em $\gamma(\reta)$ tal que $B_{\gamma}(x) = \{-\gradiente(x), B^{u}(x), B^{s}(x)\}$ é uma base de $\espacotangenteponto{x}{M}$.
	
	\begin{definicao}
		(Número de intersecção) Com as hipóteses descritas anteriormente, o sinal característico da órbita $\orbitaponto{x}$ é o índice $n_{x}(B_{\gamma})$ que assume os valores $\pm 1$, caso o referencial $B_{\gamma}$ tenha orientação positiva ou negativa, respectivamente. O número de intersecção é definido por 
		$$
		n(p,q) = \sum_{x \in \espacomoduli{p}{q} }n_{x}.
		$$
		
		Desse modo, o número de intersecção conta as órbitas entre p e q considerando a orientação.
	\end{definicao}
	
	\begin{definicao}
		(Complexo de Morse-Smale-Witten) Seja $f \in \funcoesmorsesmale{M}$. Para cada $p \in \pontoscriticos{f}$ assuma uma orientação $o(\variedadeinstavel{p})$. Sejam $C_{k}(f)$ o grupo abeliano livremente gerado pelos pontos críticos de índice $k$ e $C_{*}(f) =\bigoplus^{m}_{k=1}C_{k}(f)$. O homomorfismo $\partial_{k}: C_{k}(f)\to C_{k-1}(f)$ definido em cada gerador p de $C_{k}$
		$$
		\partial_{k}(p)=\sum_{q \in \pontoscriticos{f}}n(p,q)q
		$$
		é chamado operador de bordo de Morse-Smale-Witten e o par $(C_{*}(f), \partial_{*})$ é o complexo de cadeias de Morse-Smale-Witten  da função $f$.
		
	\end{definicao}
	
	O seguinte teorema é de grande importância pois afirma o isomorfismo entre a homologia do complexo de Morse-Smale-Witten e a homologia singular da variedade. Sua demonstração pode ser encontrada em $\cite{banyaga_morse_homology}$.
	
	\begin{teorema}
		(Teorema da Homologia de Morse) Sejam $f \in \funcoesmorsesmale{M}$ e o par $(C_{*}(f), \partial_{*})$ o complexo de cadeias de Morse-Smale-Witten da função $f$. Então $H_{*}((C_{*}(f), \partial_{*})) $ é isomorfo a homologia singular $ H_{*}(M, \inteiros)$.
	\end{teorema}
	
	O Teorema $\ref{teorema_cw_homologia}$ afirma que a homologia de um $CW$-complexo é isomorfa a sua homologia singular e também sabemos que a homologia de Morse é isomorfa a homologia singular da variedade. Vimos na Seção $\ref{secao_morse_classica}$ que uma n-variedade fechada possui o mesmo tipo de homotopia que de um $CW$-complexo construido a partir dos pontos críticos de uma função de Morse, logo a homologia singular dessa variedade é isomorfa a homologia do $CW$-complexo associado. Com isso, podemos afirmar que as homologias construidas via funções de Morse-Smale e funções de Morse clássicas são isomorfas.
	
	O cálculo da homologia singular de uma variedade com certas propriedades nem sempre é algo simples a se fazer. Contudo, podemos aplicar técnicas alternativas para a determinação de homologias isomorfas a homologia singular. Essa é importância dos resultados dos teoremas de isomorfismos anteriormente citados. Um outro ponto a ser comentado é o fato de que as homologias singulares são utilizadas para a descrição de alguns invariantes topológicos, por exemplo, a característica de Euler-Poicaré. Portanto, a demonstração desses isomorfismos garante que ainda estamos diantes dos mesmo invariantes topológicos.
	
	
	\chapter{Espaços Vetoriais Simpléticos}
	
	\section{Origem na Física}
	
	A mecânica clássica visa o estudo da dinâmica de sistemas físicos, conservativos ou não. Diz-se que um campo vetorial $F:\real{3} \to \real{3}$ é conservativo quando, dados dois caminhos $\gamma,\beta:[0,1] \to \real{3}$ de classe $C^{2}$ tais que $\gamma(0)=\beta(0)$ e $\gamma(1)=\beta(1)$ (com extremos fixos), temos
	$$
	\tau=\int_{\intervalo} \produtointerno{F(\gamma(t))}{\gamma'(t)}=
	\int_{\intervalo} \produtointerno{F(\gamma(t))}{\beta'(t)}.
	$$
	A grandeza $\tau$ é definida como sendo o trabalho realizado pelo campo $F$ ao longo do caminho $\gamma$. Logo, se o campo é conservativo, então o trabalho independe do caminho.
	
	Parte dos sistemas físicos conhecidos podem ser descritos via mecânica Newtoniana, cuja dinâmica é regida pela equação diferencial 
	$$
	F(t) = m\derivada{v(t)}{t} = \derivada{p(t)}{t},
	$$
	onde $v = \gamma'(t)$, $m\geq0$ constante e $p(t) = m\gamma'(t)$, este último chamado de momento linear. Suponha agora que exista uma função, chamada de energia potencial, de classe $C^{2}$ tal que $U:\real{3}\to \reta$ e $F = -\nabla U$. Tomando $q=(q_{1},q_{2}, q_{3})\in \real{3}$, então $\gamma(t)=(q_{1}(t),q_{2}(t), q_{3}(t)) = q(t)$ e podemos escrever $F(q(t)) =m \ddot{q}(t)= -\nabla U(q(t))$. Temos um sistema de 3 equações de segunda ordem, contudo, realizando uma mudança de variáveis, podemos reduzir o problema de segunda ordem para um problema de primeira ordem, do seguinte modo
	$$
	\dot{q} = \frac{p}{m} \;\; e \;\;\dot{p} = -\nabla U(q).
	$$
	
	O conjunto $Q$ das posições $q$ do sistema anterior é chamado espaço de configurações e o conjunto $P=\{(q,p): q,p\in \real{3}\}$ dos pares posição e momento linear é chamado de espaço de fases. No exemplo temos $Q=\real{3}$ e $P = \real{6}$, porém ambos podemo ser outras variedades diferenciáveis.
	
	Uma função Hamiltoniana é uma função $H:P \to \reta$ de classe $C^{1}$ tal que 
	$$
	\dot{q} = \derivadaparcial{H}{p} \;\; e \;\; \dot{p} = -\derivadaparcial{H}{q}.
	$$
	
	O sistema de equações acima é chamado de equações de Hamilton. Sabe-se que a energia total de um sistema físico conservativo é a soma das energias pontecial $E_{p} = U$ e cinética $E_{c} = p^{2}/2m$ (veja $\cite{nussenzveig}$), onde $p^{2} = \produtointerno{p}{p}$. Definamos a função Hamiltoniana associada a energia total do sistema por
	$$
	H(q,p) = E_{c} +E_{p} = \frac{p^{2}}{2m}+U(q). 
	$$
	
	Note que a função $H$ definida acima satisfaz as equações de Hamilton, logo é uma função Hamiltoniana e, por estar associada a energia total do sistema, é amplamente aplicada em modelos dinâmicos físicos.
	
	As equações de Hamilton nos dizem que, dada uma função Hamiltoniana, podemos recuperar as equações de Newton. Portanto, temos uma compatibilidade entre ambas as descrições de um problema físico.
	
	\section{Geometrização}
	
	A geometrização de problemas em física nos permite estudar os resultados obtidos sobre outro ponto de vista, e com isso, generalizar e analisar novos aspectos. Faremos o mesmo com a descrição Hamiltoniana, de modo que definiremos objetos utilizados adiante na análise da topologia de uma categoria específica de variedades diferenciáveis.
	
	Sejam $Q= \real{n}$ e $P=\real{2n}$ os espaços de configurações e fase, respectivamente. Por simplicidade vamos utilizar a notação $(q, p ) = (q_{1}, \dots ,q_{n}, p_{1}, \dots ,p_{n}) \in \real{2n}$. Desse modo,  temos o espaço tangente $T_{(q_{0},p_{0})} P = span\{\partial_{q_{1}}, \dots, \partial_{q_{n}}, \partial_{p_{1}}, \dots, \partial_{p_{n}}\}=span\{\partial_{q}, \partial_{p}\}$, onde $\partial_{q_{j}} = \partial/\partial_{q_{j}}$ e $\partial_{p_{j}} = \partial/\partial_{p_{j}}$ avaliados no ponto $(q_{0}, p_{0})$. 
	
	Seja $H:P \to \reta$ uma função Hamiltoniana de classe $C^{\infty}$. O gradiente Hamiltoniano é dado por
	$$
	\nabla H =\sum_{j=1}^{n}\derivadaparcial{H}{q_{j}}\derivadaparcial{}{q_{j}} + \derivadaparcial{H}{p_{j}}\derivadaparcial{}{p_{j}} = \derivadaparcial{H}{q}\derivadaparcialabrev{q} + \derivadaparcial{H}{p}\derivadaparcialabrev{p}.
	$$
	
	Definimos o campo Hamiltoniano $\campohamiltonianoabrev \in \campossuaves{\real{2n}}$ por 
	$$
	\campohamiltonianoabrev = -\estruturacomplexa \nabla H = \sum_{j=1}^{n}\derivadaparcial{H}{p_{j}}\derivadaparcial{}{q_{j}} - \derivadaparcial{H}{q_{j}}\derivadaparcial{}{p_{j}} = \derivadaparcial{H}{p}\derivadaparcialabrev{q} - \derivadaparcial{H}{q}\derivadaparcialabrev{p}, 
	$$
	onde
	$$
	\estruturacomplexa=
	\left(
	\begin{array}{cc}
	0 & -Id
	\\
	Id & 0
	\end{array}
	\right), 
	$$
	isto é, $\estruturacomplexa \derivadaparcialabrev{q} = \derivadaparcialabrev{p}$ e $\estruturacomplexa \derivadaparcialabrev{p} = -\derivadaparcialabrev{q}$.
	
	Vejamos que o campo Hamiltoniano representa um campo conservativo. Seja $\psi:P\times \reta \to P$ o fluxo do campo $\campohamiltonianoabrev$ tal que $\psi(t) = (q(t), p(t))$. Então as equações de Hamilton podem ser reescritas como 
	$$
	\begin{aligned}
	\dot{\psi}(t) &= \campohamiltoniano{\psi(t)}
	\\
	\left(
	\begin{array}{c}
	\dot{q}(t)
	\\
	\dot{p}(t)
	\end{array}
	\right)
	&=
	\left(
	\begin{array}{c}
	\derivadaparcial{H(t)}{q}
	\\
	-\derivadaparcial{H(t)}{p}
	\end{array}
	\right).
	\end{aligned}
	$$	
	
	Afirmo que, ao longo do fluxo $\psi$, o sistema Hamiltoniano é conservativo, isto é, a energia total do sistema é constante. De fato
	
	$$
	\begin{aligned}
	\derivada{}{t}H(\psi(t)) 
	&= \produtointerno{\nabla H}{\dot{\psi}(t)} 
	\\
	&= \produtointerno{\nabla H}{\campohamiltoniano{\psi(t)}} 
	\\
	&= 
	-\produtointerno{\nabla H}{\estruturacomplexa \nabla H(t)} 
	\\
	&=-\produtointerno{\derivadaparcial{H}{p}\derivadaparcialabrev{q} - \derivadaparcial{H}{q}\derivadaparcialabrev{p}
	}{\derivadaparcial{H}{p}\estruturacomplexa\derivadaparcialabrev{q} - \derivadaparcial{H}{q}\estruturacomplexa\derivadaparcialabrev{p}}
	\\
	&=-\derivadaparcial{H}{p}^{2}\produtointerno{\derivadaparcialabrev{q}
	}{\derivadaparcialabrev{p}}	-\derivadaparcial{H}{p}\derivadaparcial{H}{q}\produtointerno{\derivadaparcialabrev{q}}{\derivadaparcialabrev{q}}
	+\derivadaparcial{H}{p}\derivadaparcial{H}{q}\produtointerno{\derivadaparcialabrev{p}}{\derivadaparcialabrev{p}}	+\derivadaparcial{H}{q}^{2}\produtointerno{\derivadaparcialabrev{q}}{\derivadaparcialabrev{p}}
	\\
	&=0.
	\end{aligned}
	$$
	
	Defina $\formaSimpleticaabrev :T_{(q,p)} P \times T_{(q,p)} P \to \reta$ tal que $\formaSimpleticaabrev(v, u) = -V^{t}\estruturacomplexa U$, onde $V, U$ são as  representações matricias desses campos vetoriais no ponto $(q,p)$. Afirmo que $\formaSimpleticaabrev$ é bilinear anti-simétrica e não degenerada, isto é, dado $(q,p) \in P$ se $\formaSimpleticaPadrao{v}{y} = 0$ para todo $y \in T_{(q,p)} P$, então $v = 0$. De fato, dados $x \in T_{(q,p)} P$ e $\lambda \in \reta$, teremos $\formaSimpleticaPadrao{v + \lambda x}{u} = -(V+\lambda X)^{t}\estruturacomplexa U = -V^{t}\estruturacomplexa U -\lambda X^{t}\estruturacomplexa U = \formaSimpleticaPadrao{v}{u} + \lambda\formaSimpleticaPadrao{x}{u}$. Com um argumento análogo podemos mostrar que $\formaSimpleticaPadrao{v}{u + \lambda x} =\formaSimpleticaPadrao{v}{u} + \lambda\formaSimpleticaPadrao{v}{x} $. Portanto $\formaSimpleticaabrev$ é bilinear. É anti-simétrica pois $\formaSimpleticaPadrao{v}{u} = -V^{t}\estruturacomplexa U = -(\estruturacomplexa^{t} V)^{t}U = -U^{t}(\estruturacomplexa^{t} V)= U^{t}(\estruturacomplexa V) = -\formaSimpleticaPadrao{u}{v}$, onde usamos $\estruturacomplexa^{t} = -\estruturacomplexa$. Seja $I_{j}$ uma matriz $2\times 1$ com a j-ésima entrada igual a 1 e as outras nulas. Com isso, temos que $\estruturacomplexa I_{j+n} = -I_{j}$ e $\estruturacomplexa I_{j} = I_{j+n}$. Suponha que $v = v_{j}\derivadaparcialabrev{q_{j}}$ tal que $\formaSimpleticaPadrao{v}{e} = 0$ para todo $e$ elemento da base de $T_{(q,p)} P$. Então, fazendo $e= \derivadaparcialabrev{p_{j}}$ teremos $0= v_{j}\formaSimpleticaPadrao{\derivadaparcialabrev{q_{j}}}{\derivadaparcialabrev{p_{j}}} = -v_{j}I_{j}^{t}\estruturacomplexa I_{j+n} = v_{j}I_{j}^{t}I_{j}=v_{j}$, portanto $v_{j} = 0$. Repetindo a mesma construção para $1\leq j \leq n$ podemos concluir que $\formaSimpleticaPadrao{v}{u} = 0$ para todo $u$, então $\Omega$ é não-degenerada.
	
	Vejamos que nessa base temos $\formaSimpleticaPadrao{\derivadaparcialabrev{q_{j}}}{\derivadaparcialabrev{q_{k}}} = -I_{j}^{t}\estruturacomplexa I_{k} = -I_{j}^{t}I_{k+n} = 0$. Analogamente, $\formaSimpleticaPadrao{\derivadaparcialabrev{p_{j}}}{\derivadaparcialabrev{p_{k}}} = 0$. Por fim, $\formaSimpleticaPadrao{\derivadaparcialabrev{q_{j}}}{\derivadaparcialabrev{p_{k}}} = -I_{j}^{t}\estruturacomplexa I_{k+n} = I_{j}^{t}I_{k} = \delta_{jk}$. Assim, de forma equivalente, podemos escrever $\formaSimpleticaabrev = \sum_{j}  dq_{j}\wedge dp_{j}$, logo
	$$
	\begin{aligned}
	\formaSimpleticaPadrao{\campohamiltonianoabrev}{v} 
	&= \sum_{j}  dq_{j}\wedge dp_{j}(\campohamiltonianoabrev, v) 
	\\
	&= \sum_{j}  dq_{j}(\campohamiltonianoabrev)dp_{j}(v) - dq_{j}(v)dp_{j}(\campohamiltonianoabrev)
	\\
	&= \sum_{j} \derivadaparcial{H}{p_{j}}dp_{j}(v) + dq_{j}(v)\derivadaparcial{H}{q_{j}}
	\\
	&= \Big(\sum_{j} \derivadaparcial{H}{q_{j}}dq_{j} +\derivadaparcial{H}{p_{j}}dp_{j} \Big)(v)
	\\
	&= dH(v).
	\end{aligned}
	$$
	
	Definimos um espaço de fase $P$ e em cada ponto do espaço tangente de $P$ temos uma forma bilinear anti-simetrica e não-degenerada $\formaSimpleticaabrev$, chamada forma simplética. Com isso, o par $(T_{(q,p)}P, \formaSimpleticaabrev)$ é chamado 2n-espaço vetorial simplético, onde $dim(T_{(q,p)}P) = 2n$. A seção seguinte é dedicada ao estudo de espaços vetoriais simpléticos reais.
	
	\section{Espaços Vetoriais Simpléticos}
	\begin{definicao}
		(Espaço vetorial simplético) Sejam $V$ um 2n-espaço vetorial real e uma forma bilinear anti-simétrica $\omega$ em $\Lambda^{2}(V, \real{})$ tal que $\omega(u,v) = 0 \; \forall v \in V \Rightarrow u=0$. Então dizemos que $\omega$ é não-degenerada e o par $(V, \omega)$ é chamado de 2n-espaço vetorial simplético.
	\end{definicao}
	
	\begin{definicao}
		(Base simplética) Seja $(V, \omega)$ um 2n-espaço vetorial simplético, então uma base simplética é uma base $\{ e_{1},\dots, e_{n},f_{1},\dots f_{n}\}$ de $V$ tal que valem as relações:
		$$
		\omega(e_{i}, e_{j}) = \omega(f_{i}, f_{j}) = 0, \; \omega(e_{i}, f_{j}) = \delta_{ij}.
		$$
	\end{definicao}
	
	\begin{definicao}
		(Simplectomorfismo) Dois espaços vetoriais simpléticos $(V_{1}, \omega_{1}), (V_{2}, \omega_{2})$ são ditos simplectomorfos se existe um isomorfismo $\varphi:V\to W$ que preserva a forma simplética, isto é, $\varphi^{*}\omega_{2} = \omega_{1}$.
	\end{definicao}
	\begin{exemplo}\label{exemplo_espaco_simpletico_real}
		Seja $V = \real{2}$, $\{e_{x}, e_{y}\}$ uma base de $V$ e $w=dx \wedge dy$. Então $\omega(e_{x}, e_{y}) = (dx \wedge dy)(e_{x}, e_{y}) = dx\otimes dy(e_{x}, e_{y})-dy\otimes dx(e_{x}, e_{y}) =dx(e_{x}) dy(e_{y}) - dx(e_{y}) dy(e_{x}) = 1-0= 1$. Por outro lado, $\omega(e_{y}, e_{x}) =dx(e_{y}) dy(e_{x}) - dx(e_{x}) dy(e_{y}) =-1 =-\omega(e_{x}, e_{y})$, logo é anti-simetrica. Além disso, $\omega(e_{x}, e_{x}) = \omega(e_{y}, e_{y}) = 0$. Fixando $v \in V$ e para qualquer $u \in V$ temos que $\omega(v, u) = \omega(v_{x}e_{x}+v_{y}e_{y}, u_{x}e_{x}+u_{y}e_{y}) = v_{x}u_{y}\omega(e_{x}, e_{y}) +v_{y}u_{x}\omega(e_{y}, e_{x}) = v_{x}u_{y} -v_{y}u_{x} = 0$ se, e somente se, $v_{x}=v_{y}=0$, logo $\omega$ é não-degenerada. Para ver isso basta tomar $u_{x} = 1$ e $u_{y} = 0$, isso implica que $v_{y} = 0$. Fazendo $u_{x} = 0$ e $u_{y} = 1$ teremos $v_{x} = 0$, logo $v=0$. Seja $\varphi:V \to V$ tal que $\varphi(v) = -v$. Como $\varphi$ é um operador de reflexão, então é um isomorfismo. Definido $\varphi^{*}\omega(v, u) = \omega(Av, Au)$, então $\varphi^{*}\omega(v, u) = \omega(Av, Au)=\omega(-v, -u)=\omega(v, u)$, logo $\varphi^{*}\omega = \omega$ e $\varphi$ é um simplectomorfismo.
	\end{exemplo}
	
	\begin{definicao}\label{definicao_subespaco_simpletico_ortogonais}
		(Espaços $\omega$-ortogonais) Seja $(V, \omega)$ um 2n-espaço vetorial simplético e $W\subseteq V$ um subespaço vetorial simplético. Então o complemento $\omega$-ortogonal de $W$ é o subespaço vetorial simplético
		$$
		W^{\omega} = \{v\in V: \omega(v,u) = 0,\;\forall u\in W \}.
		$$
		Além disso, $W$ pode ser classificado de acordo com as seguintes características
		\begin{enumerate}
			\item \text{Simplético}, se $W\cap \espacoSimpleticoOrtogonal{W} = \{0\}$
			\item \text{Isotrópico}, se $W \subseteq \espacoSimpleticoOrtogonal{W}$
			\item \text{Coisototrópico}, se $W\supseteq \espacoSimpleticoOrtogonal{W}$
			\item \text{Lagrangiano}, se $W =\espacoSimpleticoOrtogonal{W}$
		\end{enumerate}
	\end{definicao}
	
	\begin{lema}\label{lema_subespaco_simpletico_ortogonal}
		(Caracterização de subespaço simplético)
		\begin{enumerate}
			\item Se $W$ for simplético, então $(W, \omega|_{W})$ é um espaço vetorial simplético.
			
			\item Se $W$ for isotrópico, então $\omega|_{W\times W} = 0$.
			
			\item Se $W$ for lagrangiano, então $W$ é isotrópico e máximal, isto é, não esta contido propriamente em nenhum outro subespaço isotrópico. 
		\end{enumerate}
	\end{lema}
	\begin{prova}
		\begin{enumerate}
			\item Supondo que $\omega|_{W}$ seja degenerada, então existe $0\neq v \in W$ tal que $\omega(v, u ) = 0$ para todo $u \in W$, o que implica que $u \in W\cap W^{\omega}$, contradizendo a hipótese $W\cap W^{\omega} =0$. Logo $\omega|_{W } $ é não-degenerada e $(W, \omega|_{W})$ é um espaço vetorial simplético.
			
			\item Dado $0\neq v \in W $ , então $\omega(v,u) = 0$ para todo $u \in W\cap W^{\omega} = W$. Portanto $\omega|_{W\times W}: W\times W \to \reta$ é a aplicação nula.
			
			\item  Como $W=W^{\omega}$, então $W\subseteq W^{\omega}$, logo $W$ é isotrópico. Seja $U \subseteq V$ um subespaço isotrópico tal que $W \subseteq U$. Então, pelo item anterior, $\omega|_{U\times U} = 0$, logo dado $v \in W \cap U$ e para todo $u \in U$, temos $\omega(v, u) = 0$, implicando $u \in W^{\omega}$. Portanto, $U = W^{\omega} = W$.
		\end{enumerate}
	\end{prova}
	
	Não há garantias de que sempre tenhamos $V = W + \espacoSimpleticoOrtogonal{W}$. Contudo, a proposição a seguir nos dá uma relação entre as dimensões desses dois espaços vetoriais.
	
	\begin{lema}\label{lema_isomorfismo_forma_simpletica}
		Seja $(V,\omega)$ um 2n-espaço vetorial simplético. A aplicação $\omega^{*}:V\to V^{*}$ definida por $\omega^{*}(v)(u) = \omega(v,u)$ é um isomorfismo.
	\end{lema}
	\begin{prova}
		Dado $v \in V$, temos pela bilinearidade de $\omega$ que $\omega^{*}(v)$ é linear, logo $\omega^{*}(v) \in V^{*}$. Além disso, $w^{*}$ é injetora pois, suponha 
		que exista $v\neq 0 \in V$ tal que $\omega^{*}(v) = 0$. Com isso, temos $0= \omega^{*}(v)(u) = \omega(v,u)$ para todo $u \in V$, o que é contradição, pois $\omega$ é não-degenerada, logo $v =0$ e $\omega^{*}(0) = 0$. Portanto $\omega^{*}$ é injetora. Seja $\colecaofinita{e}{2n}$ uma base de $V$. Denotando $b^{*}_{j}$ por $\omega^{*}(e_{j}) \in V^{*}$ temos pela injetividade que $b^{*}_{j} \neq b^{*}_{i}$ para todos $1\leq j,i\leq 2n$. Suponha que $\colecaofinita{b^{*}}{2n}$ seja linearmente dependente. Com isso, existem $\colecaofinita{\lambda}{2n} \subset \reta$ nem todos nulos tais que $0=\sum_{j=1}^{2n}\lambda_{j}b^{*}_{j} = \sum_{j=1}^{2n}\lambda_{j}\omega^{*}(e_{j}) = \omega^{*}(\sum_{j=1}^{2n}\lambda_{j}e_{j})$. Pela injetividade de $\omega^{*}$ devemos ter que $\sum_{j=1}^{2n}\lambda_{j}e_{j} = 0$, contradizendo a hipótese de que $\colecaofinita{e}{2n}$ é uma base de $V$. Portanto, $\colecaofinita{b^{*}}{2n}$ é uma base de $V^{*}$ e $\omega^{*}$ é sobrejetor, logo é um isomorfismo.
	\end{prova}
	
	\begin{proposicao}
		Sejam $(V,\omega)$ um 2-espaço vetorial simplético e $W \subseteq V$ um subespaço vetorial. Então $dim(V) = dim(W) + dim(\espacoSimpleticoOrtogonal{W})$.
	\end{proposicao}
	\begin{prova}
		Seja $\omega^{*}: V \to V^{*}$ tal que $\omega^{*}(v)(u) = \omega(v,u)$. Pelo Lema $\ref{lema_isomorfismo_forma_simpletica}$ $\omega^{*}$ é um isomorfismo.. Seja $W^{\circ}=\{f\in W^{*}: f(v) = 0,\; \forall v\in W \}$ o anulador de $W$. Tomando $f \in \omega^{*}(\espacoSimpleticoOrtogonal{W})$ temos $f(u) = \omega^{*}(v)(u)=\omega(v,u)$, para algum $v \in \espacoSimpleticoOrtogonal{W}$. Se $u\in W$, então $f(u) = 0$. Portanto $f \in W^{\circ}$ e  $\omega^{*}(\espacoSimpleticoOrtogonal{W})\subseteq W^{\circ}$. Por outro lado, seja $f \in W^{\circ}$. Como $\omega^{*}$ é um isomorfismo, então existe $v \in v$ tal que $f = \omega^{*}(v)$, logo $0=f(u) = \omega^{*}(v)(u) = \omega(v,u)$ para todo $u \in W$, o que implica que $v \in \espacoSimpleticoOrtogonal{W}$. Portanto, $f \in \omega^{*}(\espacoSimpleticoOrtogonal{W})$ e $W^{\circ} \subseteq \omega^{*}(\espacoSimpleticoOrtogonal{W})$. Logo $W^{\circ} =\omega^{*}(\espacoSimpleticoOrtogonal{W})$.
		Como $\omega^{*}$ é um isomorfismo, então $dim(\espacoSimpleticoOrtogonal{W}) = dim(\omega^{*}(\espacoSimpleticoOrtogonal{W}))$. Temos que 
		$$
		dim(V) = dim(W)+dim(W^{\circ}) = dim(W)+dim(\omega^{*}(\espacoSimpleticoOrtogonal{W})) = dim(W)+dim(\espacoSimpleticoOrtogonal{W}).
		$$ 
	\end{prova}
	
	\begin{teorema}\label{teorema_existencia_base_simpletica}
		(Existência de base simplética) Todo espaço vetorial simplético de dimensão finita possui uma base simplética.
	\end{teorema}
	\begin{prova}
		Sejam $(V, \omega)$ um 2n-espaço vetorial simplético e $e_{1} \neq 0\in V$. Como $\omega$ é não-degenerada, então existe $f_{1} \in V$ tal que $\omega(e_{1}, f_{1}) = 1$. Definindo $V_{1} = span\{e_{1}, f_{1}\}$, podemos afirmar que $V_{1}$ é simplético, logo $V = V_{1}\oplus V_{1}^{\omega}$. Efetuando o mesmo procedimento n vezes teremos $V = V_{1}\oplus \dots \oplus V_{n}$, onde $V_{i}$ é gerado por $e_{i}$ e $\omega(e_{i}, f_{i}) = 1$. Por construção temos $\omega(e_{i}, e_{j})=\omega(f_{i}, f_{j}) =0$ e $\omega(e_{i}, f_{j}) = \delta_{ij}$. Portanto, $\{e_{1}, \dots e_{n}, f_{1}, \dots f_{n}\}$ é uma base simplética.
	\end{prova}
	
	\begin{observacao}\label{observacao_existencia_base_simpletica}
		A existência de uma base simplética garante a existência de uma base em que a forma simpléctica $\omega$ poderá ser representada pela matriz
		$$
		(\omega_{ij}) =\left(
		\begin{array}{cc}
		0 & Id
		\\
		-Id & 0
		\end{array}
		\right).
		$$
	\end{observacao}
	
	\begin{teorema}
		Seja $V$ um 2n-espaço vetorial, então existe uma base $\{ e_{1},\dots, e_{n}, f_{1},\dots, f_{n}\}$ de $V$ e uma base $\{e_{1}^{*}, \dots, e_{n}^{*}, f_{1}^{*}, \dots,f_{n}^{*}\}$ de $V^{*}$ tal que dado $\alpha \in \Lambda^{2}(V)$ pode-se escrever $\alpha = \sum_{i=1}^{n} e^{*}_{i}\wedge f^{*}_{i}$.
	\end{teorema}
	\begin{prova}
		Seja $\alpha\neq 0\in \Lambda^{2}(V) $, então existem $ a_{1}, a_{1+n} \in V $ tais que $\alpha(a_{1}, a_{1+n}) = \alpha_{1} \neq 0$. Definindo $e_{1} = a_{1}/\alpha_{1}$ e $a_{1+n} = f_{1}$ teremos $\alpha(e_{1}, f_{1}) = 1$, e pela anti-simetria temos $\alpha(e_{1}, e_{1}) = \alpha(f_{1}, f_{1}) = 0$. Definindo $B_{1}=span \{e_{1}, f_{1}\}$, então a matriz $(\alpha_{ij})$ de $\alpha|_{B_{1}}$ é
		$$
		\left(
		\begin{array}{cc}
		0 & 1
		\\
		-1 & 0
		\end{array}
		\right)
		$$
		Seja  $V_{2} = \{v \in V: \alpha(v, b) = 0,\; b \in B_{1}\}$, então por construção temos $B_{1} \cap V_{2} = 0$. Como $B_{1}, V_{2} \subseteq V$ são subespaços vetoriais então $V = B_{1}\oplus V_{2}$. Dado $v \in V$ temos $v_{2} =v- \alpha(v,f_{1})e_{1} +\alpha(v,e_{1})f_{1} \in V_{2}$ pois $\alpha(v_{2}, e_{1}) = \alpha(v_{2}, f_{1}) = 0$. Repetindo a construção para $V_{2}$ podemos afirmar que existem $e_{2}, f_{2} \in V_{2}$ tais que $\alpha(e_{2}, f_{2}) = 1$, $\alpha(e_{2}, e_{2}) = \alpha(f_{2}, f_{2}) = 0$, $B_{2} = span\{e_{2}, f_{2} \}$ e $V_{3} \subset V_{2}$ tal que $B_{2}\cap V_{3}=0$, onde a matriz $(\alpha_{ij})$ de $\alpha|_{B_{2}}$ é da mesma forma que a matriz de $\alpha|_{B_{1}}$. Realizando uma indução finita na construção dos planos $B_{j}$ teremos $V = \bigoplus_{j=1}^{n}B_{j}$, logo a matriz de $\alpha$ na base  $\{ e_{1},\dots, e_{n}, f_{1},\dots, f_{n}\}$ é
		$$
		\left(
		\begin{array}{cc}
		0 & Id
		\\
		-Id & 0
		\end{array}
		\right)
		$$
		Definindo a base dual $\{e_{1}^{*}, \dots, e_{n}^{*}, f_{1}^{*}, \dots,f_{n}^{*}\}$ de $V^{*}$ teremos $\alpha = \sum_{j=1}^{n}e_{j}^{*}\wedge f_{j}^{*}$.
	\end{prova}
	
	\begin{lema}
		(Caracterização da forma simplética) Sejam $V$ um 2n-espaço vetorial, então $\omega \in \Lambda^{2}(V)$ é uma forma simplética se, e somente se, $\omega^{\wedge n} = \omega\wedge \dots \wedge \omega \in \Lambda^{2n}(V)$ é não-nula.
	\end{lema}
	\begin{prova}
		Suponha $\omega$ uma forma simplética. O Teorema $\ref{teorema_existencia_base_simpletica}$ garante a existência de uma base simplética $\{e_{1}, \dots, e_{n}, f_{1}, \dots, f_{n}\}$ de $V$. Pela bilinearidade de $\omega$ basta analisarmos $\omega$ nos elementos dessa base. Considerando $\sigma$ no conjunto das permutações de $\{1, 2, \dots , 2n\}$ temos
		$$		
		\begin{aligned}
		\omega^{\wedge n}(e_{1}, \dots, e_{n}, f_{1}, \dots, f_{n}) &=\sum_{\sigma} \omega(e_{1}, f_{\sigma(1)})...\omega(e_{n}, f_{\sigma(n)})
		\\
		&= \sum_{\sigma}\delta_{1\sigma(1)}\dots\delta_{n\sigma(n)}
		\\
		&= \delta_{11}\dots\delta_{nn}
		\\
		&= 1.
		\end{aligned}
		$$
		Por outro lado, se $\omega^{\wedge n} \neq 0$, suponha que $\{v_{1},\dots, v_{2n}\}$ seja uma base de $V$ e que exista $v =\sum a_{j}v_{j} \neq 0$ tal que $\omega(v, u) = 0$ para todo $u=\sum b_{j}v_{j}  \in V$. Então, $0=\omega(v, u ) = \sum_{j, k} a_{j}b_{k}\omega(v_{j}, v_{k})$, o que implica em $\omega(v_{j}, v_{k}) =0$. Então 
		$$
		\omega^{\wedge n}(v_{1},\dots, v_{2n}) = \sum_{\sigma} \omega(v_{1}, v_{\sigma(1)})...\omega(v_{2n}, v_{\sigma(2n)})=0,
		$$
		contradizendo a hipótese $\omega^{\wedge n} \neq 0$. Logo, $\omega$ é não-degenerada.
	\end{prova}
	
	\begin{proposicao}\label{proposicao_preservacao_volume}
		(Preservação do volume) Sejam $(V,\omega)$ um 2n-espaço vetorial simplético e $\varphi:V\to V$ um simplectomorfismo, então $\varphi^{*}\omega^{\wedge n}=\omega^{\wedge n}$ e $det(\varphi)=1$.
	\end{proposicao}
	\begin{prova}
		Seja $\varphi:V \to V$ um simplectomorfismo, então $\varphi^{*}\omega = \omega$, e portanto
		$$
		\begin{aligned}
		\varphi^{*}\omega^{\wedge n} 
		&= 
		\varphi^{*}(\omega\wedge \dots \wedge\omega) 
		\\
		&= \varphi^{*}\omega\wedge \dots \wedge\varphi^{*}\omega
		\\
		&=\omega\wedge \dots \wedge \omega 
		\\
		&= \omega^{\wedge n}.
		\end{aligned} 
		$$
		Aplicando esse resultado veremos que
		$$
		\begin{aligned}
		\omega^{\wedge n}(e_{1}, \dots,e_{n}, f_{1},\dots, f_{n})
		&=(\varphi^{*}\omega^{\wedge n})(e_{1}, \dots, e_{n}, f_{1},\dots, f_{n})
		\\
		&=
		\omega^{\wedge n}(\varphi e_{1}, \dots,\varphi  e_{n}, \varphi f_{1},\dots, \varphi f_{n})
		\\
		&=det(\varphi)\omega^{\wedge n}(e_{1}, \dots, e_{n}, f_{1},\dots, f_{n}),
		\end{aligned}
		$$
		portanto $det(\varphi) = 1$.
	\end{prova}
	
	
	\begin{definicao}\label{definicao_transformacao_simpletica}
		(Transformação simplética) Seja $(V, \omega)$ um 2n-espaço vetorial simplético sobre $\reta$. Um operador linear $T: V \to V$ é uma transformação simplética se 
		$$
		\formaSimpletica{Tu}{Tv} = \formaSimpletica{u}{v}
		$$ para todo $u,v\in V$.
	\end{definicao}
	
	\begin{definicao}\label{definicao_grupo_simpletico}
		(Grupo simplético) O grupo simplético $\gruposimpletico{V} \subset \generalgroupreal{2n}$ de $V$ é o conjunto das matrizes associadas as transformações simpléticas definidas em $V$.
	\end{definicao}
	
	\begin{exemplo}
		(Rotações em $\real{2}$) Vimos no Exemplo $\ref{exemplo_espaco_simpletico_real}$ que $(\real{2}, \omega)$ é um espaço vetorial simpletico, onde $\omega = dx\wedge dy$ e a base canônica $\{e_{x}, e_{y}\}$ é uma base simplética. Seja $R(\theta):\real{2}\to \real{2}$ uma rotação de um ângulo $\theta$, isto é, dado $v= v_{x}e_{x}+v_{y}e_{y} \in V$, temos $R(\theta)v = (v_{x}\cos(\theta)-v_{y}\sin(\theta))e_{x}+(v_{x}\sin(\theta)+v_{y}\cos(\theta))e_{y} = v'_{x}e_{x}+v'_{y}e_{y}$. Então
		$$
		\begin{aligned}
			\formaSimpletica{R(\theta)u}{R(\theta)v}&=
			\formaSimpletica{u'_{x}e_{x}+u'_{y}e_{y}}{v'_{x}e_{x}+v'_{y}e_{y}}
			\\
			&=u'_{x}v'_{y}\formaSimpletica{e_{x}}{e_{y}}	+u'_{y}v'_{x}\formaSimpletica{e_{y}}{e_{x}}
			\\
			&=(u_{x}\cos(\theta)-u_{y}\sin(\theta))(v_{x}\sin(\theta)+v_{y}\cos(\theta))
			\\
			&\;\;\;\;\;- (u_{x}\sin(\theta)+u_{y}\cos(\theta))(v_{x}\cos(\theta)-v_{y}\sin(\theta))
			\\
			&=u_{x}v_{y}-u_{y}v_{x}
			\\
			&=\formaSimpletica{u_{x}e_{x}}{v_{y}e_{y}} - \formaSimpletica{u_{y}e_{y}}{v_{x}e_{x}}
			\\
			&=\formaSimpletica{u}{v}.
		\end{aligned}
		$$
		Portanto, $R(\theta)$ é uma transformação simplética para todo $\theta \in \reta$.
	\end{exemplo}
	
	\section{$\estruturascomplexaspadrao$ e sua topologia}
	
	\begin{definicao}\label{definicao_estrutura_complexa}
		(Estrutura complexa) Uma estrutura complexa em um espaço vetorial $V$ é um endomorfismo linear $J: V \to V$, onde $J^{2} = -Id$. Dizemos que uma estrutura complexa em $V$ é compatível com a forma simplética (ou $\omega$-compatível) se $g(u,v):=\omega(u, Jv)$ define um produto interno em $V$. Denotaremos por $\estruturascomplexaspadrao$ o conjunto de todas as estruturas complexas em $V$ que sejam $\omega$-compatíveis.
	\end{definicao}
	
	\begin{observacao}\label{observacao_estrutura_complexa}
		Fixaremos a notação $\estruturacomplexa \in \estruturascomplexaspadrao$ como sendo o caso em que
		$$
		\estruturacomplexa=
		\left(
		\begin{array}{cc}
		0 & Id
		\\
		-Id & 0
		\end{array}
		\right).
		$$
	\end{observacao}
	
	Vamos mostrar que todo produto interno em $V$ pode ser associado a um elemento de $\estruturascomplexaspadrao$ e vice-versa, sendo que dessa associação vamos retirar informações sobre sua topologia.
	
	\begin{observacao}\label{observacao_conjunto_estrutura_complexa}
		Ao tratarmos $\estruturascomplexaspadrao$ como espaço topológico adotaremos sua topologia induzida pela topologia de $\generalgroupreal{V}$ gerada pela norma da convergência uniforme (ou norma do sup).
	\end{observacao}
	
	\begin{definicao}
		Seja $V$ um n-espaço vetorial real munido de um produto interno positivo-definido, então $\produtosinternos{V}$ é o conjunto de todos os produtos internos positivos-definidos em $V$.
	\end{definicao}
	
	\begin{observacao}
		Por definição $\produtosinternos{V} \subseteq \mathcal{L}(V \times V; \real{})$. Com isso, podemos muni-lo com a toplogia induzida por $\mathcal{L}(V \times V; \real{})$.
	\end{observacao} 
	
	\begin{lema}\label{lema_contratibilidade_produtos_internos}
		Seja $V$ um n-espaço vetorial com produto interno positivo-definido. Então $\produtosinternos{V}$ é contrátil.
	\end{lema}
	\begin{prova}
		Sejam $d_{1},d_{2} \in \produtosinternos{V}$ e $d:\intervalo\to \produtosinternos{V}$ tal que $d(s) = (1-s)d_{1}+ s d_{2}$. Afirmo que $d(s)$ é um produto interno. De fato, é bilinear e simétrico, pois é uma combinação linear de aplicações bilineares e simétricas. Resta-nos mostrar que $d(s)$ é positivo-definido. Supondo que $v =0$ teremos $d(s)(v,v)=(1-s)d_{1}(v,v)+ s d_{2}(v,v)  =0$, pois $d_{1}, d_{2}$ são positivos-definidos. Suponha que $v\neq 0$ e $d(s)(v,v) = 0$. Então $0=(1-s)d_{1}(v,v)+ s d_{2}(v,v)  $ o que é um absurdo pois $(1-s)d_{1}(v,v)>0 $ e $sd_{2}(v,v)> 0$. Logo $d(s)$ é positiva-definida para todo $s \in \intervalo$. Como $d_{1}, d_{2} \in \produtosinternos{V}$ são arbitrários, e $d$ é uma reta, então $\produtosinternos{V}$ é convexo, logo é contrátil.
	\end{prova}
	
	Vimos que, dados $(V, \omega)$ n-espaço vetorial simplético e uma estrutura complexa $J$ $\omega$-compatível, temos que $\formaSimpletica{v}{Ju} = g_{J}(v,u)$ é um produto interno em $V$. Com isso, a aplicação $G:\estruturascomplexaspadrao \to \produtosinternos{V}$ onde $G(J)(u,v) = \omega(u,Jv) = g_{J}(u,v)$ esta bem-definida e é injetora.
	
	A seguinte proposição afirma a reciproca do resultado anterior.
	
	\begin{proposicao}
		Seja $(V, \omega)$ uma 2n-espaço vetorial simplético. Então cada produto interno $g \in \produtosinternos{V}$ define uma estrutura complexa $\omega$-compatível.
	\end{proposicao}
	\begin{prova}
		Seja $g \in \produtosinternos{V}$. Sabe-se que $\hat{g}:V \to V^{*}$, definido por $\hat{g}(v)(u)=g(v,u)$, é um isomorfismo. Além disso, existe um único automorfismo $A:V\to V$ tal que $\formaSimpletica{v}{u} = g(Av,u)$ para todo $v,u \in V$ dado por $A = \hat{g}^{-1}\omega
		^{*}$. Note que $g(Av,u) = \formaSimpletica{v}{u} = -\formaSimpletica{u}{v} = -g(Au,v) = g(-A^{t}v,u)$, portanto $A$ é anti-simétrico. Pelo Corolário $\ref{corolario_decomposicao_matriz_antisimetrica}$ podemos escrever $A=PJ$, onde $P = (-A^{2})^{1/2}$ é positiva-definida, $J$ é ortogonal tal que $J^{2} = -Id$ e $J^{t} = J^{-1}$. Com isso, temos $\formaSimpletica{v}{Ju} = g(Av, Ju) = g(J^{t}Av, u)  = g(J^{-1}Av, u) = g(Pv, u) = g_{P}(v,u)$, o que é um produto interno positivo-definido pois $P$ é positivo-definido. Portanto, $J$ é $\omega$-compatível. Assim, temos a aplicação injetora $F: \produtosinternos{V} \to \estruturascomplexas{V}{\omega}$ definida por $F(g) = J$.
	\end{prova}
	
	\begin{proposicao}
		$\estruturascomplexaspadrao$ é homeomorfo a $\produtosinternos{V}$, logo é contrátil.
	\end{proposicao}
	\begin{prova}
		Sejam $F: \produtosinternos{V} \to \estruturascomplexaspadrao$ e $G:\estruturascomplexaspadrao \to \produtosinternos{V}$ dos resultados anteriores. Seja $J \in \estruturascomplexaspadrao$ arbitrário. Então $(F\circ G)(J) = F(g_{J}) =J$, logo $F\circ G = Id_{\estruturascomplexaspadrao}$. Por outro lado, $(G\circ F)(g_{J}) = G(J) = g_{J}$, logo $G\circ F = Id_{\produtosinternos{V}}$. Portanto $F = G^{-1}$. Munindo $\estruturascomplexaspadrao$ com a topologia induzida por $\generalgroupreal{2n}$, então pode-se mostrar que $F$ é contínua. Analogamente, munindo $\produtosinternos{V}$ com a topologia induzida do espaço vetorial de todas as forma simétricas definida em $V$, pode-se mostrar que $G$ é contínua. Portanto $F$ é um homeomorfismo. Pelo Lema $\ref{lema_contratibilidade_produtos_internos}$ temos que $\produtosinternos{V}$ é contrátil, e como a contratibilidade é preservada por homeomorfismos, então $\estruturascomplexaspadrao$ é contrátil.
	\end{prova}
	
	\chapter{O Grupo Simplético $\gruposimpletico{2n}$}
	Neste capítulo definiremos o grupo fundamental e apresentaremos um estudo aprofundado das suas propriedades. O grupo simplético e suas características topológicas exercem papel central na construção dos índices de Maslov. Vamos mostrar que o grupo fundamental de $Sp(2n)$ é isomorfo aos inteiros e tal isomorfismo será dado pelo índice de Maslov.
	
	\section{Complexificação de espaços vetoriais}\label{secao_complexificacao_espacos_vetoriais}
	
	Seja $V$ um n-espaço vetorial real. Desejamos construir um espaço vetorial complexo a partir de $V$ e uma forma de realizarmos essa construção é tomando $v \in V $ e $a+ib \in \complexo{}$ e efetuando a multiplicação $(a+ib)v = av+ibv$. Porém, a multiplicação por $i$ não tem sentido nesse contexto, já que estamos tratando de um espaço vetorial real. Podemos contornar essa dificuldade tratando a multiplicação formal $(a+ib)v = av+ibv$ como o par ordenado $(av, bv)$, resultando na seguinte definição de complexificação:
	
	\begin{definicao}
		(Complexificação do n-espaço vetorial real V) A complexificação do n-espaço vetorial real $V$ é o n-espaço vetorial complexo $\complexificacao{V}=V\oplus V$ munido da multiplicação por escalares $(a+ib)(v_{1}, v_{2}) = (av_{1}-bv_{2}, bv_{1}+ av_{2})$, onde $a+ib \in \complexo{}$ e $(v_{1}, v_{2})\in \complexificacao{V}$.
	\end{definicao}
	
	\begin{observacao}
		Essa definição tem como motivação a seguinte situação: supondo $V$ complexo, então $V \ni (a+ib)v = (a+ib)(v_{1}+iv_{2}) = av_{1}-bv_{2}+i(bv_{2}+av_{1}) \mapsto (av_{1}-bv_{2}, bv_{1}+ av_{2}) \in \complexificacao{V}$.
	\end{observacao}
	
	É possível mostrar que $\complexificacao{V}$ é um espaço vetorial sobre $\complexo{}$. De fato, basta mostrarmos que esse espaço é fechado pela operação de adição e multiplicação por escalares, pois as outras operaçoes são triviais. Dados $a+ib \in \complexo{}$ e $v,u \in \complexificacao{V}$, então $(a+ib )v+u = (av_{1}-bv_{2}, bv_{1}+ av_{2}) + (u_{1}, u_{2}) = (av_{1}-bv_{2} + u_{1}, bv_{1}+ av_{2} + u_{2}) \in \complexificacao{V}$. As demais propriedades dos axiomas de espaços vetoriais resultam imediatamente dessa.
	
	\begin{exemplo}\label{exemplo_conjugado_reta_real}
		(Complexificação de $\reta$) Definindo $V = \reta$ temos que $\complexificacao{\reta}$ é $\reta\oplus \reta$ munido da operação $(a+ib)(x,y) = (ax-by, bx+ay)$. Assim, a identificação $(a+ib)(x, y ) = (ax-by, bx+ay) \mapsto ax-by+i(bx+ay) \in \complexo{}$ nos dá o isomorfimo $\complexificacao{\reta} \ni (x,y)\mapsto x +iy\in \complexo{}$.
	\end{exemplo}
	
	\begin{exemplo}\label{exemplo_complexificacao_matrizes}
		Analogamente ao exemplo anterior temos que as aplicações $\complexificacao{\real{n}} \ni (x,y) \mapsto x+iy \in \complexo{n}$ e  $\complexificacao{\matrizquadreal{n}} \ni (x,y) \mapsto x+iy \in \matrizquadcomplexa{n}$ também são isomorfismos.
	\end{exemplo}
	
	Notemos que os espaços vetoriais $V\oplus\{0\}$ e $\{0\}\oplus V$ são isomorfos a $V$. Com isso, a inclusão $i_{V} :V \hookrightarrow \complexificacao{V}$ definida por $i(v) = (v, 0)$ é chamada de mergulho padrão de $V$ em $\complexificacao{V}$.
	
	Complexificamos os espaços vetoriais reais, porém, as aplicações lineares entre tais espaços vetoriais são outros tipos de objetos a serem complexificados. O teorema a seguir afirma a unicidade da complexificação de aplicações lineares entre as complexificações de espaços vetoriais reais.
	
	\begin{teorema}
		(Complexificação de aplicações lineares) Seja $\varphi : V \to W$ uma aplicação
		$\reta$-linear entre espaços vetoriais reais de dimensão finita. Então existe uma única aplicação linear $\complexificacao{\varphi}:\complexificacao{V} \to \complexificacao{W}$ tal que $i_{W}\circ \varphi = \complexificacao{\varphi} \circ i_{V}$, isto é, o diagrama abaixo é comutativo.
		$$
		\xymatrix{
			V\ar[d]_{i_{V}}\ar[r]^{\varphi} & W\ar[d]^{i_{W}} 
			\\
			\complexificacao{V} \ar[r]_{\complexificacao{\varphi}}&\complexificacao{W} 
		}
		$$
	\end{teorema}
	\begin{prova}
		Defina $\complexificacao{\varphi}:\complexificacao{V} \to \complexificacao{W}$ por $\complexificacao{\varphi}(v_{1}, v_{2}) = (\varphi v_{1}, \varphi v_{2})$. Como $\varphi v_{1}, \varphi v_{2} \in W$, então $(\varphi v_{1}, \varphi v_{2}) \in W\oplus W = \complexificacao{W}$. Além disso, dados $\lambda = (a+ib)\in \complexo{}$ e $(v_{1}, v_{2}), (u_{1}, u_{2})\in \complexificacao{V}$ temos 
		$$
		\begin{aligned}
		\complexificacao{\varphi} (\lambda(v_{1}, v_{2}) + (u_{1}, u_{2})) 
		&= (\varphi(a v_{1} - bv_{2} + u_{1}), \varphi(b v_{1}+a v_{2} + u_{2}))
		\\
		&=(a\varphi v_{1} - b\varphi v_{2} + \varphi u_{1}, b\varphi v_{1}+a\varphi v_{2} + \varphi u_{2})
		\\
		&=(a\varphi v_{1} - b\varphi v_{2} , b\varphi v_{1}+a\varphi v_{2} )+(\varphi u_{1},\varphi u_{2})
		\\
		&=\lambda(\varphi v_{1},\varphi v_{2})+(\varphi u_{1},\varphi u_{2})
		\\
		&=\lambda 	\complexificacao{\varphi} (v_{1},v_{2})+\complexificacao{\varphi} (u_{1},u_{2}).
		\end{aligned}
		$$
		Portanto $\complexificacao{\varphi}$ é $\complexo{}$-linear. Dado $v \in V$ temos $(i_{W}\circ \varphi)(v) = (\varphi v,0) = \complexificacao{\varphi}(v,0) = (\complexificacao{\varphi} \circ i_{V})(v)$, logo $i_{W}\circ \varphi =\complexificacao{\varphi} \circ i_{V}$. Por fim, suponha que exista $\complexificacao{\varphi'} $ definida por $\complexificacao{\varphi'}(v_{1}, v_{2}) = (\varphi' v_{1}, \varphi' v_{2})$ e tal que $i_{W}\circ \varphi =\complexificacao{\varphi'} \circ i_{V}$, onde $\varphi':V\to W$ é uma aplicação linear. Então para todo $v \in V$ temos $(i_{W}\circ \varphi )(v)=(\complexificacao{\varphi} \circ i_{V})(v) = (\complexificacao{\varphi'} \circ i_{V})(v)$, o que implica em $(\varphi v, 0) = (\varphi' v, 0)$. Como $v \in V$ é arbitrário, então $\varphi = \varphi'$, logo $\complexificacao{\varphi} = \complexificacao{\varphi'}$, demonstrando a unicidade. 
	\end{prova}
	
	Considerando o corpo dos complexos como um espaço vetorial sobre $\reta$, mostraremos que o produto tensorial $\complexificacaotensorial{V}$ é equivalente a construção da complexificação feita anteriormente. Utilizaremos construção na complexificação do 2n-espaço vetorial simplético $(V, \omega)$.
	
	\begin{teorema}\label{teorema_isomorfismo_complexificacao}
		Seja $V$ um espaço vetorial real de dimensão finita. A aplicação $f_{V}: \complexificacao{V} \to \complexificacaotensorial{V}$ definida por  $f_{V}(v_{1},v_{2}) = 1\otimes_{\reta} v_{1} + i \otimes_{\reta} v_{2}$ é um isomorfismo entre os espaços vetoriais complexos e comuta o diagrama
		$$
		\xymatrix{
			& V\ar[dl]_{i_{V}}\ar[rd]^{j} &
			\\
			\complexificacao{V}\ar[rr]_{f_{V}}& & \complexificacaotensorial{V},
		}
		$$
		onde $i_{V}(v) = (v,0)$ (é o mergulho padrão) e $j(v) = 1\otimes_{\reta} v$.
	\end{teorema}
	\begin{prova}
		Dados $z=(a+ib) \in \complexo{}$ e $v,u \in \complexificacao{V}$ temos
		$$
		\begin{aligned}
		f_{V}(zv+u) &= 1\otimes_{\reta} (a v_{1} - bv_{2} + u_{1}) + i \otimes_{\reta} (bv_{1}+av_{2} + u_{2})
		\\
		&=1\otimes_{\reta} (a v_{1} - bv_{2}) + i \otimes_{\reta} (bv_{1}+av_{2})+1\otimes_{\reta} u_{1} + i \otimes_{\reta} u_{2}
		\\
		&=(a+ib)\otimes_{\reta}v_{1} + (-b+ia)\otimes_{\reta} v_{2}+f_{V}(u)
		\\
		&=(a+ib)\otimes_{\reta}v_{1} + (a+ib)i\otimes_{\reta} v_{2}+f_{V}(u)
		\\
		&=zf_{V}(v)+f_{V}(u).
		\end{aligned}
		$$
		Portanto $f_{V}$ é $\complexo{}$-linear. Além disso, é injetora pois $f_{V}(u) = 0$ se, e somente se, $u = 0$. Tomando um elemento $w = (a+ib)\otimes_{\reta}v \in \complexificacaotensorial{V} $ e definindo $u = (av, bv) \in \complexificacao{V}$ temos que $f_{V}(u) = \complexificacaoelemento{1}{av} +\complexificacaoelemento{i}{bv} = (a+ib)\otimes_{\reta} v = w$. Portanto $f_{V}$ é sobrejetora. Logo é um isomorfismo.
		
		Para todo $v \in V$ temos que $(f_{V}\circ i_{V})(v) = f_{V}(v, 0) = 1\otimes_{\reta} v = j(v)$. Portanto o diagrama é comutativo.
	\end{prova}
	
	O conjugado de cada $z=(a+ib) \in \complexo{}$ é definido por $\overline{z} = a-ib$. Analogamente, o conjugado de $\complexificacaoelemento{z}{v} \in \complexificacaotensorial{V}$ é definido por $\complexificacaoelemento{\overline{z}}{v} \in \complexificacaotensorial{V}$. Definindo $v_{1} =av$ e $v_{2} = -bv$ temos $f_{V}(v_{1}, v_{2}) =\complexificacaoelemento{1}{v_{1}} +\complexificacaoelemento{i}{v_{2}} = \complexificacaoelemento{a}{v} -\complexificacaoelemento{ib}{v}  =\complexificacaoelemento{\overline{z}}{v}  $. Portanto, temos a identificação entre os conjugados $ \complexificacao{V} \ni (av, -bv) \mapsto \complexificacaoelemento{\overline{z}}{v} \in \complexificacaotensorial{V}$.
	
	Sejam $k\geq 1$ um inteiro e $\{V_{j}\}_{j=1}^{k}$ um conjunto de espaços vetoriais de dimensão finita sobre um corpo $\mathbb{K}$. Sabe-se que o produto tensorial $\produtotensorial{V}{k}$ é um espaço vetorial de dimensão finita sobre $\mathbb{K}$. Alem disso, sabe-se que, dado um $W$ espaço vetorial também sobre $\mathbb{K}$, tem-se que $W\otimes_{\mathbb{K}}(\produtotensorial{V}{k}) \cong W\otimes_{\mathbb{K}} \produtotensorial{V}{k}$. 

	Daqui em diante fixaremos a notação $\complexificado{V} = \complexificacaotensorial{V}$ para a complexificação de $V$ via produto tensorial.
	
	\begin{observacao}
		Visto como espaço vetorial complexo, temos que $\{1\}$ é uma base de $\complexo{}$, logo temos que $\{1^{*}\}$ é uma base do dual $\complexo{*}$, tal que $1^{*}(1) = 1$. Com isso, dado $z = (a+ib).1 \in \complexo{}$, temos $1^{*}(z) = 1^{*}((a+ib).1) = (a+ib)1^{*}(1) = a+ib$.
	\end{observacao}
	
	Sejam $B = \colecaofinita{e}{n}$ uma base do n-espaço vetorial real $V$ e $B^{*} = \colecaofinita{e^{*}}{n}$ a base de seu dual $V^{*}$ tal que $e^{*}_{j}(e_{k}) =\delta_{jk}$. Defina $1 \otimes B = \colecaofinita{\complexificacaoelemento{1}{e}}{n}$ e
	$1 \otimes B^{*} = \colecaofinita{\complexificacaoelemento{1^{*}}{e^{*}}}{n}$. Denotando $a_{j}$ e $a^{*}_{j}$ por $\complexificacaoelemento{1}{e_{j}}$ e $\complexificacaoelemento{1^{*}}{e^{*}_{j}}$, respectivamente, temos que $1\otimes B$ gera $\complexificado{V}$. De fato, todo $v \in \complexificado{V}$ pode ser escrito como 
	$$
	\begin{aligned}
		v &= \sum_{j=1}^{n} \complexificacaoelemento{z_{j}}{v_{j}}
		\\
		 &= \sum_{j=1}^{n} \complexificacaoelemento{z_{j}}{\bigparenteses{\sum_{i=1}^{n}\alpha_{ji}e_{i}}} 
		 \\
		 &= \sum_{j,i=1}^{n}\complexificacaoelemento{z_{j}\alpha_{ji}}{e_{i}}
		 \\
		 &= \sum_{i=1}^{n}\complexificacaoelemento{z'_{i}}{e_{i}}
		 \\
		 &= \sum_{i=1}^{n}z'_{i}(\complexificacaoelemento{1}{e_{i}}),
	\end{aligned}
	$$
	onde $z'_{i} = \sum_{j=1}^{n}z_{j}\alpha_{ji}$ e $ z_{j}$ estão em $\complexo{}$ e $v_{j} \in V$.
	
	
	\begin{observacao}
		O elementos $v \in \complexificado{V}$ do tipo $v = \complexificacaoelemento{z}{\alpha}$ são chamados de vetores simples. Vimos anteriormente que os vetores mais gerais são combinações lineares dos vetores simples. Por esse fato, as aplicações lineares e multilineares estudadas nessa seção serão avaliadas apenas nos tensores simples.
	\end{observacao}
	
	\begin{proposicao}\label{proposicao_base_complexificada}
		$1\otimes B$ e $1^{*}\otimes B^{*}$ são bases de $\complexificado{V}$ e $\complexificado{V}^{*}$, respectivamente, tais que $a^{*}_{j}(a_{k})=\delta_{ik}$.
	\end{proposicao}
	\begin{prova}
		 Por construção $1\otimes B$ gera $\complexificado{V}$. Afirmo que $B$ é linearmente independente pois, $0=\sum_{j}z_{j}a_{j} = \sum_{j}z_{j}(1\otimes e_{j}) = \sum_{j}(b_{j} +ic_{j})(1\otimes e_{j}) = 1\otimes \sum_{j}b_{j}e_{j}+i\otimes \sum_{j}c_{j}e_{j}$, o que implica que $\sum_{j}b_{j}e_{j}=\sum_{j}c_{j}e_{j} = 0$. Logo, $b_{j}=c_{j}=0$  e $z_{j} = 0$ para $1\leq j\leq k$. O isomorfismo $\complexificado{V} \mapsto \complexificado{V}^{*}$ garante que $B^{*}$ é base de $\complexificado{V}^{*}$. Por fim, temos que $a^{*}_{j}(a_{k})=(\complexificacaoelemento{1^{*}}{e^{*}_{j}})(\complexificacaoelemento{1}{e_{k}}) = 1^{*}(1)e^{*}_{j}(e_{k}) = \delta_{ik}$.
	\end{prova}
	
	Como o produto tensorial real $\otimes_{j=1}^{k}V_{j}$ é um espaço vetorial real, então sua complexificação será o espaço vetorial complexo $\complexificacaotensorial{(\produtotensorialreal{k}{V})} \cong \complexificacaotensorial{V_{1} \otimes_{\reta} \dots \otimes_{\reta} V_{k}}$, pelo isomorfismo anteriormente citado. Contudo, pode-se se mostrar que essa complexificação é isomorfa ao produto tensorial sobre os complexos $\bigotimes^{k}_{j=1}\complexificado{V}$, a qual denotamos por $\complexificado{V}^{k\otimes}$. 
	
	Na seção seguinte vamos utilizar o produto tensorial complexificado $\complexificado{V}^{k\otimes}$ pois ela facilita a demonstração de algumas propriedades da complexificação da forma simplética, que é um tensor de ordem 2.
	
	\begin{exemplo}\label{exemplo_complexificacao_tensorial}
		Sejam $V$ um n-espaço vetorial real e $B = \colecaofinita{e}{n}$ uma base ortonormal. Supondo que $\complexificado{V}$ seja a complexificação de $V$, então pela Proposição $\ref{proposicao_base_complexificada}$ temos que $1\otimes B^{*}$ é uma base de $\complexificado{V}^{*}$. Com isso, dado $T \in \produtotensorialdual$ podemos escrever $T = \sum_{i,j = 1}^{n} T^{ij}a^{*}_{i}\otimes a^{*}_{j}$, onde $T^{ij} \in \complexo{}$. Dados $v, u\in \complexificado{V}$ tais que $v=\complexificacaoelemento{x}{\alpha}$ e $u=\complexificacaoelemento{y}{\beta}$, temos
		$$
		\begin{aligned}
			T(v,u) &= \sum_{i,j = 1}^{n}
			 T^{ij}a^{*}_{i}\otimes a^{*}_{j}(v,u)
			 \\
			 &= \sum_{i,j = 1}^{n}
			 T^{ij}a^{*}_{i}(v)a^{*}_{j}(u)
			 \\
			 &= \sum_{i,j = 1}^{n}
			 T^{ij}(\complexificacaoelemento{1^{*}}{e^{*}_{i}})(\complexificacaoelemento{x}{\alpha})(\complexificacaoelemento{1^{*}}{e^{*}_{j}})(\complexificacaoelemento{y}{\beta})
			 \\
			 &= \sum_{i,j = 1}^{n}
			 T^{ij}1^{*}(x)e^{*}_{i}(\alpha)1^{*}(y)e^{*}_{i}(\beta)
			 \\
			 &= \sum_{i,j = 1}^{n}
			 xyT^{ij}\alpha_{i}\beta_{j},
		\end{aligned}
		$$ 
		onde $\alpha_{j}$ e $\beta_{j}$ são as $j$-ésimas coordenadas de $\alpha, \beta \in V$. 
	\end{exemplo}
	
	Para estudarmos algumas características dos auto-espaços do grupo simplético precisaremos decompor esse espaço vetorial em soma direta de determinados  auto-espaços. Tal composição será garantida pelo Teorema $\ref{teorema_espectral_jordan}$, que depende de um espaço vetorial complexo como hipótese. Como consequencia desse fato, precisaremos de um espaço vetorial simplético complexo e que seja gerado a partir de um dado espaço vetorial simplético.
	
	Na seção anterior vimos que uma das construções da complexificação de $V$ é o espaço vetorial complexo $\complexificado{V}$. Dado $(V, \omega)$ um 2n-espaço vetorial simplético real, temos que $\omega \in V^{*}\otimes V^{*}$. Sejam $B = \{e_{j}\}_{j=1}^{2n}$ uma base de $V$ e $\omega^{ij} = \omega(e_{i}, e_{j})$ as componentes da forma simplética nessa base. Dessa definição temos que $\omega^{ij} = -\omega^{ji}$.
	
	Utilizando as notações da Proposição $\ref{proposicao_base_complexificada}$, defina $\Omega=\sum_{i,j}\omega^{ij}a^{*}_{i}\otimes a^{*}_{j} \in \produtotensorialdual$. Temos que
	
	\begin{proposicao} $(\complexificado{V}, \Omega)$ é um 2n-espaço vetorial simplético sobre $\complexo{}$.
	\end{proposicao}\label{proposicao_complexificacao_espaco_simpletico}
	\begin{prova}
		Pelo Teorema $\ref{teorema_isomorfismo_complexificacao}$ temos que $\complexificado{V}$ é um 2n-espaço vetorial complexo. Por construção $\Omega$ é uma aplicação $\complexo{}$-bilinear. Do fato $\omega^{ij}  = -\omega^{ji} $ temos que $\Omega$ é anti-simétrica. Afirmo que $\Omega$ é não degenerada. De fato, tomando $v, u \in \complexificado{V}$ tal que $v= \complexificacaoelemento{x}{\alpha}$ e $u=\complexificacaoelemento{y}{\beta} $, temos pelo Exemplo $\ref{exemplo_complexificacao_tensorial}$ que 
		$$
		\begin{aligned}
		\Omega(v,u) &= \sum_{i,j = 1}^{2n}
		\omega^{ij}a^{*}_{i}\otimes a^{*}_{j}(v,u)
		\\
		&= \sum_{i,j = 1}^{2n}
		xy\omega^{ij}\alpha_{i}\beta_{j}
		\\
		&= xy\sum_{i,j = 1}^{2n}
		\formaSimpletica{\alpha_{i}e_{i}}{\alpha_{j}e_{j}}
		\\
		&= xy\formaSimpletica{\alpha}{\beta}.
		\end{aligned}
		$$
		Como $\omega$ é não-degenerada, então $\Omega$ é não-degenerada. Portanto, $(\complexificado{V}, \Omega)$ é um 2n-espaço vetorial simplético sobre $\complexo{}$.
	\end{prova}
	
	\begin{observacao}
		Futuramente mostraremos que $\Omega$ é uma extensão contínua da forma simplética $\omega$.
	\end{observacao}
	
	\begin{proposicao}
		A complexificação $\Omega$ de $\omega$ pode ser decomposta em $\Omega = g +i k$, onde $g,k$ são ambas formas simpléticas definidas em $V$.
	\end{proposicao}
	\begin{prova}
		
		O Teorema $\ref{teorema_existencia_base_simpletica}$ garante que $\complexificado{V}$ possui uma base simplética $B$. Pela Observação $\ref{observacao_existencia_base_simpletica}$ temos que a representação matricial de $\Omega$ nessa base simplética é $\estruturacomplexa$. Suponha que $V, U \in \matrizquadcomplexa{2n}$ sejam as representações matriciais de $v,u \in \complexificado{V}$ nessa base. Então podemos escrever $$
		\begin{aligned}
		\formaSimpleticaExtendida{v}{u} &= V^{*}\estruturacomplexa^{*} U 
		\\
		&= (V_{1}+iV_{2})^{*}\estruturacomplexa^{*} (U_{1}+iU_{2})
		\\
		&= \underbrace{V_{1}^{t}\estruturacomplexa^{t} U_{1}}_{\formaSimpletica{v_{1}}{u_{1}}} -V_{2}^{t}\estruturacomplexa^{t} U_{2}+i(\underbrace{ V_{1}^{t}\estruturacomplexa^{t} U_{2}}_{\formaSimpletica{v_{1}}{u_{2}}} - V_{2}^{t}\estruturacomplexa^{t} U_{1})
		\\
		&= \underbrace{\formaSimpletica{v_{1}}{u_{1}} -\formaSimpletica{v_{2}}{u_{2}}}_{g(v,u)}+i(\underbrace{ \formaSimpletica{v_{1}}{u_{2}}- \formaSimpletica{v_{2}}{u_{1}}}_{k(v,u)})
		\\
		&= g(v,u)+ik(v,u),
		\end{aligned}
		$$
		onde fizemos $v_{j}, u_{j}\in V$ e $V_{j}, U_{j}$ sendo a representação matricial de cada um deles para $j \in \{1,2\}$.
		Temos que $g,k:\complexificado{V}\times \complexificado{V} \to \reta$ são aplicações $\complexo{}$-bilineares e anti-simétricas pois são combinações lineares de aplicações $\complexo{}$-bilineares anti-simétricas. Pelo mesmo argumento, $g,k$ são não-degeneradas.
	\end{prova}
	
	\begin{proposicao}\label{proposicao_base_simpletica_conjugada}
		Seja $B=\{a_{j}, f_{j} \}_{j=1}^{n}$ uma base simplética de $\complexificado{V}$, então $\overline{B}=\{\overline{a}_{j}, \overline{f}_{j}  \}_{j=1}^{n}$ é uma base simplética de $\complexificado{V}$.
	\end{proposicao}
	\begin{prova}
		Temos que a aplicação de conjugação $\complexificado{V} \ni z\otimes v \mapsto \overline{z}\otimes  \in \complexificado{V}$ é um isomorfismo. Logo, leva base em base. Como $B$ é uma base simplética, temos $\Omega(a_{i}, a_{j}) = \Omega(f_{i}, f_{j}) =0$ e $\Omega(a_{i}, f_{j}) = \delta_{ij}$. Com isso, fazendo $a_{i} = \complexificacaoelemento{z_{i}}{v_{i}}$, e pela Proposição $\ref{proposicao_complexificacao_espaco_simpletico}$ temos $\Omega(\overline{a}_{i}, \overline{a}_{j}) =	\overline{z_{i}}\overline{z_{j}}\formaSimpletica{v_{i}}{v_{j}}=\overline{z_{i}z_{j}\formaSimpletica{v_{i}}{v_{j}}} = \overline{\Omega(a_{i}, a_{j})} = 0$. Com argumento análogo pode-se ver que $\Omega(\overline{f}_{i}, \overline{f}_{j}) =0$ e $\Omega(\overline{a}_{i}, \overline{f}_{j}) =\delta_{ij}$. Logo, $\overline{B}$ é uma base simplética.
	\end{prova}
	
	Um operador linear $T : \complexificado{V} \to \complexificado{V}$ pode ser escrito como $T=\complexificacaoelemento{\lambda}{A}$, tal que $T(v) = \complexificacaoelemento{\lambda}{A}(\complexificacaoelemento{z}{\alpha}) = \complexificacaoelemento{\lambda z}{A\alpha}$, onde $\lambda \in \complexo{}$ e $A$ é um operador linear $A:V \to V$. Com isso, $T$ esta bem-definido.
	
	\begin{definicao}
		(Transformação simplética) Seja $(\complexificado{V}, \Omega)$ um 2n-espaço vetorial simplético sobre $\complexo{}$. Um operador linear $T: \complexificado{V} \to \complexificado{V}$ é uma transformação simplética se 
		$$
		\formaSimpleticaExtendida{Tu}{Tv} = \formaSimpleticaExtendida{u}{v}
		$$ para todo $u,v\in \complexificado{V}$.
	\end{definicao}
	
	Suponha que $T=\complexificacaoelemento{1}{A}$ para algum operador linear $A:V \to V$. Afirmo que se $T$ é uma transformação simplética, então $A$ é uma transformação simplética. De fato, tomando $u = \complexificacaoelemento{x}{\alpha}$ e $v=\complexificacaoelemento{y}{\beta}$ em $\complexificado{V}$ temos que $Tu = \complexificacaoelemento{x}{A\alpha}$ e $Tv= \complexificacaoelemento{y}{A\beta}$
	$$
	\begin{aligned}
	\Omega(Tv,Tu)
	&= \sum_{i,j = 1}^{2n}
	\omega^{ij}a^{*}_{i}\otimes a^{*}_{j}(Tv,Tu)
	\\
	&= 
	\sum_{i,j = 1}^{2n}
	\omega^{ij}a^{*}_{i}\otimes a^{*}_{j}(\complexificacaoelemento{x}{A\alpha},\complexificacaoelemento{y}{A\beta})
	\\
	&= \sum_{i,j = 1}^{2n}
	xy\omega^{ij}e^{*}_{i}(Au)e^{*}_{j}(Av)
	\\
	&= xy
	\formaSimpletica{A\alpha}{A\beta}.
	\end{aligned}
	$$  
	Temos que $\formaSimpleticaExtendida{Tu}{Tv} = \formaSimpleticaExtendida{u}{v}$ o que implica que $xy
	\formaSimpletica{A\alpha}{A\beta} = xy
	\formaSimpletica{\alpha}{\beta}$. Como $\alpha, \beta \in V$ são arbitrários, então $A$ é uma transformação simplética. A recíproca é imediata.
	
	\begin{definicao}
		(Grupo simplético complexo) O grupo simplético complexo $\gruposimpletico{\complexificado{V}} \subset \generalgroupcomplexo{2n}$ de $\complexificado{V}$ é o conjunto das matrizes associadas as transformações simpléticas definidas em $\complexificado{V}$.
	\end{definicao}

	\section{O grupo simplético $\gruposimpletico{2n}$}\label{secao_grupo_simpletico}
	
	Daqui em diante vamos denotar por $\gruposimpletico{2n}$ o grupo simplético real $\gruposimpletico{\real{2n}}$.
	
	\begin{proposicao}\label{proposicao_grupo_simpletico_estrutura_grupo}
		$\gruposimpletico{2n}$ é um grupo com a operação de multiplicação de matrizes.
	\end{proposicao}
	\begin{prova}
		Sejam $A,B \in \gruposimpletico{2n}$ e $u,v \in \real{2n}$, então
		\begin{enumerate}
			\item \textit{(Operação fechada)} $\omega(ABu, ABv) = \omega(Bu, Bv) = \omega(u,v)$, logo $AB \in \gruposimpletico{2n}$.
			
			\item \textit{(Associatividade)} $\gruposimpletico{2n}$ é associativo pois a operação de multiplicação de matrizes reais é associativa.
			
			\item \textit{(Elemento neutro)} o elementro neutro de $\gruposimpletico{2n}$ é a identidade.
			
			\item \textit{(Elemento inverso)} Se $A \in \gruposimpletico{2n}$, então $\omega(u, v)=\omega(AA^{-1}u, AA^{-1}v) = \omega(A^{-1}u, A^{-1}v)$, logo $A^{-1} \in \gruposimpletico{2n}$. 
		\end{enumerate}
		Portanto $\gruposimpletico{2n}$ é um grupo.
	\end{prova}
	
	\begin{observacao}
		Quando tratarmos $\gruposimpletico{2n}$ como espaço topológico adotaremos sua topologia induzida pela topologia de $\generalgroupreal{2n}$ gerada pela norma da convergência uniforme.
	\end{observacao}
	
	Vejamos a seguinte caracterização do grupo simplético e sua relação com a estrutura complexa:
	
	\begin{lema}\label{lema_caracterizacao_Sp2n}
		(Caracterização de $Sp(2n)$) Se $(V, \omega)$ é um 2n-espaço vetorial simplético e $J \in \estruturascomplexaspadrao$ uma estrutura complexa $\omega$-compatível, então $A\in Sp(2n)$ se, e somente se, $A^{t}JA = J$. Além disso, podemos escrever 
		$$
		A=
		\left(
		\begin{array}{cc}
		B & C
		\\
		D & E
		\end{array}
		\right)
		$$
		onde $B^{t}D, C^{t}E, BC^{t}, DE^{t} $ são matrizes simétricas e $B^{t}E - D^{t}C = Id$ e $BE^{t} - CD^{t} = Id$.
	\end{lema}
	\begin{prova}
		Suponha $A \in Sp(2n)$, então:
		$$
		\omega(Av, Jw)= g(Av,w) = g(v,A^{t}w) = \omega(v, JA^{t}w) = \omega(Av, AJA^{t}w).
		$$
		Como a igualdade vale para quaisquer $v,w$, então $J = AJA^{t}$. Por outro lado, suponha que $A \in \generalgroupreal{2n}$, tal que $A^{t}JA=J$ para $J \in \estruturascomplexaspadrao$, então:
		$$
		\begin{aligned}
		\omega(Av, Aw) &= \omega(Av, -J^{2}Aw)
		\\
		&=g(Av, -JAw) 
		\\
		&= g(v, -A^{t}JAw) 
		\\
		&= g(v, -Jw) 
		\\
		&= \omega(v, -J^{2}w) 
		\\
		&= \omega(v, w), 
		\end{aligned}
		$$
		logo $A \in \gruposimpletico{2n}$. Seja $J \in \estruturascomplexaspadrao$ e $\{e, f\}$ uma base simplética de $V$ tal que a matriz $J$ com relação a essa base é $\estruturacomplexa$. A equação $A^{t}JA=J$ nos fornece as relações entre os blocos de matrizes de $A$:
		
		$$
		\begin{aligned}
		J &= A^{t}JA
		\\
		\left(
		\begin{array}{cc}
		0 & -Id
		\\
		Id & 0
		\end{array}
		\right)
		&=
		\left(
		\begin{array}{cc}
		B^{t} & D^{t}
		\\
		C^{t} & E^{t}
		\end{array}
		\right)
		\left(
		\begin{array}{cc}
		-D & -E
		\\
		B & C
		\end{array}
		\right)
		\\
		&=
		\left(
		\begin{array}{cc}
		-B^{t}D +D^{t}B & -B^{t}E+D^{t}C
		\\
		-C^{t}D+E^{t}B & -C^{t}E+E^{t}C
		\end{array}
		\right),
		\end{aligned}
		$$
		portanto $B^{t}D = D^{t}B = (B^{t}D)^{t}$ (matriz simétrica) e $D^{t}C-B^{t}E = Id$. De forma análoga obtemos as outras identidades.
	\end{prova}
	
	Dada uma matriz $A \in \generalgroupcomplexo{n}$ podemos escrever $A = B+iC$ onde $B,C \in \generalgroupreal{n}$. Com isso, consideremos a aplicação $F:\generalgroupcomplexo{n} \to \generalgroupreal{2n}$ tal que 
	$$
	F(A)=
	\left(
	\begin{array}{cc}
	B & -C
	\\
	C & B
	\end{array}
	\right).
	$$
	Note que $F(A) = 0$ se, e somente se, $A=0$, logo $F$ é injetor. Pode-se verificar que $F(AB)=F(A)F(B)$, portanto é um monomorfismo. Além disso, temos a propriedade $F(A^{*}) = F(B^{t} - iC^{t}) = F(A)^{t}$. A aplicação $F$ é contínua pois dados $A=B+iC \in \generalgroupcomplexo{n}$ e $\epsilon > 0$, então para todo $X= Y+iZ \in \generalgroupcomplexo{n}$ tal que $||A - X||=max \{|B_{ij} - Y_{ij}|,  |C_{ij} - Z_{ij}|\} < \epsilon/2$ temos
	$$
	||F(A) - F(X)|| = max \{|B_{ij} - Y_{ij}|, |C_{ij} - Z_{ij}| \}< \epsilon/2 < \epsilon.
	$$
	
	Seja $\matrizunitaria{n} = \{A\in \generalgroupcomplexo{n}: AA^{*}=Id \}$ o subgrupo das matrizes unitárias, então temos o seguinte lema:
	
	\begin{lema}\label{lema_isomorfismo_U}
		Seja $F$ a aplicação contínua definida anteriormente. Então a restrição $F|_{\matrizunitaria{n}}: \matrizunitaria{n} \to \matrizSimpleticaOrtogonal $, onde $\matrizSimpleticaOrtogonal  = \gruposimpletico{2n}\cap \matrizortogonal{2n}$ é um isomorfismo. Além disso, dado $A \in \matrizSimpleticaOrtogonal $ temos $A\estruturacomplexa=\estruturacomplexa A$.
	\end{lema}
	\begin{prova}
		Temos que $\matrizSimpleticaOrtogonal  = \gruposimpletico{2n} \cap \matrizortogonal{2n}$ é não-vazio, pois a identidade esta na intersecção. Tomando $A \in \matrizSimpleticaOrtogonal $, então $A^{t}A= Id$. Com isso, temos
		$$
		\begin{aligned}
		Id=A^{t}A &=
		\left(
		\begin{array}{cc}
		B^{t} & D^{t}
		\\
		C^{t} & E^{t}
		\end{array}
		\right)
		\left(
		\begin{array}{cc}
		B & C
		\\
		D & E
		\end{array}
		\right)
		\\
		&= 
		\left(
		\begin{array}{cc}
		B^{t}B + D^{t}D & B^{t}C + D^{t}E 
		\\
		C^{t}B + E^{t}D  & CC^{t}+EE^{t}
		\end{array}
		\right)
		\\
		&=
		\left(
		\begin{array}{cc}
		B^{t}B + D^{t}D & 0 
		\\
		0 & CC^{t}+EE^{t}
		\end{array}
		\right),
		\end{aligned}
		$$
		onde a condição é satisfeita quando $C^{t}B =- E^{t}D$, $B^{t}C =- D^{t}E$ e $BB^{t} + CC^{t} = DD^{t}+EE^{t} = Id$. 
		
		Dada $Z \in \matrizunitaria{n}$ temos $Id=F(Id) = F(Z^{*}Z) = F(Z^{*})F(Z) = F(Z)^{t}F(Z)$, portanto $F(Z) \in \matrizortogonal{2n}$. Fazendo $Z= B+iC$ teremos
		$$
		F(Z)=
		\left(
		\begin{array}{cc}
		B & -C
		\\
		C & B
		\end{array}
		\right)
		$$
		e
		$$
		F(Z^{*})F(Z)=
		\left(
		\begin{array}{cc}
		BB^{t} +CC^{t} & -B^{t}C +C^{t}B
		\\
		B^{t}C -C^{t}B & BB^{t} +CC^{t}
		\end{array}
		\right)	
		= Id
		$$
		o que implica que devemos ter $B^{t}C =C^{t}B$, logo pelo Lema $\ref{lema_caracterizacao_Sp2n}$ temos que $F(Z) \in \gruposimpletico{2n}$. Portanto $F(Z) \in \matrizSimpleticaOrtogonal $ o que implica que $F(\matrizunitaria{n}) \subseteq \matrizSimpleticaOrtogonal$.
		
		Vamos mostrar a inclusão $\matrizSimpleticaOrtogonal \subseteq F(\matrizunitaria{n})$. 
		
		Se $A \in \matrizSimpleticaOrtogonal$, então $A^{t}=A^{-1}$ e $\estruturacomplexa=A^{t}\estruturacomplexa  A=A^{-1}\estruturacomplexa A$, o que implica que $A\estruturacomplexa=\estruturacomplexa A$. Assim:
		$$
		\begin{aligned}
		A\estruturacomplexa&=\estruturacomplexa A
		\\
		\left(
		\begin{array}{cc}
		B & C
		\\
		D & E
		\end{array}
		\right)
		\left(
		\begin{array}{cc}
		0 & -Id
		\\
		Id & 0
		\end{array}
		\right)
		&=
		\left(
		\begin{array}{cc}
		0 & -Id
		\\
		Id & 0
		\end{array}
		\right)
		\left(
		\begin{array}{cc}
		B & C
		\\
		D & E
		\end{array}
		\right)
		\\
		\left(
		\begin{array}{cc}
		C & -B
		\\
		E & -D
		\end{array}
		\right)
		&=
		\left(
		\begin{array}{cc}
		-D & -E
		\\
		B & C
		\end{array}
		\right), 
		\end{aligned}
		$$
		logo temos $C=-D$ e $B=E$, portanto:
		$$
		A=\left(
		\begin{array}{cc}
		B & -C
		\\
		C & B
		\end{array}
		\right),
		$$
		
		Tomando $Z = B+iC \in \matrizunitaria{n}$ temos que $F(Z) = A$, o que implica que $\matrizSimpleticaOrtogonal \subseteq F(\matrizunitaria{n})$. Conclusão, $\matrizSimpleticaOrtogonal = F(\matrizunitaria{n})$. 
		
		Como $F$ é monomorfismo, então $F|_{\matrizunitaria{n}}:\matrizunitaria{n} \to \matrizSimpleticaOrtogonal$ é sobrejetora sobre sua imagem, portanto é um isomorfismo.
	\end{prova}
	
	Analisaremos agora o espectro $\espectrooperador{A}$ de um simplectomorfismo $A \in \gruposimpletico{2n}$ de um determinado espaço vetorial. Tal resultado será usado na demonstração da contratibilidade do quociente $\gruposimpletico{2n}/\matrizSimpleticaOrtogonal$, que por sua vez será utilizado na construção do índice de Maslov.
	
	\begin{lema}
		Seja $A \in \gruposimpletico{2n}$. Então, $A, A^{-1}, A^{t}$ são semelhantes. Com isso, $\sigma(A) = \sigma(A^{-1}) = \sigma(A^{t}) $.
	\end{lema}
	\begin{prova}
		Temos que $A^{t}\estruturacomplexa A = \estruturacomplexa$. Supondo que $A$ seja invertível, então $A^{t} = \estruturacomplexa A^{-1} \estruturacomplexa^{-1}$. Logo $A^{t}$ é semelhante a $A^{-1}$. Sabe-se que $A$ é semelhante a $A^{t}$, logo $A$ é semelhante a $A^{-1}$. Como matrizes semelhantes possuem o mesmo polinômio característico, então $\sigma(A) = \sigma(A^{-1}) = \sigma(A^{t}) $.
	\end{prova}
	
	\begin{observacao}
		$\lambda \in \sigma(A)$ se , e somente se, $\lambda^{-1}\in \sigma(A)$.
	\end{observacao}
	
	\begin{lema}\label{lema_auto_espaco_grupo_simpletico}
		(Auto-espaços de $\gruposimpletico{2n}$) Sejam $(V, \omega)$ um 2n-espaço vetorial simplético, $A \in \gruposimpletico{2n}$ e $r,s \in \inteiros$ tais que $r\geq 1$ e $s\geq 1$. Se $\lambda, \mu \in \sigma(A)$ sejam tais que $\lambda\mu \neq 1$, então seus auto-espaços generalizados $E_{\lambda}=Ker(A-\lambda Id)^{r}$ e  $E_{\mu}=Ker(A-\mu Id)^{s}$ são $\omega$-ortogonais, isto é, $\omega(E_{\lambda}, E_{\mu}) = 0$.
	\end{lema}
	\begin{prova}
		Seja $P(r,s)$ a propriedade que queremos mostrar. Por indução finita, vejamos que $P(1,1)$ é verdadeira. Dados $v\in E_{\lambda}$ e $u\in E_{\mu}$ temos que $\formaSimpletica{v}{u} = \formaSimpletica{Av}{Au} = \lambda\mu\formaSimpletica{v}{u}$, o que implica que $\formaSimpletica{v}{u} = 0$, pois $\lambda\mu\neq 1$. Aplicando a hipótese de indução no índice $s$, podemos assumir que $P(1,s)$ é verdadeira e que $u \in Ker(A-\mu Id)^{s+1}$. Com isso, $0=(A-\mu Id)^{s+1}u = (A-\mu Id)^{s}(A-\mu Id)u $, logo $(A-\mu Id)u \in Ker(A-\mu Id)^{s}$, o que implica em
		$$
		\begin{aligned}
		\formaSimpletica{v}{u}
		&=\formaSimpletica{Av}{Au}
		\\
		&= \formaSimpletica{Av}{Au -\mu u +\mu u} 
		\\
		&= \lambda\underbrace{\formaSimpletica{v}{(A-\mu Id)u}}_{=0}+\lambda\mu\formaSimpletica{v}{u}
		\\
		&=\lambda\mu\formaSimpletica{v}{u}.
		\end{aligned}
		$$
		Como $\lambda\mu \neq 1$, então $\formaSimpletica{v}{u}=0$ e $P(1, s+1)$ é verdadeira.
		
		Concluímos que $P(1, s)$ é verdadeira para todo $s\geq 1$. Analogamente, mostramos por indução que P(r,1) é verdadeira para todo $r\geq 1$. Para mostrar que P(r,s) é verdadeira por indução, assumimos que P(r,s+1) e P(r+1,s) são verdadeiras e, analogamente mostramos que P(r+1,s+1) é verdadeira. Portanto $\omega(E_{\lambda}, E_{\mu}) = 0$ para quaisquer inteiros $r\geq 1$ e $s\geq 1$.
		
	\end{prova}
	
	\begin{corolario}\label{corolario_restricao_forma_simpletica}
		Sejam $A \in \gruposimpletico{2n}$ e $\lambda, \mu \in \sigma(A)$. Então 
		\begin{enumerate}
			\item Se $\lambda\mu \neq 1$, então $\formaSimpletica{E_{\lambda}}{E_{\mu}} = 0$.
			\item As restrições $\omega|_{E_{\pm 1}}$ são não-degeneradas. Além disso, suas multiplicidades $m(\pm 1)$ são pares.
			\item Se $\lambda \neq \pm 1$, então a restrição $\omega|_{E_{\lambda} \oplus E_{\lambda^{-1}}}$ é não-degenerada.
		\end{enumerate}
	\end{corolario}
	\begin{prova}
		\begin{enumerate}
			\item Dados $v \in E_{\lambda}$ e $u \in E_{\mu}$, temos pelo Lema $\ref{lema_auto_espaco_grupo_simpletico}$ que $\formaSimpletica{v}{u} = 0$, então a restrição $\omega|_{E_{\lambda} \oplus E_{\mu}}:E_{\lambda} \oplus E_{\mu}\to \reta$ é identicamente nula. Logo, $\formaSimpletica{E_{\lambda} }{E_{\mu}} = 0$.
			
			\item  Faremos primeiro o caso em que $\lambda = \mu =1$. Suponha que $\omega|_{E_{1}}$ seja degenerada. Então existe $v\neq 0 \in E_{1}$ tal que $\omega(v, u) = 0$ para todo $u \in E_{1}$. Seja $\beta \in \complementar{\sigma(A)}{\{1 \}}$. Pelo Lema $\ref{lema_auto_espaco_grupo_simpletico}$ temos que $\formaSimpletica{E_{1}}{E_{\beta}} = 0$. Pelo Teorema $\ref{teorema_espectral_jordan}$ podemos escrever $V = E_{1}  \bigoplus_{\lambda \in \complementar{\sigma(A)}{ \{1\}  }}E_{\lambda}$. Com isso, $\formaSimpletica{v}{V} = 0$. Logo $\omega$ é degenerada, o que contradiz a hipótese. Portanto $\omega|_{E_{1}}$ é não-degenerada. Além disso, como $\lambda = \lambda^{-1}$, então a multiplicidade $m(1)$ é par. Com argumento análogo para $\lambda = \mu = -1$ temos que $\omega|_{E_{-1}}$ é não-degenerada e $m(-1)$ é par. 
			
			\item Pelo Lema $\ref{lema_auto_espaco_grupo_simpletico}$ podemos escrever $V = E_{1}  \bigoplus E_{-1}  \bigoplus_{\lambda \in \complementar{\sigma(A)}{ \{\pm 1\}  }}E_{\lambda}$. Supondo que $\omega|_{B}$ seja degenerada, onde $E= E_{\lambda} \oplus E_{\lambda^{-1}}$, então $v \neq 0 \in E$ tal que 
			$\omega(v,a)=0$ para todo $a\in E$. Além disso, pela $\omega$-ortogonalidade,  $\omega(v,E_{\beta})=0$, para todo $\beta\in \complementar{\sigma(A)}{\{1\} }$. Segue do Teorema $\ref{teorema_espectral_jordan}$ analogamente ao item anterior que $\omega(v,V)=0$, o que contradiz a hipótese de $\omega$ ser não degenerada.
		\end{enumerate}
	\end{prova}
	
	\begin{proposicao}\label{proposicao_potenciacao_grupo_simpletico}
		(Potênciação em $\gruposimpletico{2n}$) Seja $\gruposimpleticopositivo{2n} = \gruposimpletico{2n} \cap \matrizsimetricapositiva{2n}$ o conjunto das matrizes simpléticas simétricas e positivas-definidas. Dado $A \in \gruposimpleticopositivo{2n}$, então $A^{\alpha} \in \gruposimpletico{2n}$ para qualquer $\alpha \in \real{}$.
	\end{proposicao}
	\begin{prova}
		Seja $A \in \gruposimpleticopositivo{2n}$, então $A$ é simétrica, logo é normal, e pelo Lema $\ref{lema_caracterizacao_matriz_normal}$ é diagonalizável. Além disso, pela Observação $\ref{observacao_matriz_positiva_definida}$ seus auto-valores são todos positivos. Podemos decompor $V$ na soma direta de seus auto-espaços $E_{\lambda}$, onde $\lambda \in \espectrooperador{A}$. Se $u \in E_{\lambda_{u}}$ e $v \in V_{\lambda_{v}}$, então
		$$
		\omega(A^{\alpha}u,A^{\alpha}v) = 		(\lambda_{u}\lambda_{v})^{\alpha}\omega(u,v).
		$$
		Se $\lambda_{u}\lambda_{v}\neq 1$, então $\omega(u,v)=0$, o que implica que $\omega(A^{\alpha}u,A^{\alpha}v)=(\lambda_{u}\lambda_{v})^{\alpha}\omega(u,v)=0$, logo $\omega(A^{\alpha}u,A^{\alpha}v) = \omega(u,v)=0$, portanto $A^{\alpha} \in \gruposimpletico{2n}$. Caso $\lambda_{u}\lambda_{v}=1$ temos $\omega(A^{\alpha}u,A^{\alpha}v) = \omega(u,v)$, portanto $A^{\alpha} \in \gruposimpletico{2n}$.
	\end{prova}
	
	\begin{observacao}\label{observacao_determinante_matriz_unitaria}
		Note que, dado $A \in \matrizunitaria{n}$, temos $1= det(AA^{*}) = det(A)det(A^{*}) = det(A)\overline{det(A)} = ||det(A)||^{2}$, portanto $det(\matrizunitaria{n}) \subseteq S^{1}$.
	\end{observacao}
	
	
	\begin{lema}\label{lema_conexidade_matriz_unitaria}
		$\matrizSimpleticaOrtogonal$ é conexo por caminhos, logo é conexo.
	\end{lema}
	\begin{prova}
		Seja $A \in \matrizunitaria{n}$. Então $A$ é diagonalizável, e $det(A) \in S^{1}$, e pela Observação $\ref{observacao_caracterizacao_matriz_normal}$ existe uma matriz unitária $U$ tal que $A=U^{*}diag\{e^{i\theta_{1}}, \dots, e^{i\theta_{n}}\}U$, com isso temos $det(A) = e^{i(\theta_{1}+\dots+\theta_{n})} \in \circulo$. Definindo o caminho contínuo $\gamma:[0,1] \to \matrizunitaria{n}$ tal que $\gamma(\lambda)=U^{*}diag\{e^{i\theta_{1}\lambda}, \dots, e^{i\theta_{n}\lambda}\}U$, temos $\gamma(0)=Id$ e $\gamma(1)=A$. Temos que $\gamma$ está bem-definida pois $D=diag\{e^{i\theta_{1}\lambda}, \dots, e^{i\theta_{n}\lambda}\}$ é tal que $D^{*}D = Id$, logo $D \in \matrizunitaria{n}$. Além disso, $U^{*}, U \in \matrizunitaria{n}$, por construção. Então temos que $\gamma(\lambda) \in \matrizunitaria{n}$. Notemos que $det(\gamma(\lambda)) = e^{i\lambda(\theta_{1}+\dots+\theta_{n})} \in \circulo$, logo $\gamma([0,1]) \subset \matrizunitaria{n}$. Com isso, toda $A \in \matrizunitaria{n}$ pode ser conectada a $Id$ por um caminho contínuo, logo $\matrizunitaria{n}$ é conexo por caminhos, portanto é conexo. Pelo Lema $\ref{lema_isomorfismo_U}$ temos que $F|_{\matrizunitaria{n}}:\matrizunitaria{n} \to \matrizSimpleticaOrtogonal$ é um isomorfismo contínuo, logo é um homeomorfimo. Como $\matrizunitaria{n}$ é conexo e a conexidade é preservada por aplicações contínuas, então $\matrizSimpleticaOrtogonal = F(\matrizunitaria{n})$ é conexo por caminhos, logo é conexo.
	\end{prova}
	
	\begin{lema}
		$\gruposimpleticopositivo{2n}$ é conexo por caminhos, logo é conexo.
	\end{lema}
	\begin{prova}
		Seja a aplicação contínua $\gamma:\gruposimpleticopositivo{2n}\times [0,1] \to \gruposimpletico{2n}$ tal que $\gamma(A,\lambda) = A^{\lambda}$. Pela Proposição $\ref{proposicao_potenciacao_grupo_simpletico}$, a aplicação $\gamma$ está bem-definida e é contínua. Fixando $A \in \gruposimpleticopositivo{2n}$ temos a curva $\gamma_{A}:[0,1]\to \gruposimpletico{2n}$ tal que $\gamma_{A}(0) = Id$ e $\gamma_{A}(1) = A$, ou seja, é um caminho contínuo que conecta a identidade a matriz $A$. Como $A=A^{t}$, segue da Proposição $\ref{proposicao_potenciacao_grupo_simpletico}$ que $\gamma_{A}(\lambda)^{t} = (A^{\lambda})^{t} = (A^{t})^{\lambda} = (A)^{\lambda} = \gamma_{A}(\lambda)$. Além disso, os k-subdeterminantes $det_{k}(\gamma_{A}(\lambda)) = det_{k}(A^{\lambda}) > 0$ para $1\leq k \leq 2n$. Pelo fato de que $\gamma_{A}(\lambda)$ é simétrica e pelo Teorema $\ref{teorema_matriz_positiva_definida}$ temos que $\gamma_{A}(\lambda)$ é positiva-definida, logo $\gamma_{A}([0,1]) \subset \gruposimpleticopositivo{2n}$. Como $A \in \gruposimpleticopositivo{2n}$ é arbitrária, então a construção anterior vale para quaisquer elementos de $\gruposimpleticopositivo{2n}$. Com isso, dados $A, B \in \gruposimpleticopositivo{2n}$, podemos conectar $A$ a $B$ por uma curva contínua que passa pela identidade, portanto $\gruposimpleticopositivo{2n}$ é conexo por caminhos, logo é conexo.
	\end{prova}	
	
	\begin{lema}\label{lema_decomposicao_grupo_simpletico_positivo}
		Se $A \in \gruposimpletico{2n}$, então existem únicas $P \in \gruposimpleticopositivo{2n}$ e $O \in \matrizSimpleticaOrtogonal$ tal que $A=PO$.
	\end{lema}
	\begin{prova}
		Segue do Teorema $\ref{teorema_decomposicao_polar}$ que $A=PO$, onde $P=AA^t$ é positiva definida e O é uma matriz ortogonal. Como $A$ e $A^{t} $ são matrizes simpléticas, então $P=AA^{t}\in \gruposimpletico{2n}$. 
		Além disso, como $\gruposimpletico{2n}$ é grupo então $P^{-1}\in \gruposimpletico{2n}$, logo $O=P^{-1}A \in \mathcal{U}$.
	\end{prova}
	
	\begin{teorema}\label{teoerma_sp2n_conexo}
		$\gruposimpletico{2n}$ é conexo por caminhos, logo é conexo.
	\end{teorema}
	\begin{prova}
		Se $A \in \gruposimpletico{2n}$, então pelo Lema $\ref{lema_decomposicao_grupo_simpletico_positivo}$ podemos escrever $A=PO$ onde $P \in \gruposimpleticopositivo{2n}$ e $O\in \matrizSimpleticaOrtogonal$ são únicas. Pela unicidade da decomposição anterior a aplicação $G: \gruposimpletico{2n} \to \gruposimpleticopositivo{2n} \times \matrizSimpleticaOrtogonal$ definida por $G(A) = (P,O)$ é injetora. Por outro lado, dado $(P,O) \in \gruposimpleticopositivo{2n} \times \matrizSimpleticaOrtogonal$ temos $(PO)^{t}\estruturacomplexa PO = O^{t}P^{t}\estruturacomplexa PO = O^{t}\estruturacomplexa O = \estruturacomplexa$, logo pelo Lema $\ref{lema_caracterizacao_Sp2n}$, temos $PO \in \gruposimpletico{2n}$ e $G$ é sobrejetora. De fato, definindo $A=PO \in \gruposimpletico{2n}$ temos que $G(A) = (P,O)$. Portanto $G$ é bijetora. Seja $G^{-1}:\gruposimpleticopositivo{2n} \times \matrizSimpleticaOrtogonal\to \gruposimpletico{2n}$ tal que $G^{-1}(P,O) = PO$. Então, podemos ver que $G\circ G^{-1} = Id$ e $G^{-1} \circ G= Id$, logo $G^{-1} $ é a inversa de $G$. Como $G$ e $G^{-1} $ são aplicações contínuas, então $G$ é um homeomorfismo. Podemos afirmar que $\gruposimpleticopositivo{2n}\times \matrizSimpleticaOrtogonal$ é conexo por caminhos, pois é o produto cartesianos de espaços topológicos conexos por caminhos e, como funções contínuas preservam a conexidade, então $G^{-1}(\gruposimpleticopositivo{2n}\times \matrizSimpleticaOrtogonal) = \gruposimpletico{2n}$ é conexo por caminhos, logo é conexo.
	\end{prova}
	
	\begin{observacao}\label{observacao_decomposicao_Sp2n}
		No teorema anterior exibimos um homeomorfismo $G:\gruposimpletico{2n} \to \gruposimpleticopositivo{2n} \times \matrizSimpleticaOrtogonal$, isto é, mostramos que se $A \in \gruposimpletico{2n}$, então ela pode ser decomposta unicamente como $A=PO$, onde $P\in \gruposimpleticopositivo{2n}$ e $O \in \matrizSimpleticaOrtogonal$. Usaremos essa afirmação na demonstração de alguns resultados adiante.
	\end{observacao}
	
	\begin{teorema}
		O quociente $\gruposimpletico{2n}/\matrizSimpleticaOrtogonal$ é contrátil.
	\end{teorema}
	\begin{prova}
		No Lema $\ref{lema_decomposicao_grupo_simpletico_positivo}$ foi mostrado que se $A \in \gruposimpletico{2n}$ temos $A=PO$, onde $P \in \gruposimpleticopositivo{2n}$ e $O \in \matrizSimpleticaOrtogonal$. Com isso temos $AA^{t} = POO^{t}P^{t} = PP^{t}=P^{2}$. Como $A,A^{t} \in \gruposimpletico{2n}$, então $AA^{t} =P^{2} \in \gruposimpletico{2n}$ pois $\gruposimpletico{2n}$. Pela Proposição $\ref{proposicao_potenciacao_grupo_simpletico}$ anterior podemos afirmar que $P^{\alpha} \in \gruposimpletico{2n}$ para todo $\alpha \in \real{}$. Definindo a aplicação $r:\gruposimpletico{2n}\times [0,1] \to \gruposimpletico{2n}$ tal que $r(A, \alpha) = (AA^{t})^{-\alpha/2}A$ é contínua pois é o produto de matrizes, que é uma operação contínua em $\gruposimpletico{2n}$. Temos que $r$ é um retrato de deformação de $\gruposimpletico{2n}$ sobre $\matrizSimpleticaOrtogonal$ pois $r(A, 0) = A$, $r(A, 1) = (AA^{t})^{-1/2}A = P^{-1}A = O \in \matrizSimpleticaOrtogonal$ e, por fim, tomando $B \in \matrizSimpleticaOrtogonal$ temos $r(B, 1) = (BB^{t})^{-1/2}B = B$, pois $BB^{t} = Id$.
		
		Por brevidade denotaremos $\mathcal{S} = \gruposimpletico{2n}/\matrizSimpleticaOrtogonal$. Definindo a aplicação $R:\mathcal{S} \times [0,1] \to \mathcal{S}$ tal que $R([A], \lambda) = [r(A, \lambda)] = [(AA^{t})^{-\lambda/2}A]$, temos que $R$ é uma contração. De fato, a imagem de $R$ é a classe de equivalência da imagem de $r$, que é contínua, portanto $R$ é contínua. Além disso, $R([A], 0) = [A]$, $R([A], 1) = [(AA^{t})^{-1/2}A] = [P^{-1}A] = [O] = [Id]$, pois $O \in \matrizSimpleticaOrtogonal$, isto é, $R(., 0) = Id_{\mathcal{S}}(.)$ é a identidade e $R(., 1) = [Id]$ é a aplicação constante, logo é uma contração e $\mathcal{S}$ é contrátil.
	\end{prova}
	
	\begin{observacao}\label{observacao_quociente_grupo_simpletico_contratil}
		Na demonstração da contratibilidade do quociente $\gruposimpletico{2n}/\matrizSimpleticaOrtogonal$ mostramos que $\matrizSimpleticaOrtogonal$ é um retrato por deformação de $\gruposimpletico{2n}$, logo todo caminho contínuo em $\gruposimpletico{2n}$ pode ser deformado contínuamente em um caminho contínuo em $\matrizSimpleticaOrtogonal$.
	\end{observacao}
	
	\begin{observacao}\label{observacao_conexidade_grupo_simpletico}
		Até o momento demonstramos muitos lemas técnicos afim de examinarmos algumas características da topologia de $\gruposimpletico{2n}$ com o objetivo de mostrarmos que esse conjunto é conexo. Esse resultado é fundamental para a construção da homologia de Floer, pois, para definirmos um complexo de cadeias nessa homologia devemos ter um homomorfismo graduado. Tal graduação será dada pelo índice de Maslov e este será relacionado grupo fundamental $\grupofundamental{\gruposimpletico{2n}}$. Por fim, a estratégia adotada necessita que $\grupofundamental{\gruposimpletico{2n}} \cong \inteiros$. Para mostrar esse fato precisamos da conexidade.
	\end{observacao}
	
	\begin{teorema}
		$\grupofundamental{\gruposimpletico{2n}} \cong \inteiros$.
	\end{teorema}
	\begin{prova}
		Como $\matrizSimpleticaOrtogonal$ é um retrato de deformação de $\gruposimpletico{2n}$, então $\grupofundamental{\gruposimpletico{2n}}$ e $\grupofundamental{\matrizSimpleticaOrtogonal}$ são isomorfos. Do Lema $\ref{lema_isomorfismo_U}$ temos que $\matrizSimpleticaOrtogonal\cong \matrizunitaria{n}$, logo $\grupofundamental{\matrizSimpleticaOrtogonal} \cong \grupofundamental{\matrizunitaria{n}} \cong \inteiros$ e $\grupofundamental{\gruposimpletico{2n}} \cong \inteiros$.
	\end{prova}
	
	Definamos os conjuntos $\gruposimpleticonaodegenerado{*} = \{ A \in \gruposimpletico{2n}: det(Id-A)\neq 0 \}$, $\gruposimpleticonaodegenerado{+} = \{ A \in \gruposimpletico{2n}: det(Id-A)> 0 \}$ e  $\gruposimpleticonaodegenerado{-} = \{ A \in \gruposimpletico{2n}: det(Id-A)< 0 \}$.
	
	O seguinte lema será usado nas próximas demostrações e sua demonstração pode ser encontrada em $\cite{audi_floer_homology}$.
	
	\begin{lema}\label{lema_conectividade_grupo_simlpetico_nao_degenerado}
		Seja $A\in \gruposimpleticonaodegenerado{*}$. Então existe um caminho contínuo em $\gruposimpleticonaodegenerado{*}$ conectando $A$ a uma matriz $B \in \gruposimpleticonaodegenerado{*}$ cujos  auto-valores são todos distintos com uma das seguintes condições: 1) se $A\in \gruposimpleticonaodegenerado{+}$, então $B$ não possui auto-valores reais positivos ou 2) se $A\in \gruposimpleticonaodegenerado{-}$, então $B$ possui apenas 2 auto-valores reais positivos.
	\end{lema}
	
	\begin{lema}
		$\gruposimpleticonaodegenerado{*} = \gruposimpleticonaodegenerado{+}\cup \gruposimpleticonaodegenerado{-}$, onde $\gruposimpleticonaodegenerado{\pm}$ são as duas componentes conexas por caminhos, portanto conexas.
	\end{lema}
	\begin{prova}
		A demonstraçãõ não esta completa e será finalizada futuramente.
	\end{prova}
	
	\begin{corolario}
		A inclusão $\gruposimpleticonaodegenerado{*} \hookrightarrow \gruposimpletico{2n}$ induz o homomorfismo trivial entre os grupos fundamentais.
	\end{corolario}
	\begin{prova}
		A demonstração não esta completa e será finalizada futuramente.
	\end{prova}
	
	\chapter{Índice de Maslov - A Construção de Conley-Zehnder}
	\section{Motivação}
	Considere a função Hamiltoniana dependente do tempo $H:M\times \reta\to \reta$ ao qual associamos o campo vetorial $X_{H} \in \campossuaves{M}$, chamado campo Hamiltoniano, e definido pela equação $\formaSimpletica{\campohamiltoniano{t}}{Y} = -dH(Y)$, cujo fluxo $\psi:M\times \reta \to M$ é solução do sistema Hamiltoniano
	$$
	\derivadaparcial{\psi(t)}{t} = X_{H}(\psi(t), t)
	$$
	satisfazendo as condições periódicas de contorno $\psi(t+1) = \psi(t)$, $\psi(0) = \psi_{0}$ e $\dot{\psi}(0) = \campohamiltoniano{0}$. Tais soluções são chamadas de soluções 1-periódicas das equações de Hamilton. Além disso, buscamos as soluções 1-periódicas que são contráteis, isto é, homotópicas a uma curva constante. Elas são pontos críticos do funcional de ação $f_{H}$. Analogamente a Teoria de Morse vamos atribuir um índice (um número inteiro) a cada um desses pontos críticos, o qual denominaremos por índice de Maslov.
	
	Vamos realizar a associação $\reta/\mathbb{Z} \ni t \mapsto A(t) \in \gruposimpletico{2n}$, onde $A$ é um caminho contínuo tal que $A(0) = Id$ e $det(Id - A(t))\neq 0$. Para cada um desses caminhos teremos a associação $\gruposimpletico{2n} \ni A(t) \mapsto \rho(A) \in \circulo$. Por fim, teremos o índice de Maslov $A \mapsto \mu(A) \in \inteiros$.
	
	\section{Axiomatização}
	
	Originalmente, o índice de Maslov foi definido para associar uma caminho fechado $\caminhossempontobase{\gruposimpletico{2n}} \ni \gamma \mapsto \inteiros$. Contudo, existe uma pluralidade de definições equivalentes desse mesmo objeto, e por equivalente entende-se aquelas definições que satistazem a mesma axiomatização. Em $\cite{cappell_maslov_index_equivalencia}$ pode-se encontrar quatro definições distintas e a demonstração de suas equivalências.
	
	Sejam $(V, \omega)$ um 2n-espaço vetorial simplético, $L_{V}$ o conjunto dos subespaços Lagrangianos de $V$ e   $\caminhoslagrangianosV{a}{b}= \{\gamma:[a,b]\to L_{V}\times L_{V}\}$ o conjunto de todos os caminho contínuos e suaves por partes em $L_{V}$. Como topologia de $\caminhoslagrangianosV{a}{b}$ vamos adotar a topologia compacto-aberta (veja $\cite{munkres_topology}$). Um índice de Maslov é uma aplicação $\mu:\caminhoslagrangianosV{a}{b}\to \inteiros$ satisfazendo as seguintes propriedades:
	\begin{enumerate}
		\item \textbf{\textit{(Invariância por Translação)}} Seja $g: [a,b] \to [ak+l, bk+l]$ tal que $g(t)=at+l$, para $k>0$ e $l\geq 0$. Então, dado $\gamma\in \caminhoslagrangianosV{ak+l}{bk+l}$ temos que 
		$$
		\mu(\gamma) = \mu(\gamma\circ g).
		$$
		\item \textbf{\textit{(Invariância por Homotopia)}} Sejam $\gamma, \beta \in \caminhoslagrangianosV{a}{b}$ e $h:[0,1] \times [a,b] \to L_{V}\times L_{V}$ uma homotopia de extremos fixos entre $\gamma$ e $\beta$. Então
		$$
		\mu(\gamma) = \mu(\beta).
		$$
		\item \textbf{\textit{(Aditividade de Caminhos)}} Se $a<b<c$ e $\gamma \in \caminhoslagrangianosV{a}{c}$, então $$
		\mu(\gamma)=\mu(\gamma|_{[a,b]})+\mu(\gamma|_{[b,c]}).
		$$
		\item \textbf{\textit{(Aditividade Simplética)}} Sejam $V$ e $V'$ 2n-espaços vetoriais simpléticos, $\gamma \in \caminhoslagrangianosV{a}{b}$ e $\gamma' \in \caminhoslagrangianos{a}{b}{V'}$ dadas por $\gamma(t) = (L_{1}(t), L_{2}(t))$, $\gamma'(t) = (L'_{1}(t), L'_{2}(t))$, respectivamente, onde $L_{j}, L'_{j}: [a,b] \to L_{V}$ são aplicações contínuas por partes. Defina $\gamma\oplus\gamma' \in \caminhoslagrangianos{a}{b}{V\oplus V'}$ tal que $(\gamma\oplus\gamma' )(t) = (L_{1}(t)\oplus L_{1}'(t), L_{2}(t)\oplus L_{2}'(t))$. Então 
		$$
		\mu(\gamma\oplus\gamma' )= \mu(\gamma)+\mu(\gamma' ).
		$$
		\item \textbf{\textit{(Invariância Simplética)}} Sejam $\gamma \in \caminhoslagrangianosV{a}{b}$ e $\phi:[a,b]\times \gruposimpletico{V} \to \gruposimpletico{V}$ uma família contínua e suave por partes de simplectomorfimos. Defina $\phi_{*}: \caminhoslagrangianosV{a}{b} \to \caminhoslagrangianosV{a}{b}$ tal que $ (\phi_{*}\gamma)(t) = (\phi(t, L_{1}(t)), \phi(t, L_{2}(t)))$. Então 
		$$
		\mu(\phi_{*}\gamma) = \mu(\gamma)).
		$$
		\item \textbf{\textit{(Normalização)}} Consideremos o espaço vetorial simplético $\complexo{}$ munido do produto interno $\iprod{v}{u} = v_{1}u_{2}- v_{2}u_{1} = Re(i(v_{1}+iv_{2})\overline{(u_{1}+iu_{2})})$, onde $v=v_{1}+iv_{2},u =u_{1}+iu_{2}\in \complexo{}$. Defina $\gamma \in \caminhoslagrangianos{-\pi/4}{\pi/4}{\complexo{}}$ tal que $\gamma(t) = (\reta(1), \reta(e^{it}))$. Então
		\begin{enumerate}
			\item $\mu(\gamma|_{[-\pi/4, \pi/4]}) = 1;$
			\item $\mu(\gamma|_{[-\pi/4, 0]}) = 0;$
			\item $\mu(\gamma|_{[0, \pi/4]}) = 1.$	
		\end{enumerate}
		\begin{comment}
			\begin{observacao}
				Esse último axioma contém uma discussão mais extensa com diagramas esquemáticos em $\cite{cappell_maslov_index_equivalencia}$.
			\end{observacao}
		\end{comment}

	\end{enumerate}
	
	\section{Contrução de $\rho: \gruposimpletico{2n} \to \circulo$}
	Para a construção do índice de Maslov vamos adotar as complexificações $(\real{2n}, \formaSimpleticaabrev) \hookrightarrow (\complexo{2n}, \Omega)$ e $\gruposimpleticoreal{2n} \hookrightarrow \gruposimpleticocomplexo{2n}$ citadas no Seção $\ref{secao_complexificacao_espacos_vetoriais}$. Temos como candidato para aplicação contínua $\rho: \gruposimpletico{2n} \to \circulo$ a função determinante. De fato, temos $\matrizSimpleticaOrtogonal \subset \gruposimpletico{2n}$ e $\rho|_{\matrizSimpleticaOrtogonal}=det|_{\matrizSimpleticaOrtogonal}:\matrizSimpleticaOrtogonal \to \circulo$ (veja a Observação $\ref{observacao_determinante_matriz_unitaria}$). Notemos que apenas a imagem da restrição $\rho$ esta em $\circulo$. O seguinte lema mostra que essa restrição pode ser continuamente para uma única aplicação  $\rho: \gruposimpletico{2n} \to \circulo$.
	
	Sejam $(V, \omega)$ um 2n-espaço vetorial simplético e $\gruposimpletico{V}$ o grupo dos simplectomorfismos em $V$. 
	\begin{teorema}\label{teorema_aplicacao_rho}
		Sejam $(V_{1}, \omega_{1})$ e $(V_{2}, \omega_{2})$ 2n-espaços vetoriais simpléticos. Existe uma aplicação contínua $\rho:Sp(2n) \to S^{1}$ satisfazendo as seguintes propriedades:
		\begin{enumerate}
			\item \textbf{Naturalidade:}  Se $T:V_{1} \to V_{2}$ é um isomorfismo simplético, isto é, $T^{*}\omega_{2} = \omega_{1}, $então 
			$$
			\rho(TAT^{-1}) = \rho(A)
			$$
			para toda $A\in \gruposimpletico{V_{1}}$.
			
			\item \textbf{Produto:} Se $(V,\omega) = (V_{1}\times V_{2},\omega_{1}\times \omega_{2})$, então
			$$
			\rho(A) = \rho(A_{1})\rho(A_{2})
			$$
			para $A\in \gruposimpletico{V}$ definida por $A(v_{1}, v_{2})=(A_{1}v_{1}, A_{2}v_{2})$, onde $A_{i} \in \gruposimpletico{V_{i}}$.
			
			\item \textbf{Deteminante:} Se $A\in \gruposimpleticopositivo{2n}$, então 
			$$
			\rho(A) = det(X+iY), \text{onde} \;	
			A=\left(
			\begin{array}{cc}
			X & -Y					\\
			Y & X
			\end{array}
			\right).
			$$
			Além disso, a aplicação indizuda $\rho_{*}: \grupofundamental{\gruposimpletico{2n}} \to \grupofundamental{\circulo} \cong \inteiros$ é um isomorfismo.
			
			\item \textbf{Normalização:} Se $A \in \gruposimpletico{2n}$ com $\sigma(A)\cap \circulo = \emptyset$, então $\rho(A) = \pm 1$.
		\end{enumerate}
	\end{teorema}
	
	\begin{comment}
		
		Na Seção $\ref{secao_complexificacao_espacos_vetoriais}$ foi mostrado que, dados $\lambda \in \sigma(A)$, temos que $\lambda, \lambda^{-1}, \overline{\lambda}, \overline{\lambda}^{-1}  \in \sigma(A)$ e dados $v, u \in \complexo{2n}$ temos $\formaSimpleticaExtendida{v}{u}= -iV^{t}U$, onde $V$ e $U$ são as representações matricias de $v$ e $u$, respectivamente. Suponha que $\lambda, \overline{\lambda} \in \circulo$, isto é $\lambda\overline{\lambda} = 1$. Então $0 \neq \formaSimpleticaExtendida{E_{\lambda}}{E_{\overline{\lambda}}} \in i\reta$. De fato, dados $v \in E_{\lambda}$ e $\overline{v} \in E_{\overline{\lambda}}$, temos que  $\formaSimpleticaExtendida{\overline{v}}{v} =-iV^{t}V=- i\norma{v}^{2}\in i\reta$. 
		
		Para construirmos uma aplicação que extenda contínuamente o determinante vamos introduzir uma ordenação nos auto-valores de $A$ de modo que tenhamos algo como $\{\lambda_{1} ,\dots,\lambda_{n},\lambda_{n}^{-1},\dots,\lambda_{1}^{-1} \}$. Sabemos que um auto-valor $\lambda$ podemo assumir um dos valores $|\lambda|\leq 1$ ou $|\lambda|>1$. Além disso, como são determimados em quádruplas $\lambda, \overline{\lambda}, \lambda^{-1}, \overline{\lambda}^{-1}$, basta analisarmos os casos em que $|\lambda| \leq 1$ pois, supondo $|\lambda|\leq 1$, teremos $|\lambda^{-1}|\geq 1$. O que implica $|\overline{\lambda}|\leq 1$ e $|\overline{\lambda}^{-1}|\geq 1$.
		
		Todo auto-valor $\lambda \in \complexo{}$ pode ser escrito como $\lambda = |\lambda|\exp(i\theta_{\lambda})$, para algum $\theta_{\lambda} \in [0,2\pi]$. Fixe $\lambda\in \sigma(A)$ tal que $|\lambda|<1$. Então diremos que $\lambda = \lambda_{1}$ se, para qualquer $\exp(i\theta_{\beta}) = \beta\in \sigma(A)$ com $|\beta|<1$ tivermos $|\lambda|\leq  |\beta|$ e $\theta_{\lambda}\leq \theta_{\beta}$. Tomando $\lambda \neq \lambda'\in \sigma(A)$, diremos que $\lambda' = \lambda_{2}$ se, para todo $\beta \in \complementar{\sigma(A)}{\{\lambda\} }$ com $|\beta|<1$ tivermos $|\lambda'|\leq  |\beta|$ e $\theta_{\lambda}\leq \theta_{\beta}$.  Repetindo esse procedimento n vezes teremos os conjunto ordenado $\{\lambda_{1} ,\dots,\lambda_{n},\lambda_{n}^{-1},\dots,\lambda_{1}^{-1} \}$.
		
		\begin{definicao}
		Seja $\gruposimpleticoespecial{2n} =\{A\in \gruposimpletico{2n} : m(\lambda) = 1,\;\forall \lambda\in \sigma(A) \}$ o conjunto das matrizes simpléticas cujos auto-valores são distintos e ordenados de acordo com a descrição anterior.
		\end{definicao}
		
		\begin{lema}
		A aplicação $\rho:\gruposimpleticoespecial{2n} \to \circulo$ definida por 
		$$
		\rho(A) = \prod_{j=1}^{n}\frac{\lambda_{j}}{|\lambda_{j}|}
		$$
		é contínua.
		\end{lema}
		\begin{prova}
		Como os auto-valores de $A$ são não-nulos, então podemos escrever $\lambda/|\lambda| = e^{i\theta}$. Com isso, $\rho(A)=\prod \lambda_{j}/|\lambda_{j}| = \prod e^{i\theta_{j}} = e^{i(\theta_{1}+\dots +\theta_{n})} \in \circulo$, onde $\lambda_{j}/|\lambda_{j}| = e^{i\theta_{j}}$ para $1\leq j \leq n$. Logo $\rho$ esta bem-definida.
		
		Pelo Teorema $\ref{teoerma_sp2n_conexo}$ sabemos que $\gruposimpletico{2n}$ é conexo por caminhos. Com isso, na topologia herdada de $\generalgroupcomplexo{2n}$, dado $1>\epsilon >0$ tal que $\norma{A-B}< \epsilon$ as representação diagonal $D_{A}$ e $D_{B}$, respectivamente, também satisfazem $\norma{D_{A}-D_{B}}< \epsilon$, isto é, $sup|\lambda_{j}-\beta_{k}| < \epsilon$, onde $\beta_{k} \in \sigma(B)$. Sejam $\alpha = inf \{|\lambda_{j}|,|\beta_{j}|\}$. Então
		$$
		|\rho(A) -\rho(B)| < \Big|\prod_{j=1}^{n} \frac{\lambda_{j}}{\alpha} - \frac{\beta_{j}}{\alpha} \Big| <\frac{1}{\alpha}\prod_{j=1}^{n} sup|\lambda_{j} - \beta_{j}|=\frac{\epsilon^{n}}{\alpha}<\epsilon.
		$$
		Portanto, $\rho$ é contínua.
		\end{prova}		
	\end{comment}
	
	A etapa final desse capítulo é a demonstração de que $\rho$ pode ser extendida contínuamente para $\gruposimpletico{2n}$ e com isso provaremos que $\rho$ satisfaz todas as condições do Teorema $\ref{teorema_aplicacao_rho}$. Parte das demonstrações foram feitas, mas alguns resultados serão finalizados futuramente.
	
	\section{Índice de Maslov $\mu : \caminhossempontobase{\gruposimpletico{2n}} \to \inteiros$}
	
	Vimos na Seção $\ref{secao_grupo_simpletico}$ que $\gruposimpleticonaodegenerado{\pm}$ são as duas componentes conexas de  $\gruposimpleticonaodegenerado{*}\subset \gruposimpletico{2n}$, isto é, $\gruposimpleticonaodegenerado{*}=\gruposimpleticonaodegenerado{+}\cup\gruposimpleticonaodegenerado{-}$. Definindo $\Sigma = \{A \in \gruposimpletico{2n}: det(Id-A)=0 \}$, podemos escrever $\gruposimpletico{2n}=\gruposimpleticonaodegenerado{+}\cup\gruposimpleticonaodegenerado{-}\cup \Sigma$.
	
	Um dado caminho $\gamma:[0,1]\to \gruposimpletico{2n}$ pode partir de uma das componentes conexas $\gruposimpleticonaodegenerado{\pm}$ e cruzar $\Sigma$ um número finíto de vezes, sendo que esse número de cruzamentos será determinado pelo índice de Maslov. Para efetuar a contagem dos cruzamentos de $\gamma$ valos fixar dois pontos $W^{\pm} \in \gruposimpleticonaodegenerado{\pm}$. A definição do índice não dependerá dessa escolha, pois vimos na Seção $\ref{secao_grupo_simpletico}$ que ambas são conexar por caminhos. Com isso, o caminho conectando um dado $A \in \gruposimpletico{2n}$ a $W^{+}$ pode ser conectado a um outro ponto $U^{+} \in \gruposimpleticonaodegenerado{+}$ através do caminho que conecta $W^{+}$ a $U^{+}$. Com uma construção análoga, o mesmo é válido para $W^{-} \in \gruposimpleticonaodegenerado{-}$. 
	
	\begin{definicao}
		(Índice de Maslov) Sejam $exp:\real{} \to \circulo \subset \mathbb{C}$ a aplicação exponencial e $W^{\pm} \in Sp(2n)^{\pm}$ duas matrizes fixas. Para cada curva $\gamma:[0,1] \to Sp(2n)$ escolhamos o levantamento $\alpha:[0,1] \to \real{}$ de $\rho\circ \gamma$ tal que o diagrama abaixo comute
		$$
		\xymatrix{
			& & \real{}\ar[d]\ar[d]^{\text{exp}}
			\\
			[0,1 ]\ar[urr]^{\alpha} \ar[r]_{\gamma} & Sp(2n) \ar[r]_{\rho} & S^{1}
		}
		$$	
		Definamos $\varDelta(\gamma) = (\alpha(0) - \alpha(1))/\pi$. Seja $A \in Sp(2n)^{*}$ e uma determinada $\gamma_{A}:[0,1] \to Sp(2n)^{*}$ (sua homotopia esta bem-definida) com $\gamma_{A}(0) = A$ e $\gamma_{A}(1) = W^{\pm}$, então temos o número $\varDelta(\gamma_{A}) \in \real{}$ fixo.
		Seja $\psi:[0,1] \to Sp(2n)$ com $\psi(0)=Id$ e $\psi(1)=A$, então o índice de Maslov da curva $\psi$ é dado por
		$$
		\mu(\psi) = \varDelta(\psi) - \varDelta(\gamma_{A}).
		$$
		Esse número indica quantas vezes a a imagem aplicação $\rho$ executa uma meia-volta.
	\end{definicao}
	
	Os dois próximos resultados são importantes propriedades do índice de Maslov que são úteis no cálculo do mesmo.
	
	\begin{teorema}
		Seja $\psi\in \caminhossempontobase{\gruposimpletico{2n}} $ um caminho contínuo. Então:
		\begin{enumerate}
			\item $\mu(\psi) \in \inteiros$.
			\item Dois caminhos $\alpha, \beta \in \caminhossempontobase{\gruposimpletico{2n}} $ com $\alpha(0) = \beta(0)$ e $\alpha(1) = \beta(1)$ são homotópicos se, e somente se, $\mu(\alpha) = \mu(\beta)$.
			\item $sign(det(Id - A)) = (-1)^{\mu(\psi)-n}$.
			\item Se $S \in GL(2n)$ é uma matriz simétrica com a norma $||S|| < 2\pi$ e se $\psi(t) = exp(t\estruturacomplexa S)$, então 
			$$
			\mu(\psi) = Ind(S) - n,
			$$
			onde $Ind(S)$ é a multiplicidade dos auto-valores negativos de $S$.
		\end{enumerate}
	\end{teorema}
	\begin{prova}
		Alguns pontos dessa demonstração ainda estão incompletos e serão finalizados futuramente.
	\end{prova}
	
	No caso de sistemas Hamiltonianos autônomos teremos o caso Hamiltoniano reduzido a uma função de Morse $H:M\to \real{}$ e conjunto de soluções 1-periódicas $\lacocontrateis$ será o conjunto de pontos críticos isolados de $H$, logo o índice de Maslov terá uma relação direta com Morse da seguinte forma:
	
	\begin{corolario}
		Sejam $(M, \omega)$ uma 2n-variedade simplectica, $H : M \to \real{}$ uma função hamiltoniana autônoma e $x \in Crit(H)$. Assumindo que $||Hess_{x}(H)|| < 2\pi$, então o índice de Maslov $\mu(x)$ da solução periódica $x$ do sistema hamiltoniano $\dot{x}(t) = X_{H}(x(t))$, pode ser relacionado o índice de Morse $Ind(x)$ do ponto crítico da função $H$ da seguinte forma:
		$$
		\mu(x) = Ind(x) - n.
		$$
	\end{corolario}	
	
	\chapter{Homologia de Floer}
	A Teoria de Morse clássica é uma estrátegia de se estudar a topologia de variedades diferenciáveis de dimensão finita através da análise do comportamento de funções suaves definidas na dada variedade, chamadas funções de Morse. Tal estratégia resume-se em determinar os pontos críticos dessas funções, e a eles associar invariantes topológicos (os índices de Morse). Por fim, calcula-se a homologia da variedade.
	
	Em 1966 em um congresso em Moscou, o matemático russo Vladimir Igorevich Arnold, nos estudos de sistemas Hamiltonianos e topologia do 2-toro, formulou uma conjectura a respeito do número de pontos fixos que um simplectomorfismo definido em uma variedade simplética possui e o número de pontos crísticos de uma função de Morse, que deu origem a seguinte generalização:
	
	\textit{\textbf{(Conjectura de Arnold):} Sejam $(M, \omega)$ uma variedade simplética 2n-dimensioanl e $\psi : M \to M $ um simplectomorfismo Hamiltoniano, então $\psi$ deve ter tantos pontos fixos quanto uma função suave em $M$ deve ter de ponstos críticos. Se os pontos fixos forem não-degenerados, então os número de pontos fixos é, no mínimo, o mesmo número de pontos críticos de uma função de Morse em $M$.}
	
	Foi no contexto de sua demonstração que nasceu a Homologia de Floer, quando na tentativa de se construir uma técnica analoga a  Morse clássica que se deparou com algumas barreiras técnicas, tais como: variedades infinitas e a definição de um análogo ao índice de Morse dos pontos críticos não-degenerados nessas variedades. Floer utiliza como função de Morse um funcional definido nesse espaço, que é um espaço de funções, e estuda seus pontos críticos e linhas de fluxo de seu gradiente para a construção da homologia da variedade simplética. Ao final, mostra que essa homologia é isomorfa a homologia singular da variedade.
	
	\section{Definições}
	Seja $C = C(M, \inteiros_{2})$ o espaço vetorial sobre o corpo $\inteiros_{2}$ e gerado pelos elementos de $\lacocontrateis$. Esse espaço é graduado pela função $m$, de modo que
	$$
	C = \bigoplus_{k}C_{k}, \; C_{k}(M, \inteiros_{2}) = \text{span}\{x \in \lacocontrateis:m(x)=k \}.
	$$
	Segue-se da compacidade e da estruta de variedade diferenciável que $\mathcal{M}(y,x)$ possui um número finito de elementos sempre que $ m(y)-m(x)=1 = dim(\mathcal{M}(y,x))$. Com esse fato podemos construir o operador bordo $\partial : C_{k+1} \to C_{k}$ tal que
	$$
	\partial y = \sum_{m(x)=k} n_{k}(x) x,	
	$$
	onde $n_{k}(x)$ é o número de componentes de $\mathcal{M}(y,x)$ módulo 2. Posteriormente Floer demonstra que $\partial^{2}=0$, assim $(C,\partial)$ define um complexo de cadeias e a homologia
	$$
	HF_{*}(M, \inteiros_{2}) = \frac{Ker(\partial)}{Im(\partial)}
	$$
	é chamada homologia de Floer.
	
	\textbf{Observação:} Note que ao se definir o complexo de cadeias não fizemos referência a função Hamiltoniana nem a estrutura quase-complexa J escolhidas, isso porque a homologia de Floer não depende de tais escolhas, seguindo o teorema:
	
	\begin{teorema}
		Sejam $(H,J)$ e $(H',J')$ pares regulares, isto é, $J, J' \in J_{reg}$, respeticamente, então existe um homomorfismo de cadeias induzindo um isomorfismo nas homologias de Floer
		$$
		HF_{*}(M,\inteiros_{2};H,J) \cong HF_{*}(M,\inteiros_{2};H',J'). 
		$$
		Além disso, existe um isomorfismo natural entre a homologia de Floer e a homologia singular de $M$
		$$
		HF_{*}(M,\inteiros_{2};H,J) \cong H_{*}(M;\inteiros_{2}). 
		$$
		
	\end{teorema}
	
	\appendix
	\chapter{Preliminares de Álgebra}
	
	Nessa seção apresentaremos alguns resultados preliminares necessários para o estudo da topologia de $\gruposimpletico{2n}$ e do conjunto das estruturas complexas $\estruturascomplexas{V}{\omega}$.
	
	
	Sejam $V$ um n-espaço vetorial real, $B= \{e_{j}\}_{j=1}^{n}$ uma base ordenada e $f:V\times V\to \reta$ uma aplicação bilinear. Definindo $A$ como a matriz de $f$ na base $B$, isto é, $A_{ij} = f(e_{i}, e_{j})$, pode-se mostrar que $f$ é positiva-definida se, e somente se, a função $g_{A}: M_{n\times 1}(\reta)\times M_{n\times 1}(\reta) \to \reta$, definida por $
	g_{A}(U,V) = U^{t}AV$, é positiva-definida.
	
	\begin{definicao}
		(k-subdeterminante) Seja $A \in \matrizquadreal{n}$. O seu k-subdeterminante é
		$$
		det_{k}(A) =
		det \left(
		\begin{array}{ccc}
		A_{11} & \dots & A_{1k}
		\\
		\vdots & \ddots & \vdots
		\\
		A_{k1} & \dots & A_{kk}
		\end{array}
		\right),\;\; 1\leq k \leq n.
		$$
	\end{definicao}
	
	\begin{teorema}\label{teorema_matriz_positiva_definida}
		Sejam $V$ um n-espaço vetorial real, $f: V\times V\to \reta$ uma aplicação bilinear e $A$ a matriz de $f$ na base ordenada $B$. Então $f$ é positiva-definida se, e somente se, $A=A^{t}$ e $det_{k}(A)>0$ para $1\leq k\leq n$.
	\end{teorema}
	
	\begin{observacao}\label{observacao_matriz_positiva_definida}
		Do teorema anterior pode-se afirmar que, se $A$ for diagonalizável, todos os seus auto-valores serão positivos.
	\end{observacao}
	
	Note a relação $f(u, v) = \sum_{i, j}u_{i}v_{j}f(e_{i}, e_{j}) = \sum_{i, j}u_{i}v_{j}A_{ij} = U^{t}AV = g_{A}(U, V)$, onde $U, V$ são as representações matriciais de $u$ e $v$, respectivamente. Assim, temos a seguinte definição.
	
	\begin{definicao}\label{definicao_matriz_positiva_definida}
		(Matriz positiva-definida) Se uma matriz $A \in \matrizquadreal{n}$ é tal que $g_{A}(U, V)\geq 0$ para todos $U,V \in M_{n\times 1}$, então diremos que $A$ é positiva-definida. Denotaremos por $\matrizsimetricapositiva{n}$ o conjunto de todas as matrizes em $\matrizquadreal{n}$ positivas-definidas.
	\end{definicao}
	
	Supondo que $\espectrooperador{A}$ seja o espectro de $A$, então $\autoespaco{\lambda}$ é o auto-espaço de $A$ associado a $\lambda \in \espectrooperador{A}$.
	
	\begin{definicao}\label{definicao_potenciacao_matriz}
		(Potênciação de matriz) Sejam $V$ um n-espaço vetorial real, $A:V \to V$ um operador linear diagonalizável. Dado $\alpha \in \real{}$ o operador linear $A^{\alpha}:V \to V$ é o operador definido por $A^{\alpha} = B^{-1}diag\{ \lambda_{1}^{\alpha} , \dots, \lambda_{2n}^{\alpha} \}B$, onde $B$ é a matriz tal que $A= B^{-1}diag\{ \lambda_{1}, \dots, \lambda_{2n}\}B$.
	\end{definicao}
	
	\begin{observacao}
		Note que, para um dado $v \in E_{\lambda}$, teremos $A^{\alpha}v = \lambda^{\alpha}v$, logo $v \in E_{\lambda^{\alpha}}$. Portanto, $E_{\lambda}\subset E_{\lambda^{\alpha}}$.
	\end{observacao}
	
	\begin{observacao}\label{observacao_transposta_potenciacao_matriz}
		Denotando $D = diag\{ \lambda_{1}^{\alpha} , \dots, \lambda_{2n}^{\alpha} \}$, temos da definição que
		$$
		(A^{\alpha})^{t} = B^{t}D^{t}(B^{-1})^{t} = B^{t}D(B^{t})^{-1} = (A^{t})^{\alpha}.
		$$
	\end{observacao}
	
	\begin{definicao}
		(Matriz ortogonal) O conjunto $\matrizortogonal{n} =\{ A \in \generalgroupreal{n}: AA^{t}=Id \}$ é denominado conjunto das matrizes ortogonais.
	\end{definicao}
	
	\begin{observacao}
		O conjunto das matrizes ortogonais forma um grupo com a operação de multiplicação de matrizes.
	\end{observacao}
	
	O resultado seguinte é uma caracterização de matrizes normais  utilizando matrizes ortogonais e matrizes positivas definidas. Sua demonstração pode ser encontrada em $\cite{hoffman_kunze}$.
	
	\begin{lema}\label{lema_caracterizacao_matriz_normal}
		(Caracterização matriz normal) Seja $A\in \matrizquadreal{n}$ uma matriz normal, isto é, $A^{t}A=AA^{t}$. Então existem uma matriz diagonal $D \in \matrizquadreal{n}$ positiva-definida e uma matriz $O\in \matrizortogonal{n}$ tais que $A=ODO^{t}$. Nesse caso seus auto-valores são positivos. 
	\end{lema}
	
	\begin{observacao}\label{observacao_caracterizacao_matriz_normal}
		No caso de uma matriz complexa $A \in M_{n\times n}(\mathbb{C})$ teremos a decomposição $A=U^{*}DU$, onde $U \in \matrizunitaria{n}$.
	\end{observacao}
	
	\begin{lema}\label{lema_raiz_matriz_normal}
		(Raíz de matriz normal) Seja $V$ um n-espaço vetorial e $A\in \matrizquadreal{n}$ uma matriz normal, então existe uma única $P\in \matrizsimetricapositiva{n}$ tal que $A=P^{2}$. 
	\end{lema}
	\begin{prova}
		Como $A$ é normal, então pelo Lema $\ref{lema_caracterizacao_matriz_normal}$ podemos escrever $A=ODO^{t}$, onde $D=(D_{ii})$ é uma matriz diagonal com entradas positivas e $O\in \matrizortogonal{n}$. Logo podemos definir $C \in \generalgroupreal{n}$ como sendo $C = (\sqrt{D_{ii}})$, o que implica em $C^{2} = D$. Definindo $P = OCO^{t}$ teremos $P^{2} = OCO^{t}OCO^{t} = OC^{2}O^{t} = ODO^{t}=A$. Temos que $P^{t} = (OCO^{t})^{t} = OCO^{t} = P$, pois $C$ é diagonal. Além disso, $P$ é semelhante a uma matriz diagonal, então pelo Teorema $\ref{teorema_matriz_positiva_definida}$ temos que $P \in \matrizsimetricapositiva{n}$. A unicidade vem do fato de que $C^{2} = D$ é única, logo $P$ é única.
	\end{prova}
	
	\begin{observacao}\label{observacao_raiz_matriz_normal}
		A matriz do Lema $\ref{lema_raiz_matriz_normal}$ é chamada raíz de $A$ e é denotada por $P=\sqrt{A}$.
	\end{observacao}
	
	O seguinte teorema é de grande importância pois é fundamental na caracterização do grupo simplético e investigação de sua topologia. Um caso mais geral que pode ser encontrado em $\cite{hoffman_kunze}$.
	
	\begin{teorema}\label{teorema_decomposicao_polar}
		(Decomposição polar) Se $(V, \produtointerno{}{})$ é um n-espaço vetorial real com um produto interno positivo-definido e $A \in \generalgroupreal{n}$, então podemos escrever $A=PO$ onde $P \in  \matrizsimetricapositiva{n}$ e $O \in \matrizortogonal{n}$ e essa decomposição é única.
	\end{teorema}
	\begin{prova}
		Por construção temos que $AA^{t}$ é normal. Então pelo Lema $\ref{lema_raiz_matriz_normal}$ existe uma única $P \in \matrizsimetricapositiva{n}$ tal que $P^{2} = AA^{t}$, isto é, $P = \sqrt{AA^{t}}$. Como $P$ é invertível, podemos definir $O = P^{-1}A$. Vejamos que $OO^{t} = P^{-1}AA^{t}(P^{-1})^{t} = P^{-1}AA^{t}(P^{t})^{-1} = P^{-1}AA^{t}P^{-1} = P^{-1}P^{2}P^{-1} = Id$, logo $O \in \matrizortogonal{n}$. Pela unicidade de $P$ temos que $O=P^{-1}A$ é única. Portanto $A=PO$, onde $P \in \matrizsimetricapositiva{n}$ e $O \in \matrizortogonal{n}$ são únicas.
	\end{prova}
	
	\begin{corolario}\label{corolario_decomposicao_matriz_antisimetrica}
		(Decomposição polar anti-simétrica) Considere as hipóteses no Teorema $\ref{teorema_decomposicao_polar}$ e tome $A \in \generalgroupreal{n}$ uma matriz anti-simétrica. Então $A = PO$, onde $P \in \matrizsimetricapositiva{n}$, $O \in \matrizortogonal{n}$ com  $O^{2} = -Id$ e $O^{t} = -O$.
	\end{corolario}
	\begin{prova}
		Temos que $AA^{t}$ é uma matriz normal, logo pelo Lema $\ref{lema_caracterizacao_matriz_normal}$ é diagonalizável e podemos escrever $AA^{t} = B^{-1}diag\{\lambda_{1}, \dots, \lambda_{n}\}B$. Logo temos 
		$$
		(AA^{t})^{1/2} =B^{-1}diag\{\lambda_{1}^{1/2}, \dots, \lambda_{n}^{1/2}\}B.
		$$
		Portanto, $P=(AA^{t})^{1/2}$ é positiva-definida, logo $P=P^{t}$. Sejam $D_{P}$ e $D_{A}$ as matrizes diagonais semelhantes a $P$ e $A$, respectivamente. Afirmo que $PA = AP$. De fato, $PA = B^{-1}D_{P}B B^{-1}D_{A}B = B^{-1}D_{A} D_{P}B = B^{-1}D_{A}B B^{-1}D_{P}B = AP$. Definindo $O = P^{-1}A$ teremos $OO^{t} = P^{-1}A(P^{-1}A)^{t} = P^{-1}AA^{t}(P^{t})^{-1} = P^{-1}AA^{t}P^{-1} = P^{-1}P^{2}P^{-1}  = Id$, portanto $O \in \matrizortogonal{n}$. Além disso, $O^{2} = P^{-1}AP^{-1}A = P^{-2}A^{2} = (AA^{t})^{-1}A^{2} = -Id$, onde usamos a anti-simetria e o fato de que $P^{-1}$ comuta com $A$. Pelo Teorema $\ref{teorema_decomposicao_polar}$ a decomposição $A=PO$ é única.
	\end{prova}
	
	Seja $T:V\to V$ um operador linear e $V$ um n-espaço vetorial sobre os complexos. Suponha que $A \in \matrizquadcomplexa{n}$ seja sua representação matricial. Mesmo que $A$ seja invertível, isso não garante que $T$ seja diagnalizável. Contudo, sob algumas hipósteses, podemos escrever $A$ de um modo que se assemelha a uma matriz diagonal, e com isso, decompormos $V$ como soma direta de subespaços vetoriais construidos a partir de $T$. Essa construção é o que chamamos de forma canônica de Jordan e será utilizada na análise dos auto-valores do grupo simplético.
	
	A diagonalização de um dado operador linear $T:V\to V$ nem sempre é garantida, consequentemente, não teremos a decomposição do espaço vetorial em auto-espaços $\autoespaco{\lambda}$, onde $\lambda\in \espectrooperador{T}$. Para contornar esse dificuldade técnica vamos utilizar a forma canônica de Jordan de $T$ e construir uma generalização de auto-espaços desse operador.
	
	\begin{corolario}\label{teorema_espectral_jordan}
		(Teorema Espectral) Sejam $T:V \to V$ um operador linear e $V$ um n-espaço vetorial complexo. Suponha que o polinômio característico de $T$ seja
		$$
		p_{T}(\lambda) = (\lambda - \lambda_{1})^{n_{1}}\dots (\lambda - \lambda_{k})^{n_{k}}
		$$
		em que $\lambda_{j} \in \sigma(T)$ sejam todos distintos. Então existem subespaços $V_{j} \subset V$ com $1\leq j \leq k$ invariantes por $T$ tais que 
		$$
		V = E_{1}\oplus \dots \oplus E_{k}.
		$$
		Além disso, $dim(E_{j}) = n_{j}$,  o polinômio de $T|_{E_{j}}$ é $m_{j}(\lambda) = (\lambda - \lambda_{j})^{m_{j}}$ e $E_{j} = Ker(T-\lambda_{j})^{m_{j}}$, em que $1\leq m_{j}\leq n_{j}$ é o comprimento do maior bloco de Jordan associado ao auto-valor $\lambda_{j}$.
	\end{corolario}
	
	\begin{definicao}\label{definicao_autoespaco_generalizado}
		(Auto-espaços generalizados) Sejam $A$ como no teorema anterior e $\lambda \in \sigma(A)$. O $\lambda-$auto-espaço de generalizado de $A$ é o conjunto $E_{\lambda} = \bigcup_{r \in \mathbb{N}} Ker(A - \lambda)^{r}$.
	\end{definicao}
	
	\begin{thebibliography}{9}
		\bibitem{abramovich}
		Abramovich, Y. A.; Aliprantis, C. D.
		\emph{An Invitation to Operator Theory},
		American Mathematical Society, 2002.
		
		\bibitem{amyia_diff_topology}
		Amyia, Mukherjee:
		\emph{Topics in Differential Topology},
		Texts and Reading in Mathematics 34,
		2005.
		
		\bibitem{audi_floer_homology}
		Audi, Michèlle; Damian, Mihai:
		\emph{Morse Theory and Floer Homology},
		Springer, first edition,
		2010.
		
		\bibitem{banyaga_morse_homology}
		Banyaga, Augustin; Hurtubise, David
		\emph{Lectures on Morse Homology},
		Springer Science + Business Media, first edition,
		2004.
		
		\bibitem{breazis_sobolev_spaces}
		Brezis, Haim:
		\emph{Functional Analysis, Sobolev Spaces and Partial Differential Equantions},
		Springer, first edition,
		2011.
		
		\bibitem{cappell_maslov_index_equivalencia}
		Cappell, Sylvain E.; Lee, Ronnie; Miller, Edward Y.
		\emph{On Maslov Index}, Communication on Pure and Applied Mathematics, Vol. XLVII, 121-186 (1994).
		
		\bibitem{manfredo_riemannian_geo}
		Do Carmo, Manfredo P.:
		\emph{Riemannian Geometry},
		Birkhauser, 2nd edition,
		1992.
		
		\bibitem{doering_ode}
		Doering, Claus I.; Lopes, Artur O.:
		\emph{Equações Diferenciais Ordinárias - Coleção Matemática Universitária},
		IMPA, terceira edição,
		2008.
		
		\bibitem{guillemin_differential_topology}
		Guillemin, Victor; Pollack, Alan:
		\emph{Differential Topolgy},
		Prentice-Hall,
		1974.	
		
		\bibitem{hoffman_kunze}
		Hoffman, Kenneth; Kunze, Ray
		\emph{Linear Algebra},
		John Wiley and Sons, 2nd edition, 1971.
		
		\bibitem{kreyszig_analise_funcional}
		Kreyszig, Erwin
		\emph{Introduction to Functional Analysis with Applications},
		John Wiley and Sons, 1978.
		
		\bibitem{friedlander}
		Friedlander, F. G.; Joshi, M.
		\emph{Introduction to Theory of Distributions},
		Cambridge University Press, 2nd edition
		1998.
		
		\bibitem{elon_grupo_fundamental}
		Lima, Elon Lages:
		\emph{Fundamental Group and Covering Spaces},
		A K Peters, 2003.
		
		\bibitem{massey}
		Massey, William S.:
		\emph{A Basic Course in Algebraic Topology},
		Springer-Verlag, first edition,
		1991.
		
		\bibitem{milnor}
		Milnor, J.:
		\emph{Morse Theory},
		Princeton University Press, 1963.

		\bibitem{munkres_topology}
		Munkres, James R.:
		\emph{Topology},
		Prentice Hall Inc., 2000.
				
		\bibitem{nakahara}
		Nakahara, Mikio:
		\emph{Geometry, Topology and Physics},
		Graduate Student Series in Physics, 2nd edition,
		2003.
		
		\bibitem{nussenzveig}
		Nussenzveig, Moyses:
		\emph{Mecânica - Curso de Física Básica Vol 1},
		Edgard Blucher, 4 edição,
		2002.
		
		\bibitem{palis_dynamical_systems}
		Palis, Jaboc; Melo, Welington:
		\emph{Geometric Theory od Dynamical Systems},
		Springer-Verlag,
		1982.
		
		\bibitem{pontryagin_ode}
		Pontryagin, L.S.:
		\emph{Ordinary Differential Equations},
		Addison-Wesley Publishing Company,
		1962.
		
		\bibitem{salamon_lecture}
		Salamon, Dietmar:
		\emph{Lectures on Floer Homology},
		University of Warnick,
		1997.
		
		\bibitem{witten_supersymmetry_morse}
		Witten, Edward:
		\emph{Supersymmetry and Morse Theory},
		J. Differential Geometry 17,
		1982.
	\end{thebibliography}
	
\end{document}